#!/usr/bin/env node
//"use strict"

fs ← require('fs')

minimist ← require('minimist')
sync ← require('sync')
_ ← require('underscore')

//__sub__ ← λ{__get__(v,b)}
__slice__ ← λ(v,a,b){return is(b)? v.slice(a,b) : v.slice(a)}
__sliceλ__ ← λ(a,b){return is(b)? λ{v[a:b]} : λ{v[a:]}}

print ← console.log.bind(console)
running_as ← process.argv₁.match(~/[^\/]*\/[^\/]*$/)₀
print('--- running as:',running_as,'---')

//===---------------------------===// utils //===--------------------------===//

seq ← λ{v isa Array? v : typeof(v)='string'? v.split('') : Object.keys(v).map(λ(k){return [k,vₖ]})}
Array.prototype.object ←! λ{this.reduce(λ(r,v){r[v₀] ←! v₁; return r},{})}
memoize_o ← λ(o,f){return λ(v){r ← own(o,v); return is(r)? r : (oᵥ ←! f(v))}}
merge_o ← λ{$args.map(λ{seq(v)}).m_concat().object()}
object_by ← λ(v,f){return seq(v).map(λ{[f(v),v]}).object()}

pad_left ← λ(v,s,l){return s.repeat(l-v.length)+v}
hex ← λ(v,l){return pad_left(v.toString(16),'0',l)}
now ← λ{Date.now() / 1000}
ord ← λ{v.charCodeAt(0)}
chr ← λ{String.fromCharCode(v)}
own ← λ(o,m){return Object.prototype.hasOwnProperty.call(o,m)? oₘ : undefined}
err ← λ(){print.apply(console, ['#error#:'].concat($args)); throw(Error())}
extend_function ← λ(f){r ← λ(){r ← f(); r.__proto__ ←! λ.prototype; return r}; r.prototype.__proto__ ←! Function.prototype; return r}
delset ← λ(o,m,v){if (¬is(v)) delete(oₘ); else oₘ ←! v}
is ← λ{v≠undefined}
i ← λ{parseInt(v)}
float_next_after  ← λ(v){r ← v=0?  1e-300 : v<0? v*0.9999999999999995 : v*1.0000000000000005; if (r=v) err(v); return r} // hack
float_next_before ← λ(v){r ← v=0? -1e-300 : v<0? v*1.0000000000000005 : v*0.9999999999999995; if (r=v) err(v); return r} // hack
String.prototype.repeat ←! λ{v≤0? '' : new Array(v+1).join(this)}
Array.prototype.m_concat ←! λ{Array.prototype.concat.apply([],this)}
Object.defineProperty(Array.prototype,'no',{get:λ{this.length=0}})

//===-------------------------===// reader_or //===------------------------===//

reader_or ← extend_function(λ{λ(start,s,line){return (λ[s₀]? λ[s₀](start+s₀,s[1:],line) : undefined) || (λ['']? λ[''](start,s,line) : undefined)}})
reader_or.prototype.get ←! λ(s){return this[s₀]? (this[s₀] isa reader_or? this[s₀].get(s[1:]) : this[s₀]) : undefined}
reader_or.prototype.set ←! λ(ss,r){
	seq(ss).map(λ(s){
		c ← s=''? '' : s₀; s ← s[1:]
		if (s ≠ '') (this[c] isa reader_or? this[c] : this[c] ←! new reader_or().set([''],own(this,c))).set([s],r)
		else delset(this,c,r)
	}.bind(this)); return this}
reader_or.prototype.reduce_l ←! λ(s){r ← []; line ← 1; while (s ≠ '') {t ← this('',s,line); r.push(t₀); s ←! t₁; line ←! t₂} return r}
reader_or.prototype.reduce   ←! λ(s){r ← [];           while (s ≠ '') {t ← this('',s     ); r.push(t₀); s ←! t₁            } return r}

//===------------------------===// characters //===------------------------===//

js_valid_symbol ← new (λ(){
	//! _short
	_short ← [' _'].concat("!1 #3 %5 &7 (9 )0 *8 +p ,C -m .d /s :c =E ?q @2 [L 'b ^6 `k {B |o ~t …r ←w →e ¬n ∀A ≠N ǂǂ <lt ≤le >gt ≥ge".split(' ')).map(λ{[v₀,v[1:]]})
	encode_short ← _short.map(λ{[v₀,'ǂ'+v₁]}).object()
	decode_short ← _short.map(λ{[v₁,v₀]}).object()
	is_start ← memoize_o(seq(';ǂ \t\n\x0b\x0c\x0d').map(λ{[v,false]}).object(),λ(v){try {eval('var '+v )} catch (e) {return false} return true})
	is_part  ← memoize_o(seq(';ǂ \t\n\x0b\x0c\x0d').map(λ{[v,false]}).object(),λ(v){try {eval('var a'+v)} catch (e) {return false} return true})
	encode_char ← memoize_o(encode_short, λ(v){return is_part(v)? v : 'ǂu'+hex(ord(v),4)})

	keywords ← ['break','do','instanceof','typeof','case','else','new','var','catch','finally','return','void','continue','for','switch','while','debugger','function','this','with','default','if','throw','delete','in','try','class','enum','extends','super','const','export','import','implements','let','private','public','yield','interface','package','protected','static']

	decoder ← new reader_or()
	decoder.set([''],λ(_,s){return [s₀,s[1:]]})
	decoder.set(['ǂu'],λ(_,s){return [chr(parseInt(s[:4],16)),s[4:]]})
	seq(decode_short).map(λ(kv){k ← kv₀; v ← kv₁; decoder.set(['ǂ'+k],λ(_,s){return [v,s]})})

	this.is_part ←! is_part
	this.encode ←! memoize_o(keywords.map(λ{[v,'ǂ'+v]}).object(),λ(v){r ← seq(v).map(encode_char).join(''); return (¬is_start(r₀)?'ǂ':'')+r})
	this.decode ←! memoize_o(keywords.map(λ{['ǂ'+v,v]}).object(),λ{decoder.reduce(v₀='ǂ'? v[1:] : v).join('')})
	})
unicode ← λ(table){return {
	subscripts:   table.map(λ{v₀}).filter(λ{v≠'-'}),
	midscripts:   table.map(λ{v₁}),
	superscripts: table.map(λ{v₂}).filter(λ{v≠'-'}),
	subscript:   λ(f){return λ{seq(v).map(λ{f[v]}).join('')}}(table.map(λ{[[v₁,v₀], [v₂,v₀]]}).m_concat().object()),
	midscript:   λ(f){return λ{seq(v).map(λ{f[v]}).join('')}}(table.map(λ{[[v₀,v₁], [v₂,v₁]]}).m_concat().object()),
	superscript: λ(f){return λ{seq(v).map(λ{f[v]}).join('')}}(table.map(λ{[[v₀,v₂], [v₁,v₂]]}).m_concat().object())
	}}('₀0⁰ ₁1¹ ₂2² ₃3³ ₄4⁴ ₅5⁵ ₆6⁶ ₇7⁷ ₈8⁸ ₉9⁹ ₊+⁺ ₋-⁻ ₌=⁼ ₍(⁽ ₎)⁾ ₐaᵃ -bᵇ -cᶜ -dᵈ ₑeᵉ -fᶠ -gᵍ ₕhʰ ᵢiⁱ ⱼjʲ ₖkᵏ ₗlˡ ₘmᵐ ₙnⁿ ₒoᵒ ₚpᵖ ᵣrʳ ₛsˢ ₜtᵗ ᵤuᵘ ᵥvᵛ -wʷ ₓxˣ -yʸ -zᶻ -Aᴬ -Bᴮ -Dᴰ -Eᴱ -Gᴳ -Hᴴ -Iᴵ -Jᴶ -Kᴷ -Lᴸ -Mᴹ -Nᴺ -Oᴼ -Pᴾ -Rᴿ -Tᵀ -Uᵁ -Vⱽ -Wᵂ'.split(' '))

//===--------------------------===// Symbol //===--------------------------===//

Symbol ← λ(v,line,before,after){this.v ←! v; if (line) this.line ←! line; this.space_before ←! is(before)?before:true; this.space_after ←! is(after)?after:true}
//	space_update ← λ(me){me._space ←! (me.space_before?'_':'')+'$'+(me.space_after?'_':'')}
//Object.defineProperty(Symbol.prototype,'space',{get:λ{this._space},set:λ(v){this._space ←! v; this._space_before ←! v₀='_'; this._space_after ←! v₋₁='_'}})
//Object.defineProperty(Symbol.prototype,'space_before',{get:λ{this._space_before},set:λ(v){this._space_before ←! v; space_update(this)}})
//Object.defineProperty(Symbol.prototype,'space_after', {get:λ{this._space_after },set:λ(v){this._space_after  ←! v; space_update(this)}})

Object.defineProperty(Symbol.prototype,'space',{get:λ{err('a')},set:λ(v){err('b')}})
Object.defineProperty(Symbol.prototype,'space_before',{get:λ{err('c')},set:λ(v){err('d')}})
Object.defineProperty(Symbol.prototype,'space_after', {get:λ{err('e')},set:λ(v){err('f')}})
Symbol.prototype.inspect ←! λ{'`'+this.v}
Symbol.prototype.with_v ←! λ{new Symbol(v,this.line,this.space_before,this.space_after)}
S ← λ{new Symbol(v,undefined,false,false)}
/*symbol_set_decode ← λ(v){
	t ← v.match(~/^([₋␣])?(.+?)([₋␣])?$/); s ← (t₁||'?')+(t₃||'?'); n ← t₂
	return (symbol_set_table[s]||err('bad symbol set',s)).map(λ(v){r ← new Symbol(n); r.space ←! v; return r})}
	symbol_set_table ← {
		'₋₋':['$'],
		'₋␣':['$_'],
		'␣₋':['_$'],
		'␣␣':['_$_'],
		'?₋':['$','_$'],
		'?␣':['$_','_$_'],
		'₋?':['$','$_'],
		'␣?':['_$','_$_'],
		'??':['$','$_','_$','_$_']
		}*/
SP ← {}
se ← λ{v isa Symbol && v.v=b} // hack
s_int ← λ{v isa Symbol && v.v.match(~/^[0-9]+$/)} // hack
s_mk_float ← λ{new Symbol(v.v+'.'+b.v,v.line,v.space_before,b.space_after)} // hack

//===---------------------===// load.α hack utils //===--------------------===//

split_symbol ← λ(l,s){r ← [[]]; l.map(λ(v){if (se(v,s)) r.push([]); else r₋₁.push(v)}); return r}
has_sym ← λ(v,s){return v.some(λ{se(v,s)})}
split_slice ← λ(l){r ← split_symbol(l,':'); r ← [[(is(r₀₀)? r₀₀ : S('0'))]].concat(r[1:]).m_concat(); return r}
pr ← λ(){if (running_as = 'bin/load.js') print.apply(this,['##'].concat($args)); return $args₀}
printable ← λ{λᵥ}

//===---------------------------===// repr //===---------------------------===//

String.prototype.repr_js ←! λ(){v ← this.valueOf(); return (v.match(~/'/g)||[]).length ≤ (v.match(~/"/g)||[]).length? //?
	"'"+seq(v).map(λ{{"'":"\\'",'\n':'\\n','\t':'\\t','\\':'\\\\'}ᵥ || (printable(v)? v : '\\u'+hex(ord(v),4))}).join('')+"'" :
	'"'+seq(v).map(λ{{'"':'\\"','\n':'\\n','\t':'\\t','\\':'\\\\'}ᵥ || (printable(v)? v : '\\u'+hex(ord(v),4))}).join('')+'"'}
RegExp.prototype.repr_js ←! λ{this+''}
String.prototype.repr ←! String.prototype.repr_js
RegExp.prototype.repr ←! λ{'~'+this+''}
repr_js_trans_infix ← merge_o({'&':'&&','|':'||','isa':'instanceof','=':'===','≠':'!==','≤':'<=','≥':'>='},object_by('. * / % + - < > in && || +='.split(' '),λ{v}))
repr_js ← λ(v,line){rj ← λ{repr_js(v,line)}; mrj ← λ{v.map(rj).join(b||'')}; ln ← λ{(v && v.line && line? '\n'.repeat(λ(v){line₀ += v; return v}(Math.max(0, v.line-line₀))) : '')}
	return ¬is(v)? pr('<gah>',line₀) :
		v.repr_js? v.repr_js(line) :
		v isa Symbol? ln(v) + (v.space_before?' ':'') + (v.v='/'?'÷':v.v='$args'?'Array.prototype.slice.apply(arguments)':v.v) + (v.space_after?' ':'') :
		v isa Array?
			v.no? '()' :
				v₀ isa Symbol? ln(v₀) + (
					v₀.v='__literal__'? v₁+'' :
					//v₀.v='__do__'? v.length=2? rj(v₁) : '{'+mrj(v[1:],';')+'}' :
					v₀.v='__do__e'? '('+rj(v₁)+')' :
					v₀.v='__do__s'? '{'+mrj(v[1:],';')+'}' :
					v₀.v='__get__'? '('+rj(v₁)+'['+rj(v₂)+'])' :
					v₀.v='__sub__'? '('+rj(v₁)+'['+rj(v₂)+'])' :
					v₀.v='__array__'? '['+mrj(v[1:],',')+']' :
					v₀.v='←'? 'var '+rj(v₁)+' = '+rj(v₂) :
					v₀.v='←!'? '('+rj(v₁)+' = '+rj(v₂)+')' :
					v₀.v='¬'? '(!'+rj(v₁)+')' :
					v₀.v='new'? 'new '+rj(v₁).replace(~/^\((.*)\)$/,'$1') :
					v₀.v='return'? 'return '+rj(v₁) : // should be return(…) or return
					v₀.v='throw'? 'throw '+rj(v₁) :
					v₀.v='delete'? 'delete '+rj(v₁) :
					v₀.v='while'? 'while('+rj(v₁)+'){'+rj(v₂)+'}' :
					v₀.v='try'? 'try{'+rj(v₁)+'}catch(e){'+rj(v₂)+'}' :
					v₀.v='λ'? 'function λ('+mrj(v₁,',')+'){'+rj(v₂)+'}' :
					v₀.v='if'? '('+rj(v₁)+'?'+rj(v₂)+':'+rj(v₃)+')' :
					v₀.v='if_s'? 'if('+rj(v₁)+'){'+rj(v₂)+'}'+(¬is(v₃)?'':'else{'+rj(v₃)+'}') :
					v₀.v='-' && v.length=2? '(-('+rj(v₁)+'))' :
					own(repr_js_trans_infix,v₀.v)? '('+rj(v₁)+repr_js_trans_infix[v₀.v]+rj(v₂)+')'  :
						'('+rj(v₀)+'('+mrj(v[1:],',')+'))' ) :
					rj(v₀)+'('+mrj(v[1:],',')+')' :
		typeof(v)='object'? '{'+Object.keys(v).map(λ(k){return rj(k)+':'+rj(vₖ)}).join(',')+'}' :
			'<what:'+v+'>'}
repr_js_file ← λ(form){return repr_js(form, [1])[1: -1].replace(~/ +/mg,' ').replace(~/^ /mg,'').replace(~/;$/m,'')}

//===------------------===// reader macros (lexing) //===------------------===//

reader_macros ← new reader_or()
tokenize ← λ(s){
	t←undefined; r ← [].concat([SP],((t ←! s.match(~/^#!.*/))? [S('__literal__'),S('('),t₀,S(')'),SP] : []),reader_macros.reduce_l(t? s[t₀.length:] : s),[SP])
	i←1; while (i<r.length-1) {if (rᵢ isa Symbol) {rᵢ.space_before ←! r[i-1]=SP; rᵢ.space_after ←! r[i+1]=SP} i+=1}
	return r.filter(λ{v ≠ SP})}

subscript_ops ← [].concat(unicode.subscripts,unicode.subscripts.map(λ{'₋'+v}))

reader_macros.set([''], λ(_,s,l){
	first_type ← js_valid_symbol.is_part(s₀)
	r ← ''; while (s ≠ '' && (s.match(~/^[0-9]/) || ¬reader_macros.get(s)) && js_valid_symbol.is_part(s₀) = first_type) {r += s₀; s ←! s[1:]}
	return [new Symbol(r,l),s,l]})
reader_macros.set('0123456789', λ(_,s,l){t ← s.match(~/^[0-9]*\.[0-9]*(?:[eE][+-]?[0-9]+)?/); return t? [new Symbol(_+t₀),s[t₀.length:],l] : undefined})
reader_macros.set(['.'],λ(_,s,l){t ← s.match(~/^[0-9]+(?:[eE][+-]?[0-9]+)?/); return [new Symbol(t?_+t₀:_,l),t?s[t₀.length:]:s,l]})
reader_macros.set([].concat(seq('()[]{}‹›`~?:,;'), ['~@','¬in'],subscript_ops), λ(_,s,l){return [new Symbol(_,l),s,l]})
reader_macros.set(' \t\x0c\x0d', λ(_,s,l){return [SP,s,l]})
reader_macros.set('\n', λ(_,s,l){return [SP,s,l+1]})
reader_macros.set(['//'], λ(_,s,l){return [SP,s.replace(~/^.*/,''),l]})
reader_macros.set(['/*'], λ(_,s,l){t ← s.match(~/^[^]*?(\*\/|$)/)₀; return [SP,s[t.length:],l+(t.match(~/\n/g)||[]).length]})
reader_macros.set('\'"', λ(start,s,line){
	t ← s.match(start='"'? ~/^((?:(?:.*[^\\])?(?:\\\\)*)?)"/ : ~/^((?:(?:.*[^\\])?(?:\\\\)*)?)'/) || err('string is not closed @'+line); s ←! s[t₀.length:]; v ← t₁
	return [v.match(~/\\u[0-9a-fA-F]{4}|\\x[0-9a-fA-F]{2}|\\[nt'"\\]|./g).map(λ(v){
		if (v='\n') line += 1; return {"\\'":"'",'\\"':'"','\\\\':'\\','\\n':'\n','\\t':'\t'}ᵥ || (v.length>2? chr(parseInt(v[2:],16)) : v)
		}).join(''),s,line]})
reader_macros.set(['~/'], λ(start,s,line){t ← (s.match(~/^((?:[^\/\\\[]|(?:\\.)|\[(?:[^\\\]]|(?:\\.))*\])*\/[a-z]*)/) || err('could not match regex: '+start+s[:10]))₁; return [eval('/'+t),s[t.length:],line]})

//===----------===// special token macros (deliberate hack) //===----------===//

special_expand ← λ(tokens){
	tokens.map(λ(v){if (v isa Symbol) v.v ←! aliases[v.v] || v.v})
	groups_expand ← λ(tokens){r ← group_expand(S('{'),tokens.concat([S('}')])); if (¬r₁.no) err(); return r₀}
		group_expand ← λ(g,l){
			check ← λ(){if (l.no) err('group is not closed @'+g.line)}
			check()
			r ← [g]; while(true){
				if (se(l₀,groups[g.v])) return [r,l[1:]]
				if (l₀ isa Symbol && own(groups,l₀.v)) {t ← group_expand(l₀,l[1:]); r.push(t₀); l ←! t₁; check(); continue}
				r.push(l₀); l ←! l[1:]; check()}}
	tokens ←! groups_expand(tokens)
	walk ← λ(v,f){return (λ(v,i,l,f){
		if (v isa Array) {for (j←0;j<v.length;) j ←! (λ)(v[j],j,v,f); return i+1}
		else return f(v,i,l) })(v,0,undefined,f)}
	walk(tokens,λ(v,i,l){
		if (se(v,'new') && l[i+1] isa Symbol) {l.splice(i,2,[v,[new Symbol('__QUOTE__',undefined,undefined,true),l[i+1]]]); return i+1}
		else if (se(v,'λ') && l[i+1] isa Array && se(l[i+1]₀,'(')) {l.splice(i,2,v,[new Symbol('__QUOTE__',undefined,undefined,true),l[i+1]]); return i+2}
		else if (se(v,'λ') && l[i+1] isa Array && se(l[i+1]₀,'{')) {l.splice(i,1,v,[new Symbol('__QUOTE__',undefined,undefined,true),S('v')]); return i+2}
		else return i+1 })
	return tokens}

groups ← ['()','[]','{}'].object()
aliases ← {';':',','&&':'&','||':'|'}

//===---------===// "precedence/open/anyfix/operator macros" //===---------===//

operator_expand ← λ(tokens){
	return tokens
}

operators ← {}

def_operators ← λ(prec_l,prec_r,ops){
	//Array.prototype.cartesian ←! λ{this.reduce(λ(a,v){r ← []; a.map(λ(a){seq(v).map(λ(b){r.push(a.concat([b]))})}); return r}, [[]])}
	symbol_set_split ← λ(v){
		t ← v.match(~/^([₋␣])?(.+?)([₋␣])?$/); p ← [t₁||'?',t₃||'?']; n ← t₂
		return [{'__DOT__':['.'], '__SUBSCRIPT__':subscript_ops}[n]||[n], λ{_.zip(p,v).every(λ{v₀='?'||v₀=v₁})}]}

	ops.map(λ(op){
		t ← op.match(~/\[.*?\]|[^\[\]]+/g).map(λ(v){t←0; r ← ((t ←! v₀='[' && v₋₁=']')? v[1:-1] : v).match(~/\.|[^.]+/g); return t?[r]:r}).m_concat()
		ANY ← {}
		pr(t₁,typeof t₁)
		pr('::',symbol_set_split(t₁))
		//! CURRENT
		// hm. at this point we're thinking about maybe normalizing ops into all four, so .₋+₋. is [.₋+₋.] but ¬␣. is [␣¬␣. ₋¬␣.]
		// we could also do something similar with option parsing, though that can get downright combinatorial. though worst current case is try, which fragments into 64 pieces.
		// we could even do this with __SUBSCRIPT__ . which, just so you know, fragments into on the order of 160 pieces. which is still not very much time or space even on an old phone.
		// yeah, i like this
		//'return[.]__SUBSCRIPT__' → ['return','[.]','__SUBSCRIPT__'] → [['return'],['.',undefined],['₁','₂',etc]]
		//[['return'],['.',undefined],['₁','₂',etc]].cartesian() → [['return','.','₁'],['return',undefined,'₁'],etc]
		// nope this does not work. try.[,][catch.][,][finally.] splits into 115600 pieces. gotta branch more.


		//[ 'if', '.', [ ':' ], '.', [ ',' ], [ 'else', '.' ] ]
		/*t.map(λ(v,i,l){
			if (v isa Array) v.map(λ)
			else if (v='.') lᵢ ←! ANY
			else {
				t ← symbol_set_split(v)
				pr('hey',v,t)
			}
		})*/
		//pr('impl:defop',prec_l,prec_r,t)
	}) }

;[	'400 401 .__DOT__₋. .₋__SUBSCRIPT__ .₋[ .₋(',
	'390 391 ¬₋. -₋.',
	'380 381 .₋*₋. .₋/₋. .₋%₋.',
	'370 371 .₋+₋. .₋-₋.',
	'350 350 .₋=₋. .₋≠₋. .₋<₋. .₋>₋. .₋≤₋. .₋≥₋.',
	'340 341 .₋&₋. .₋|₋.',
	'331 330 .₋?₋.₋:₋.',
	'321 322 .₋+=₋.',
	'323 320 .₋←₋. .₋←!₋.',
	'300 301 `₋. ~₋. ~@₋.',
	'290 291 ¬␣.',
	'280 281 .␣*␣. .␣/␣. .␣%␣.',
	'270 271 .␣+␣. .␣-␣.',
	'260 260 .␣isa␣.',
	'250 250 .␣=␣. .␣≠␣. .␣<␣. .␣>␣. .␣≤␣. .␣≥␣.',
	'240 241 .␣&␣. .␣|␣.',
	'231 230 .₋?␣.␣:␣.',
	'221 222 .␣+=␣.',
	'223 220 .␣←␣. .␣←!␣.',
	'210 211 λ.. if.[:].[,][else.] while.[:]. return[.] try.[,][catch.][,][finally.]',
	'200 201 `␣. ~␣. ~@␣.',
	'100 100 , :'
	].map(λ(v){t ← v.split(' '); def_operators(i(t₀),i(t₁),t[2:])})

//===--------------------------===// <edge> //===--------------------------===//

read ← λ(s){
	seq(s).map(λ{printableᵥ ←! true})
	// a bit outdated:
	// tokenize: characters are tokenized with λ(rest_characters) → [token,rest_characters]
	// anyfix/open macros: was // anyfix: tokens naming anyfix macros are expanded into forms with λ(previous_forms,symbol,rest_tokens) → [previous_forms,rest_tokens], but they are not allowed to eat more than the last form of previous_forms . these functions may be called multiple times, so they should be pure.
	// ?: forms naming macros are expanded into forms
	// ?: forms are translated into javascript

	r ← operator_expand(special_expand(tokenize(s)))
	//pr(r)
	return r}

compile_f ← λ(_in,out){fs.writeFileSync(out,repr_js_file(read(fs.readFileSync(_in).toString())))}

compile_f(process.argv₂,process.argv₃)

//===---------------------------===// todo //===---------------------------===//

// keep in mind that the basic idea was always just "write a really nice preprocessor" http://publications.gbdirect.co.uk/c_book/chapter7///how_the_preprocessor_works.html

// void could be a macro for undefined, or it could just be another global variable . i'm not sure what to do with such things that javascript doesn't like

// {expr,} = void
// {expr} = expr
// [1,,1] = [1 void 1]
// [1,1] = [1 1] = [1 1,] = [1 1]
// [1 1,,] = [1 1 void]
// [,1 1] = [void 1 1]

// try compiling an empty file

// todo: [for] generator expression, non-lazy
// todo: (for) generator expression, lazy
// todo: {for} generator expression, set
// todo: {: for} generator expression, object
// todo?: v{} call
// todo: either (replace Ca with [] and [] with [__array__]) or (replace Ca with ())
// todo: curry can be max.(1) and indexer function can be list.[]

// todo: r ← [1 2 3]; r[1:2] ←! [5 5]; r = [1 5 5 3]
// todo: more meanings of ?

// later
// ` ~ ~@
//	tight					…++	…--
//	prefix					+…	bit~…
//	bitwise					bit|	bit^	bit&	bit>>>	bit>>	bit<<
//	assignment				+=	-=	*=	/=	&=	|=	bit<<=	bit>>=	bit>>>=	bit&=	bit^=	bit|=
//	statement				delete …	yield …

// derp, if ~/ is regex ~" should be too

// ¬in has to be a reader macro too ...

// fix the shit where all the functions are named λ

// actually yeah, → operator

// yeah, just have a bit() or bit{} anyfix namespace that provides ~ | ^ & >>> >> << ~= |= ^= &= >>>= >>= <<=

// i am starting to worry that we may have failed enormously by not studying perl

// i'm waffling between operator-floats and lexer-floats

// _want_ syntax log₂n

//===---------------===// probably shit; try to discard //===--------------===//
/*
def_group ← λ(a,b){}
def_precedence ← λ(value,associativity,name){}
def_operators ← λ(precedence,operators){
	def_precedence.apply(null,precedence)
	operators.map(λ(op){

	}) }

;[	['13 → group		\\[…*\\] (…*) {…*} ‹…*›'],
	['12 ← lex-like		/\\d+/\\./\\d+/ ; λ…*<→{> new/.+/'],
	['11 ← tight		\\[ ( { ‹ .\\.. .−\\[ .−( '+subscript_ops.map(λ{'.−'+v}).join(' ')],
	['10 → prefix		¬−. ↔-−.'],
	['9  ← mul			.*. .\\/. .%.'],
	['8  ← add			.+. .-.'],
	['7  ← bitwise		'],
	['6  ← cmp 			.isa. .in. .¬in.'],
	['5  → cmp-chained	.=. .≠. .\\<. .\\>. .≤. .≥.'],
	['4  ← logical		.&. .|.'],
	['3  → if-infix		.?.:.'],
	['2  → statement	.←. .←!. .+=. λ.. if.:?.,?[else.]? while.:?. return.? try.,?[catch.,?]?[finally.]?'],
	['1  → quote		`. ~. ~@.'],
	['0  ← separator	, :']
	].map(λ(v){t ← v.split(~/\t+/); def_operators(t₀.split(/ +/),t₁.split(' '))})

precedences ← {}*/

/*
open_eval ← λ{operators_expand(open_macro_eval(groups_expand(v)))}

groups ← {'(':')','[':']','{':'}','‹':'›'}
open_macros ← {}
operators ← {}
open_macros_set ← λ
operators_add ← λ

groups_expand ← λ(g){r ← group_expand(S('{'),g.concat([S('}')])); if (¬r₁.no) err(); return r₀}
	group_expand ← λ(g,l){
		check ← λ(){if (l.no) err('group is not closed @'+g.line)}
		check()
		r ← [g]; while(true){
			if (se(l₀,groups[g.v])) return [r,l[1:]]
			if (l₀ isa Symbol && own(groups,l₀.v)) {t ← group_expand(l₀,l[1:]); r.push(t₀); l ←! t₁; check(); continue}
			r.push(l₀); l ←! l[1:]; check()}}

open_macro_eval ← λ(v){

}

operators_expand ← λ(v){

}

open_macros_set('λ',λ(forms,sym,tokens){

})
open_macros_set('−.−',λ(forms,sym,tokens){return s_int(forms₋₁) && s_int(tokens₀)? [forms[: -1].concat([s_mk_float(forms₋₁,tokens₀)]),tokens[1:]] : [forms.concat([sym]),tokens]})

anyfix_macros_set('.', λ(forms,sym,tokens){return [forms[: -1].concat([[sym,forms₋₁||err('bad .',forms₋₁,tokens),tokens₀]]),tokens[1:]]})
anyfix_macros_set([';',','], λ(forms,sym,tokens){return [forms,tokens]})
anyfix_macros_set(unicode.subscripts.concat(unicode.subscripts.map(λ{'₋'+v})),
	λ(forms,sym,tokens){return [forms[: -1].concat([[S('__sub__'),forms₋₁,sym.with_v(unicode.midscript(sym.v))]]),tokens]})
anyfix_macros_set('λ', λ(forms,sym,tokens){
	// don't require () ?
	if (tokens₀ isa Array && tokens₀₀.v = '(') {
		p ← tokens₀[1:].filter(λ{¬se(v,',')}); tokens ← tokens[1:]
		// may disrespect precedence
		t ← anyfix_macro_eval_p1([],tokens); b ← t₀₀; tokens ← t₁; if (t₀.length ≠ 1) err('bad λ')
		return [forms.concat([[sym,p,b]]),tokens] }
	else if (tokens₀ isa Array && tokens₀₀.v = '{') {
		p ← [S('v'),S('b'),S('c')]
		// may disrespect precedence
		tokens₀₀.v ←! '(' //! gah
		t ← anyfix_macro_eval_p1([],tokens); b ← t₀₀; tokens ← t₁; if (t₀.length ≠ 1) err('bad λ')
		return [forms.concat([[sym,p, [S('return')].concat([b])]]),tokens] }
	else return [forms.concat([sym]),tokens] })

--- phase macro ---
group			[] () {} ‹›
special			λ .
--- phase evaluated ---
← tight			[ ( { ‹ ….… …−[ …−( …₀ᵢ // …++ …--
← new			new…
→ prefix		¬−… ↔-−… // ↔+−…
← mul			…*… …/… …%… // % is temporary
← add			…+… …-…
← bitwise
← cmp 			…isa… …in… …¬in…
s cmp-chained	…=… …≠… …<… …>… …≤… …≥…
← logical		…&… …|… // maybe && || and or ?
→ if-infix		…?…:…
→ assignment	…←… …←!… …+=… // temporary hacks, bah -= *= /= &= |=
? separator		…;… …,…
s ?				λ… if…[:]…[else…] while…[:]… return[…] try…[catch…][finally…] // maybe throw ?

groups ← {'(':')','[':']','{':'}','‹':'›'}
group ← λ(g){
	group ← λ(g,l){
		check ← λ(){if (l.no) err('group is not closed @'+g.line)}
		check()
		r ← [g]; while(true){
			if (se(l₀,groups[g.v])) return [r,l[1:]]
			if (l₀ isa Symbol && own(groups,l₀.v)) {t ← group(l₀,l[1:]); r.push(t₀); l ←! t₁; check(); continue}
			r.push(l₀); l ←! l[1:]; check()}}
	r ← group(S('{'),g.concat([S('}')])); if (¬r₁.no) err(); return r₀}

open_macro_eval ← λ{anyfix_macro_eval(group(v))}


anyfix_macros ← {}; anyfix_macros_set ← λ(ss,f){(ss isa Array? ss : [ss]).map(λ(s){symbol_set_decode(s).map(λ(s){
	v ← s.v; s ← s.space
	if (¬is(f)) {if (own(anyfix_macros,v)) {delete(anyfix_macros[v][s]); if (Object.keys(anyfix_macros[v]).no) delete(anyfix_macros[v])}}
	else {if (¬own(anyfix_macros,v)) {anyfix_macros[v] ←! {}} anyfix_macros[v][s] ←! f}
	}) }) }

anyfix_macro_eval ← λ(token){t ← anyfix_macro_eval_form([], [token]); if (¬(t₁.no && t₂.no)) err(); return t₀}
anyfix_macro_eval_l ← λ(tokens){r ← []; while (¬tokens.no) {t ← anyfix_macro_eval_1(r,tokens); r ←! t₀; tokens ←! t₁} return r}
anyfix_macro_eval_form ← λ(buf,tokens,dont){while (¬(buf.length>1 || tokens.no || (¬buf.no && dont && dont(tokens)))) {t ← anyfix_macro_eval_1(buf,tokens); buf ←! t₀; tokens ←! t₁} return [buf₀,buf[1:],tokens]}
anyfix_macro_eval_1 ← λ(forms,tokens){
	v ← tokens₀; tokens ←! tokens[1:]
	if (v isa Array) {t ← ((anyfix_macros[v₀.v]||err(v₀))[v₀.space]||err(v₀,v₀.space))(forms,v₀, [v[1:]].concat(tokens)); forms ←! t₀; tokens ←! t₁}
	else if (v isa Symbol && own(anyfix_macros,v.v) && anyfix_macros[v.v][v.space]) {t ← anyfix_macros[v.v][v.space](forms,v,tokens); forms ←! t₀; tokens ←! t₁}
	else forms.push(v)
	return [forms,tokens]}

anyfix_macro_eval_p1 ← λ(forms,tokens){l ← forms.length; while (¬tokens.no && forms.length < l+1) {t ← anyfix_macro_eval_1(forms,tokens); forms ←! t₀; tokens ←! t₁} return [forms,tokens]}

; (λ(){
	vector ← λ(forms,sym,tokens){tokens₀ ←! anyfix_macro_eval_l(tokens₀); return [forms.concat([(has_sym(tokens₀,':')? [S('__sliceλ__')].concat(split_slice(tokens₀)) :
		[sym.with_v('__array__')].concat(tokens₀))]),tokens[1:]]}
	block ← λ(forms,sym,tokens){return [forms.concat([[S('__do__')].concat(tokens₀)]),tokens[1:]]}
anyfix_macros_set('[', vector)
anyfix_macros_set('−[', λ(forms,sym,tokens){return forms.no? vector([],sym,tokens) : [
	forms[: -1].concat(
		has_sym((tokens₀ ←! anyfix_macro_eval_l(tokens₀)),':')?
			[[S('__slice__'),forms₋₁].concat(split_slice(tokens₀))] :
			[[S('__sub__'),forms₋₁].concat(tokens₀)]
			),tokens[1:]]})
anyfix_macros_set('(',block)
anyfix_macros_set('−(', λ(forms,sym,tokens){return forms.no? block([],sym,tokens) : [forms[: -1].concat([[forms₋₁].concat(anyfix_macro_eval_l(tokens₀))]),tokens[1:]]})
})()
anyfix_macros_set('{', λ(forms,sym,tokens){
	r←undefined
	starts_like_dict ← λ{(v₀ isa Symbol || typeof(v₀)='string') && se(v₁,':')}
	if (starts_like_dict(tokens₀)) {
		r ←! {}; buf ← []; tokens_ ← tokens₀
		while (¬tokens_.no) {if (¬starts_like_dict(tokens_)) {err(tokens_)} t ← anyfix_macro_eval_form(buf,tokens_[2:],starts_like_dict); r[tokens_₀.v||tokens_₀] ←! t₀; buf ←! t₁; tokens_ ← t₂}
		r ←! [r].concat(buf)
		}
	else r ←! [[S('__do__s')].concat(anyfix_macro_eval_l(tokens₀))]
	return [forms.concat(r),tokens[1:]] })
anyfix_macros_set('‹', λ(forms,sym,tokens){err('‹› not implemented')})
anyfix_macros_set('.', λ(forms,sym,tokens){return [forms[: -1].concat([[sym,forms₋₁||err('bad .',forms₋₁,tokens),tokens₀]]),tokens[1:]]})
anyfix_macros_set([';',','], λ(forms,sym,tokens){return [forms,tokens]})
anyfix_macros_set(unicode.subscripts.concat(unicode.subscripts.map(λ{'₋'+v})),
	λ(forms,sym,tokens){return [forms[: -1].concat([[S('__sub__'),forms₋₁,sym.with_v(unicode.midscript(sym.v))]]),tokens]})
anyfix_macros_set('λ', λ(forms,sym,tokens){
	// don't require () ?
	if (tokens₀ isa Array && tokens₀₀.v = '(') {
		p ← tokens₀[1:].filter(λ{¬se(v,',')}); tokens ← tokens[1:]
		// may disrespect precedence
		t ← anyfix_macro_eval_p1([],tokens); b ← t₀₀; tokens ← t₁; if (t₀.length ≠ 1) err('bad λ')
		return [forms.concat([[sym,p,b]]),tokens] }
	else if (tokens₀ isa Array && tokens₀₀.v = '{') {
		p ← [S('v'),S('b'),S('c')]
		// may disrespect precedence
		tokens₀₀.v ←! '(' //! gah
		t ← anyfix_macro_eval_p1([],tokens); b ← t₀₀; tokens ← t₁; if (t₀.length ≠ 1) err('bad λ')
		return [forms.concat([[sym,p, [S('return')].concat([b])]]),tokens] }
	else return [forms.concat([sym]),tokens] })
anyfix_macros_gen ← λ(v,to){
	// this is horrifying and needs a good refactoring
	parse ← λ{v.match(~/(\[.*?\])|[^[\]]+/g).map(λ{v₀='['? [parse(v[1: -1])] : v.trim().split(' ')}).m_concat().filter(λ{v ≠ ''})}
	t ← parse(v); first ← t₀='…'; t ← first?t[1:]:t; n ← t₀; vs ← t[1:]
	anyfix_macros_set(n,λ(forms,sym,tokens){
		buf ← []
		r ← [to? sym.with_v(to) : sym]; if (first) r.push(is(forms₋₁)?forms₋₁:err())
		vs.map(λ(v,i){
			if (v='…') {
				dont ← vs[i+1] isa Array && vs[i+1]₀ ≠ '…'? vs[i+1]₀ : undefined
				t ← anyfix_macro_eval_form(buf,tokens,λ{se(v₀,dont)}); r.push(t₀); buf ←! t₁; tokens ←! t₂}
			else if (v isa Array) {
				tokens_ ← tokens
				buf_ ← buf
				r_ ← []
				vs_ ← v
				if (vs_.every(λ(v){
						if (v='…') {
							dont ← vs_[i+1] isa Array && vs_[i+1]₀ ≠ '…'? vs_[i+1]₀ : undefined
							t ← anyfix_macro_eval_form(buf_,tokens_,λ{se(v₀,dont)}); r_.push(t₀); buf_ ←! t₁; tokens_ ←! t₂}
						else {
							if (buf_.no && se(tokens_₀,v))
								tokens_ ←! tokens_[1:]
							else return false
						}
						return true
					})) {
					tokens ←! tokens_
					r ←! r.concat(r_)
					buf ←! buf_
				}
			}
			else err('|'+v+'|')
		})
		return [(first?forms[: -1]:forms).concat([r],buf),tokens]
	}) }
anyfix_macros_gen('if … [:] … [else …]','if_s')
anyfix_macros_gen('… ? … [:] …','if')
anyfix_macros_gen('while … [:] …')
anyfix_macros_gen('return […]') // !!
anyfix_macros_gen('throw …')
anyfix_macros_gen('try … [catch …] [finally …]') // !!
anyfix_macros_gen('new …')
anyfix_macros_gen('¬− …')
anyfix_macros_gen('… isa …')
anyfix_macros_gen('… in …')
anyfix_macros_gen('… ¬in …')
anyfix_macros_gen('… * …')
anyfix_macros_gen('… / …')
anyfix_macros_gen('… % …') //-
anyfix_macros_gen('… + …')
anyfix_macros_gen('… - …')
anyfix_macros_gen('↔-− …') // !!
anyfix_macros_gen('… = …')
anyfix_macros_gen('… ≠ …')
anyfix_macros_gen('… < …')
anyfix_macros_gen('… > …')
anyfix_macros_gen('… ≤ …')
anyfix_macros_gen('… ≥ …')
anyfix_macros_gen('… & …'); anyfix_macros_gen('… && …') //-
anyfix_macros_gen('… | …'); anyfix_macros_gen('… || …') //-
anyfix_macros_gen('… ← …')
anyfix_macros_gen('… ←! …')
anyfix_macros_gen('… += …')
*/