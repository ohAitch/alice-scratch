#!/usr/bin/env node
//"use strict"

fs ← require('fs')

minimist ← require('minimist')
sync ← require('sync')
_ ← require('underscore')

//__sub__ ← λ{__get__(v,b)}
__slice__ ← λ(v,a,b){return is(b)? v.slice(a,b) : v.slice(a)}
__sliceλ__ ← λ(a,b){return is(b)? λ{v[a:b]} : λ{v[a:]}}

print ← console.log.bind(console)
running_as ← process.argv₁.match(~/[^\/]*\/[^\/]*$/)₀
print('--- running as:',running_as,'---')

//===---------------------------===// utils //===--------------------------===//

seq ← λ{v isa Array? v : typeof(v)='string'? v.split('') : Object.keys(v).map(λ(k){return [k,vₖ]})}
Array.prototype.object ←! λ{this.reduce(λ(r,v){r[v₀] ←! v₁; return r},{})}
memoize_o ← λ(o,f){return λ(v){r ← own(o,v); return is(r)? r : (oᵥ ←! f(v))}}
merge_o ← λ{$args.map(λ{seq(v)}).m_concat().object()}
object_by ← λ(v,f){return seq(v).map(λ{[f(v),v]}).object()}

pad_left ← λ(v,s,l){return s.repeat(l-v.length)+v}
hex ← λ(v,l){return pad_left(v.toString(16),'0',l)}
now ← λ{Date.now() / 1000}
ord ← λ{v.charCodeAt(0)}
chr ← λ{String.fromCharCode(v)}
own ← λ(o,m){return Object.prototype.hasOwnProperty.call(o,m)? oₘ : undefined}
err ← λ(){print.apply(console, ['#error#:'].concat($args)); throw(Error())}
extend_function ← λ(f){r ← λ(){r ← f(); r.__proto__ ←! λ.prototype; return r}; r.prototype.__proto__ ←! Function.prototype; return r}
delset ← λ(o,m,v){if (¬is(v)) delete(oₘ); else oₘ ←! v}
is ← λ{v≠undefined}
i ← λ{parseInt(v)}
//float_next_after  ← λ(v){r ← v=0?  1e-300 : v<0? v*0.9999999999999995 : v*1.0000000000000005; if (r=v) err(v); return r} // hack
//float_next_before ← λ(v){r ← v=0? -1e-300 : v<0? v*1.0000000000000005 : v*0.9999999999999995; if (r=v) err(v); return r} // hack
String.prototype.repeat ←! λ{v≤0? '' : new Array(v+1).join(this)}
Array.prototype.m_concat ←! λ{Array.prototype.concat.apply([],this)}
Object.defineProperty(Array.prototype,'no',{get:λ{this.length=0}})
genex_2a ← λ(re){return _.range(2).map(λ{[128,128].slice(v).map(λ{_.range(v).map(λ{String.fromCharCode(v)})}).cartesian().map(λ{v.join('')})}).m_concat().filter(λ{v.match(re)})}
Array.prototype.cartesian ←! λ{this.reduce(λ(a,v){r ← []; a.map(λ(a){seq(v).map(λ(b){r.push(a.concat([b]))})}); return r}, [[]])}
oed ← λ(o,v){Object.keys(v).map(λ(k){oₖ ←! vₖ}); return o}

//===-------------------------===// reader_or //===------------------------===//

reader_or ← extend_function(λ{λ(start,s,line){return (λ[s₀]? λ[s₀](start+s₀,s[1:],line) : undefined) || (λ['']? λ[''](start,s,line) : undefined)}})
reader_or.prototype.get ←! λ(s){return this[s₀]? (this[s₀] isa reader_or? this[s₀].get(s[1:]) : this[s₀]) : undefined}
reader_or.prototype.set ←! λ(ss,r){
	seq(ss).map(λ(s){
		c ← s=''? '' : s₀; s ← s[1:]
		if (s ≠ '') (this[c] isa reader_or? this[c] : this[c] ←! new reader_or().set([''],own(this,c))).set([s],r)
		else delset(this,c,r)
	}.bind(this)); return this}
reader_or.prototype.reduce_l ←! λ(s){r ← []; line ← 1; while (s ≠ '') {t ← this('',s,line); r.push(t₀); s ←! t₁; line ←! t₂} return r}
reader_or.prototype.reduce   ←! λ(s){r ← [];           while (s ≠ '') {t ← this('',s     ); r.push(t₀); s ←! t₁            } return r}

//===------------------------===// characters //===------------------------===//

js_valid_symbol ← new (λ(){
	//! _short
	_short ← [' _'].concat("!1 #3 %5 &7 (9 )0 *8 +p ,C -m .d /s :c =E ?q @2 [L 'b ^6 `k {B |o ~t …r ←w →e ¬n ∀A ≠N ǂǂ <lt ≤le >gt ≥ge".split(' ')).map(λ{[v₀,v[1:]]})
	encode_short ← _short.map(λ{[v₀,'ǂ'+v₁]}).object()
	decode_short ← _short.map(λ{[v₁,v₀]}).object()
	is_start ← memoize_o(seq(';ǂ \t\n\x0b\x0c\x0d').map(λ{[v,false]}).object(),λ(v){try {eval('var '+v )} catch (e) {return false} return true})
	is_part  ← memoize_o(seq(';ǂ \t\n\x0b\x0c\x0d').map(λ{[v,false]}).object(),λ(v){try {eval('var a'+v)} catch (e) {return false} return true})
	encode_char ← memoize_o(encode_short, λ(v){return is_part(v)? v : 'ǂu'+hex(ord(v),4)})

	keywords ← ['break','do','instanceof','typeof','case','else','new','var','catch','finally','return','void','continue','for','switch','while','debugger','function','this','with','default','if','throw','delete','in','try','class','enum','extends','super','const','export','import','implements','let','private','public','yield','interface','package','protected','static']

	decoder ← new reader_or()
	decoder.set([''],λ(_,s){return [s₀,s[1:]]})
	decoder.set(['ǂu'],λ(_,s){return [chr(parseInt(s[:4],16)),s[4:]]})
	seq(decode_short).map(λ(kv){k ← kv₀; v ← kv₁; decoder.set(['ǂ'+k],λ(_,s){return [v,s]})})

	this.is_part ←! is_part
	this.encode ←! memoize_o(keywords.map(λ{[v,'ǂ'+v]}).object(),λ(v){r ← seq(v).map(encode_char).join(''); return (¬is_start(r₀)?'ǂ':'')+r})
	this.decode ←! memoize_o(keywords.map(λ{['ǂ'+v,v]}).object(),λ{decoder.reduce(v₀='ǂ'? v[1:] : v).join('')})
	})
unicode ← λ(table){return {
	subscripts:   table.map(λ{v₀}).filter(λ{v≠'_'}),
	midscripts:   table.map(λ{v₁}),
	superscripts: table.map(λ{v₂}).filter(λ{v≠'_'}),
	subscript:   λ{table.map(λ{[[v₁,v₀], [v₂,v₀]]}).m_concat().filter(λ{v₁≠'_'}).object()[v]},
	midscript:   λ{table.map(λ{[[v₀,v₁], [v₂,v₁]]}).m_concat().filter(λ{v₁≠'_'}).object()[v]},
	superscript: λ{table.map(λ{[[v₀,v₂], [v₁,v₂]]}).m_concat().filter(λ{v₁≠'_'}).object()[v]}
	}}('₀0⁰ ₁1¹ ₂2² ₃3³ ₄4⁴ ₅5⁵ ₆6⁶ ₇7⁷ ₈8⁸ ₉9⁹ ₊+⁺ ₋-⁻ ₌=⁼ ₍(⁽ ₎)⁾ ₐaᵃ _bᵇ _cᶜ _dᵈ ₑeᵉ _fᶠ _gᵍ ₕhʰ ᵢiⁱ ⱼjʲ ₖkᵏ ₗlˡ ₘmᵐ ₙnⁿ ₒoᵒ ₚpᵖ ᵣrʳ ₛsˢ ₜtᵗ ᵤuᵘ ᵥvᵛ _wʷ ₓxˣ _yʸ _zᶻ _Aᴬ _Bᴮ _Dᴰ _Eᴱ _Gᴳ _Hᴴ _Iᴵ _Jᴶ _Kᴷ _Lᴸ _Mᴹ _Nᴺ _Oᴼ _Pᴾ _Rᴿ _Tᵀ _Uᵁ _Vⱽ _Wᵂ'.split(' '))

//===--------------------------===// Symbol //===--------------------------===//

Symbol ← λ(name,space,line){this.name ←! name; this.space ←! space; if (line) this.line ←! line}
Object.defineProperty(Symbol.prototype,'space_before',{get:λ{this.space₀='␣'},set:λ(v){this.space ←! (v?'␣':'₋')+this.space₁}})
Object.defineProperty(Symbol.prototype,'space_after', {get:λ{this.space₁='␣'},set:λ(v){this.space ←! this.space₀+(v?'␣':'₋')}})
Symbol.prototype.toString ←! Symbol.prototype.inspect ←! λ{'`'+this.space₀+this.name+this.space₁}
Symbol.prototype.with_name ←! λ{new Symbol(v,this.space,this.line)}
S ← λ{new Symbol(v,'₋₋',b)}
/*symbol_set_decode ← λ(v){
	t ← v.match(~/^([₋␣])?(.+?)([₋␣])?$/); s ← (t₁||'?')+(t₃||'?'); n ← t₂
	return (symbol_set_table[s]||err('bad symbol set',s)).map(λ(v){r ← new Symbol(n); r.space ←! v; return r})}
	symbol_set_table ← {
		'₋₋':['$'],
		'₋␣':['$_'],
		'␣₋':['_$'],
		'␣␣':['_$_'],
		'?₋':['$','_$'],
		'?␣':['$_','_$_'],
		'₋?':['$','$_'],
		'␣?':['_$','_$_'],
		'??':['$','$_','_$','_$_']
		}*/
SP ← {}
se ← λ{v isa Symbol && v.name=b} // hack
//s_int ← λ{v isa Symbol && v.v.match(~/^[0-9]+$/)} // hack
//s_mk_float ← λ{new Symbol(v.v+'.'+b.v,v.line,v.space)} // hack

//===---------------------===// load.α hack utils //===--------------------===//

split_symbol ← λ(l,s){r ← [[]]; l.map(λ(v){if (se(v,s)) r.push([]); else r₋₁.push(v)}); return r}
has_sym ← λ(v,s){return v.some(λ{se(v,s)})}
split_slice ← λ(l){r ← split_symbol(l,':'); r ← [[(is(r₀₀)? r₀₀ : S('0'))]].concat(r[1:]).m_concat(); return r}
pr ← λ(){if (running_as = 'bin/load.js') print.apply(this,['##'].concat($args)); return $args₀}
printable ← λ{λᵥ}

//===---------------------------===// repr //===---------------------------===//

String.prototype.repr_js ←! λ(){v ← this.valueOf(); return (v.match(~/'/g)||[]).length ≤ (v.match(~/"/g)||[]).length? //?
	"'"+seq(v).map(λ{{"'":"\\'",'\n':'\\n','\t':'\\t','\\':'\\\\'}ᵥ || (printable(v)? v : '\\u'+hex(ord(v),4))}).join('')+"'" :
	'"'+seq(v).map(λ{{'"':'\\"','\n':'\\n','\t':'\\t','\\':'\\\\'}ᵥ || (printable(v)? v : '\\u'+hex(ord(v),4))}).join('')+'"'}
RegExp.prototype.repr_js ←! λ{this+''}
String.prototype.repr ←! String.prototype.repr_js
RegExp.prototype.repr ←! λ{'~'+this+''}
/*repr_js_trans_infix ← merge_o({'&':'&&','|':'||','isa':'instanceof','=':'===','≠':'!==','≤':'<=','≥':'>='},object_by('. * / % + - < > in && || +='.split(' '),λ{v}))
repr_js ← λ(v,line){rj ← λ{repr_js(v,line)}; mrj ← λ{v.map(rj).join(b||'')}; ln ← λ{(v && v.line && line? '\n'.repeat(λ(v){line₀ += v; return v}(Math.max(0, v.line-line₀))) : '')}
	return ¬is(v)? pr('<gah>',line₀) :
		v.repr_js? v.repr_js(line) :
		v isa Symbol? ln(v) + (v.space_before?' ':'') + (v.v='/'?'÷':v.v='$args'?'Array.prototype.slice.apply(arguments)':v.v) + (v.space_after?' ':'') :
		v isa Array?
			v.no? '()' :
				v₀ isa Symbol? ln(v₀) + (
					v₀.v='__literal__'? v₁+'' :
					//v₀.v='__do__'? v.length=2? rj(v₁) : '{'+mrj(v[1:],';')+'}' :
					v₀.v='__do__e'? '('+rj(v₁)+')' :
					v₀.v='__do__s'? '{'+mrj(v[1:],';')+'}' :
					v₀.v='__get__'? '('+rj(v₁)+'['+rj(v₂)+'])' :
					v₀.v='__sub__'? '('+rj(v₁)+'['+rj(v₂)+'])' :
					v₀.v='__array__'? '['+mrj(v[1:],',')+']' :
					v₀.v='←'? 'var '+rj(v₁)+' = '+rj(v₂) :
					v₀.v='←!'? '('+rj(v₁)+' = '+rj(v₂)+')' :
					v₀.v='¬'? '(!'+rj(v₁)+')' :
					v₀.v='new'? 'new '+rj(v₁).replace(~/^\((.*)\)$/,'$1') :
					v₀.v='return'? 'return '+rj(v₁) : // should be return(…) or return
					v₀.v='throw'? 'throw '+rj(v₁) :
					v₀.v='delete'? 'delete '+rj(v₁) :
					v₀.v='while'? 'while('+rj(v₁)+'){'+rj(v₂)+'}' :
					v₀.v='try'? 'try{'+rj(v₁)+'}catch(e){'+rj(v₂)+'}' :
					v₀.v='λ'? 'function λ('+mrj(v₁,',')+'){'+rj(v₂)+'}' :
					v₀.v='if'? '('+rj(v₁)+'?'+rj(v₂)+':'+rj(v₃)+')' :
					v₀.v='if_s'? 'if('+rj(v₁)+'){'+rj(v₂)+'}'+(¬is(v₃)?'':'else{'+rj(v₃)+'}') :
					v₀.v='-' && v.length=2? '(-('+rj(v₁)+'))' :
					own(repr_js_trans_infix,v₀.v)? '('+rj(v₁)+repr_js_trans_infix[v₀.v]+rj(v₂)+')'  :
						'('+rj(v₀)+'('+mrj(v[1:],',')+'))' ) :
					rj(v₀)+'('+mrj(v[1:],',')+')' :
		typeof(v)='object'? '{'+Object.keys(v).map(λ(k){return rj(k)+':'+rj(vₖ)}).join(',')+'}' :
			'<what:'+v+'>'}
repr_js_file ← λ(form){return repr_js(form, [1])[1: -1].replace(~/ +/mg,' ').replace(~/^ /mg,'').replace(~/;$/m,'')}*/

//===------------------===// reader macros (lexing) //===------------------===//

tokenize ← λ(s){
	t←undefined; r ← [].concat([SP],((t ←! s.match(~/^#!.*/))? [S('__literal__'),S('('),t₀,S(')'),SP] : []),reader_macros.reduce_l(t? s[t₀.length:] : s),[SP])
	i←1; while (i<r.length-1) {if (rᵢ isa Symbol) rᵢ.space ←! (r[i-1]=SP?'␣':'₋')+(r[i+1]=SP?'␣':'₋'); i+=1}
	return r.filter(λ{v ≠ SP})}

subscript_ops ← genex_2a(~/^-?[0-9a-z]$/).map(λ{seq(v).map(unicode.subscript)}).filter(λ{v.every(λ{v})}).map(λ{v.join('')})

reader_macros ← new reader_or()
reader_macros.set([''], λ(_,s,l){
	first_type ← js_valid_symbol.is_part(s₀)
	r ← ''; while (s ≠ '' && (s.match(~/^[0-9]/) || ¬reader_macros.get(s)) && js_valid_symbol.is_part(s₀) = first_type) {r += s₀; s ←! s[1:]}
	return [S(r,l),s,l]})
reader_macros.set('0123456789', λ(_,s,l){t ← s.match(~/^[0-9]*\.[0-9]*(?:[eE][+-]?[0-9]+)?/); return t? [S(_+t₀,l),s[t₀.length:],l] : undefined})
reader_macros.set(['.'],λ(_,s,l){t ← s.match(~/^[0-9]+(?:[eE][+-]?[0-9]+)?/); return [S(t?_+t₀:_,l),t?s[t₀.length:]:s,l]})
reader_macros.set([].concat(seq('()[]{}‹›`~?:,;'), ['~@','¬in'],subscript_ops), λ(_,s,l){return [S(_,l),s,l]})
reader_macros.set(' \t\x0c\x0d', λ(_,s,l){return [SP,s,l]})
reader_macros.set('\n', λ(_,s,l){return [SP,s,l+1]})
reader_macros.set(['//'], λ(_,s,l){return [SP,s.replace(~/^.*/,''),l]})
reader_macros.set(['/*'], λ(_,s,l){t ← s.match(~/^[^]*?(\*\/|$)/)₀; return [SP,s[t.length:],l+(t.match(~/\n/g)||[]).length]})
reader_macros.set('\'"', λ(start,s,line){
	t ← s.match(start='"'? ~/^((?:(?:.*[^\\])?(?:\\\\)*)?)"/ : ~/^((?:(?:.*[^\\])?(?:\\\\)*)?)'/) || err('string is not closed @'+line); s ←! s[t₀.length:]; v ← t₁
	return [v.match(~/\\u[0-9a-fA-F]{4}|\\x[0-9a-fA-F]{2}|\\[nt'"\\]|./g).map(λ(v){
		if (v='\n') line += 1; return {"\\'":"'",'\\"':'"','\\\\':'\\','\\n':'\n','\\t':'\t'}ᵥ || (v.length>2? chr(parseInt(v[2:],16)) : v)
		}).join(''),s,line]})
reader_macros.set(['~/'], λ(start,s,line){t ← (s.match(~/^((?:[^\/\\\[]|(?:\\.)|\[(?:[^\\\]]|(?:\\.))*\])*\/[a-z]*)/) || err('could not match regex: '+start+s[:10]))₁; return [eval('/'+t),s[t.length:],line]})

//===----------===// special token macros (deliberate hack) //===----------===//

//documentation from precedence\ table.txt
	//regime breakers:
	//\[…*\] (…*) {…*}
	//λ
	//new
	//; && ||
	//\[ ( {

special_expand ← λ(tokens){
	tokens.map(λ(v){if (v isa Symbol) v.name ←! aliases[v.name] || v.name})
	groups_expand ← λ(tokens){r ← group_expand(S('{'),tokens.concat([S('}')])); if (¬r₁.no) err(r); return r₀}
		group_expand ← λ(g,l){
			check ← λ(){if (l.no) err('group is not closed @'+g.line)}
			check()
			r ← [g]; while(true){
				if (se(l₀,groups[g.name])) return [r,l[1:]]
				if (l₀ isa Symbol && own(groups,l₀.name)) {t ← group_expand(l₀,l[1:]); r.push(t₀); l ←! t₁; check(); continue}
				r.push(l₀); l ←! l[1:]; check()}}
	tokens ←! groups_expand(tokens)
	walk ← λ(v,f){return (λ(v,i,l,f){
		if (v isa Array) {for (j←0;j<v.length;) j ←! (λ)(v[j],j,v,f); return i+1}
		else return f(v,i,l) })(v,0,undefined,f)}
	walk(tokens,λ(v,i,l){
		if (se(v,'new') && l[i+1] isa Symbol) {l.splice(i,2,[v,[new Symbol('__QUOTE__','␣␣'),l[i+1]]]); return i+1}
		else if (se(v,'λ') && l[i+1] isa Array && se(l[i+1]₀,'(')) {l.splice(i,2,v,[new Symbol('__QUOTE__','␣␣'),l[i+1]]); return i+2}
		else if (se(v,'λ') && l[i+1] isa Array && se(l[i+1]₀,'{')) {l.splice(i,1,v,[new Symbol('__QUOTE__','␣␣'),S('v')]); return i+2}
		else return i+1 })
	return tokens}

groups ← ['()','[]','{}'].object()
aliases ← {';':',','&&':'&','||':'|'}

//===---------===// "precedence/open/anyfix/operator macros" //===---------===//

operator_expand ← λ(form){
	/*r ← [form₀]
	last ← undefined
	rest ← form[1:]

	if (rest.no) {
		err('a')
	} else if (¬is(last)) {
		if (rest₀ isa Symbol && operators[rest₀]) {
			op ← operators[rest₀]
			if 
		}
	} else {
		err('b')
	}*/
	// [is a last item] [last item is full] [next item is left-wall]: recurse back up to whatever is eating many thing in sequence?
	// [is a last item] [last item is full] [next item is maybe left-wall]: ??? not sure ???
	// [is a last item] [last item is full] [next item is left-eaty]:
	// 	if its left-priority > our right-priority: recurse to next item
	// 	elif its left-priority < our right-priority: recurse upwards
	// 	else: this is that =≠<>≤≥ thingy! or something like it!
	// [is a last item] [last item is full] [next item is void]: why marvelous, just let the above level handle this end
	// [is a last item] [last item is want] [next item is not-an-op]: eat it
	// [is a last item] [last item is want] [next item can be left-wall and have lower priority than us]: recurse to next item!
	// [is a last item] [last item is want] [next item is any other op]: error!
	// [is a last item] [last item is want] [next item is void]: oh no, you don''t get your satisfaction! but this is still not a problem.
	// [void last item] [next item is left-wall]: marvelous, no problem, just do whatever the thing that is eating things says
	// [void last item] [next item is maybe left-wall]: next item is definitely left-wall
	// [void last item] [next item is left-eaty]: oh my well you don''t get to eat anything then! this is not actually a problem. we can just pass you void/undefined.
	// i think we can figure out left-priorities by just going on ahead and recursing to the item. because all of these things are pure! recursing to the item is cheap and stuff.
	// so it might be somewhat hard to figure out just what the priority of possibly even the last item is.
	// yeah. we didn''t solve the "which operator am i even?" problem.
	// alright. let''s leave that there for now and go ahead to implementing this. it looks like we have something actually solid now? i mean ... it''s still kinda just a conceptual prototype. but it looks like a _usable_ one
	return tokens}

// oh fuck we just had -₋. and .₋-₋. trample over each other
// so op_repr includes space information but not wall/eaty information ... oh fuck ...
//! CURRENT: redo things and fix this!

operators ← {} // {op_repr:op}
op_ANY ← {} // object, not a dictionary
def_operators ← λ(prec_l,prec_r,ops){
	symbol_set_split ← λ(v){
		t ← v.match(~/^([₋␣])?(.+?)([₋␣])?$/); p ← [t₁||'?',t₃||'?']; n ← t₂
		return {name:n, spaces:λ{_.zip(p,v).every(λ{v₀='?'||v₀=v₁})}, symbols:λ(){me ← this; return ['₋␣','₋␣'].cartesian().map(λ{v.join('')}).filter(λ(v){return me.spaces(v)}).map(λ{new Symbol(me.name,v)})}}}
	ops.map(λ(op){
		op ←! op.match(~/\[.*?\]|[^\[\]]+/g).map(λ(v){t←0; r ← ((t ←! v₀='[' && v₋₁=']')? v[1:-1] : v).match(~/\.|[^.]+/g); return t?[r]:r}).m_concat()
		op ←! op.map(λ{v isa Array? v.map(λ) : v='.'? op_ANY : v})
		left_eat ← false; if (op₀=op_ANY) {left_eat ←! true; op ←! op[1:]}
		t ← symbol_set_split(op₀); op ←! op[1:]
		;({'__DOT__':['.'], '__SUBSCRIPT__':subscript_ops}[t.name]||[t.name]).map(λ(n){
			op ←! op.map(λ{v isa Array? v.map(λ) : v=op_ANY? v : symbol_set_split(v)})
			r ← {prec_l:prec_l, prec_r:prec_r, left_eat:left_eat, op:oed(t,{name:n}), right:op}
			r.op.symbols().map(λ(v){
				if (operators[v]) pr('okay :c',v,operators[v],r)
				operators[v] ←! r
			})
			}) }) }
;[	'400 401 .__DOT__₋. .₋__SUBSCRIPT__ .₋[ .₋(',
	'390 391 ¬₋. -₋.',
	'380 381 .₋*₋. .₋/₋. .₋%₋.',
	'370 371 .₋+₋. .₋-₋.',
	'350 350 .₋=₋. .₋≠₋. .₋<₋. .₋>₋. .₋≤₋. .₋≥₋.',
	'340 341 .₋&₋. .₋|₋.',
	'331 330 .₋?₋.₋:₋.',
	'321 322 .₋+=₋.',
	'323 320 .₋←₋. .₋←!₋.',
	'300 301 `₋. ~₋. ~@₋.',
	'290 291 ¬␣.',
	'280 281 .␣*␣. .␣/␣. .␣%␣.',
	'270 271 .␣+␣. .␣-␣.',
	'260 260 .␣isa␣.',
	'250 250 .␣=␣. .␣≠␣. .␣<␣. .␣>␣. .␣≤␣. .␣≥␣.',
	'240 241 .␣&␣. .␣|␣.',
	'231 230 .₋?␣.␣:␣.',
	'221 222 .␣+=␣.',
	'223 220 .␣←␣. .␣←!␣.',
	'210 211 λ.. if.[:].[,][else.] while.[:]. return[.] try.[,][catch.][,][finally.]',
	'200 201 `␣. ~␣. ~@␣.',
	'100 100 , :'
	].map(λ(v){t ← v.split(' '); def_operators(i(t₀),i(t₁),t[2:])})

//===--------------------------===// <edge> //===--------------------------===//

read ← λ(s){
	seq(s).map(λ{printableᵥ ←! true})
	// a bit outdated:
	// tokenize: characters are tokenized with λ(rest_characters) → [token,rest_characters]
	// anyfix/open macros: was // anyfix: tokens naming anyfix macros are expanded into forms with λ(previous_forms,symbol,rest_tokens) → [previous_forms,rest_tokens], but they are not allowed to eat more than the last form of previous_forms . these functions may be called multiple times, so they should be pure.
	// ?: forms naming macros are expanded into forms
	// ?: forms are translated into javascript

	r ← operator_expand(special_expand(tokenize(s)))
	//pr(r)
	return r}

compile_f ← λ(_in,out){fs.writeFileSync(out,repr_js_file(read(fs.readFileSync(_in).toString())))}

compile_f(process.argv₂,process.argv₃)

//===---------------------------===// todo //===---------------------------===//

// keep in mind that the basic idea was always just "write a really nice preprocessor" http://publications.gbdirect.co.uk/c_book/chapter7///how_the_preprocessor_works.html

// void could be a macro for undefined, or it could just be another global variable . i'm not sure what to do with such things that javascript doesn't like

// {expr,} = void
// {expr} = expr
// [1,,1] = [1 void 1]
// [1,1] = [1 1] = [1 1,] = [1 1]
// [1 1,,] = [1 1 void]
// [,1 1] = [void 1 1]

// try compiling an empty file

// todo: [for] generator expression, non-lazy
// todo: (for) generator expression, lazy
// todo: {for} generator expression, set
// todo: {: for} generator expression, object
// todo?: v{} call
// todo: either (replace Ca with [] and [] with [__array__]) or (replace Ca with ())
// todo: curry can be max.(1) and indexer function can be list.[]

// todo: r ← [1 2 3]; r[1:2] ←! [5 5]; r = [1 5 5 3]
// todo: more meanings of ?

// later
// ` ~ ~@
//	tight					…++	…--
//	prefix					+…	bit~…
//	bitwise					bit|	bit^	bit&	bit>>>	bit>>	bit<<
//	assignment				+=	-=	*=	/=	&=	|=	bit<<=	bit>>=	bit>>>=	bit&=	bit^=	bit|=
//	statement				delete …	yield …

// derp, if ~/ is regex ~" should be too

// ¬in has to be a reader macro too ...

// fix the shit where all the functions are named λ

// actually yeah, → operator

// yeah, just have a bit() or bit{} anyfix namespace that provides ~ | ^ & >>> >> << ~= |= ^= &= >>>= >>= <<=

// i am starting to worry that we may have failed enormously by not studying perl

// i'm waffling between operator-floats and lexer-floats

// _want_ syntax log₂n

// && || % are probably temporary
// add ++ -- with .₋\[
// add ␣+₋. with ␣-₋.
// add ./\ᵛ+/ with ./₋?\ᵥ/
// add -= *= /= &= |= with +=
// add back .in. .¬in. with isa
// ? bah, throw
// have a place for bitwise ops?
// what about `₋. ? dunno how i feel about that being like it is

/* PRECEDENCE_TABLE.TXT notes

"is there anything i want to push out despite spacing? check from bottom up (top down)"

a, b + 7, 9

maybe ,
if shouldn''t. if is a statement. if _always_ pushes out, except against ,
v+2 * 7

[] _eats_ tokens without giving them any opportunity to bind to anything

// okay, we've let our thoughts on this percolate for a while. let's see if we can write out the operators in a sensible way.

oh!
eating another left-eating op (probably?) doesn''t change the number of things we''re eating, but another non-left-eating op *does*
so the question is: what gets ops interpreted as functions and what gets ops interpreted as macros?

[is a last item] [last item is full] [next item is left-wall]: recurse back up to whatever is eating many thing in sequence?
[is a last item] [last item is full] [next item is maybe left-wall]: ??? not sure ???
[is a last item] [last item is full] [next item is left-eaty]:
	if its left-priority > our right-priority: recurse to next item
	elif its left-priority < our right-priority: recurse upwards
	else: this is that =≠<>≤≥ thingy! or something like it!
[is a last item] [last item is full] [next item is void]: why marvelous, just let the above level handle this end
[is a last item] [last item is want] [next item is not-an-op]: eat it
[is a last item] [last item is want] [next item can be left-wall and have lower priority than us]: recurse to next item!
[is a last item] [last item is want] [next item is any other op]: error!
[is a last item] [last item is want] [next item is void]: oh no, you don''t get your satisfaction! but this is still not a problem.
[void last item] [next item is left-wall]: marvelous, no problem, just do whatever the thing that is eating things says
[void last item] [next item is maybe left-wall]: next item is definitely left-wall
[void last item] [next item is left-eaty]: oh my well you don''t get to eat anything then! this is not actually a problem. we can just pass you void/undefined.
i think we can figure out left-priorities by just going on ahead and recursing to the item. because all of these things are pure! recursing to the item is cheap and stuff.

so it might be somewhat hard to figure out just what the priority of possibly even the last item is.
yeah. we didn''t solve the "which operator am i even?" problem.
alright. let''s leave that there for now and go ahead to implementing this. it looks like we have something actually solid now? i mean ... it''s still kinda just a conceptual prototype. but it looks like a _usable_ one

// add more than minimum? alpha precedence (so, 190 195 instead of 190 191? or just allow floats.)

// it might be worth considering the case of independent libraries.
// "fail-fast" could be adequate

// http://compilers.iecc.com/comparch/article/01-07-068

parse_expression ()
	return parse_expression_1 (parse_primary (), 0)
parse_expression_1 (lhs, min_precedence)
	while the next token is a binary operator whose precedence is >= min_precedence
		op := next token
		rhs := parse_primary ()
		while the next token is a binary operator whose precedence is greater
				 than op''s, or a right-associative operator
				 whose precedence is equal to op''s
			lookahead := next token
			rhs := parse_expression_1 (rhs, lookahead''s precedence)
		lhs := the result of applying op with operands lhs and rhs
	return lhs
Example execution of the algorithm[edit]
An example execution on the expression 2 + 3 * 4 + 5 == 19 is as follows. We give precedence 0 to equality expressions, 1 to additive expressions, 2 to multiplicative expressions.

parse_expression_1 (lhs = 2, min_precedence = 0)

the next token is +, with precedence 1. the while loop is entered.
op is + (precedence 1)
rhs is 3
the next token is *, with precedence 2. recursive invocation.
parse_expression_1 (rhs = 3, min_precedence = 2)
the next token is *, with precedence 2. the while loop is entered.
op is * (precedence 2)
rhs is 4
the next token is +, with precedence 1. no recursive invocation.
lhs is assigned 3*4 = 12
the next token is +, with precedence 1. the while loop is left.
12 is returned.
the next token is +, with precedence 1. no recursive invocation.
lhs is assigned 2+12 = 14
the next token is +, with precedence 1. the while loop is not left.
op is + (precedence 1)
rhs is 5
the next token is ==, with precedence 0. no recursive invocation.
lhs is assigned 14+5 = 19
the next token is ==, with precedence 0. the while loop is not left.
op is == (precedence 0)
rhs is 19
the next token is end-of-line, which is not an operator. no recursive invocation.
lhs is assigned the result of evaluating 19 == 19, for example 1 (as in the C standard).
the next token is end-of-line, which is not an operator. the while loop is left.
1 is returned.
*/
//===---------------===// probably shit; try to discard //===--------------===//
/*
def_group ← λ(a,b){}
def_precedence ← λ(value,associativity,name){}
def_operators ← λ(precedence,operators){
	def_precedence.apply(null,precedence)
	operators.map(λ(op){

	}) }

;[	['13 → group		\\[…*\\] (…*) {…*} ‹…*›'],
	['12 ← lex-like		/\\d+/\\./\\d+/ ; λ…*<→{> new/.+/'],
	['11 ← tight		\\[ ( { ‹ .\\.. .−\\[ .−( '+subscript_ops.map(λ{'.−'+v}).join(' ')],
	['10 → prefix		¬−. ↔-−.'],
	['9  ← mul			.*. .\\/. .%.'],
	['8  ← add			.+. .-.'],
	['7  ← bitwise		'],
	['6  ← cmp 			.isa. .in. .¬in.'],
	['5  → cmp-chained	.=. .≠. .\\<. .\\>. .≤. .≥.'],
	['4  ← logical		.&. .|.'],
	['3  → if-infix		.?.:.'],
	['2  → statement	.←. .←!. .+=. λ.. if.:?.,?[else.]? while.:?. return.? try.,?[catch.,?]?[finally.]?'],
	['1  → quote		`. ~. ~@.'],
	['0  ← separator	, :']
	].map(λ(v){t ← v.split(~/\t+/); def_operators(t₀.split(/ +/),t₁.split(' '))})

precedences ← {}*/

/*
open_eval ← λ{operators_expand(open_macro_eval(groups_expand(v)))}

groups ← {'(':')','[':']','{':'}','‹':'›'}
open_macros ← {}
operators ← {}
open_macros_set ← λ
operators_add ← λ

groups_expand ← λ(g){r ← group_expand(S('{'),g.concat([S('}')])); if (¬r₁.no) err(); return r₀}
	group_expand ← λ(g,l){
		check ← λ(){if (l.no) err('group is not closed @'+g.line)}
		check()
		r ← [g]; while(true){
			if (se(l₀,groups[g.v])) return [r,l[1:]]
			if (l₀ isa Symbol && own(groups,l₀.v)) {t ← group_expand(l₀,l[1:]); r.push(t₀); l ←! t₁; check(); continue}
			r.push(l₀); l ←! l[1:]; check()}}

open_macro_eval ← λ(v){

}

operators_expand ← λ(v){

}

open_macros_set('λ',λ(forms,sym,tokens){

})
open_macros_set('−.−',λ(forms,sym,tokens){return s_int(forms₋₁) && s_int(tokens₀)? [forms[: -1].concat([s_mk_float(forms₋₁,tokens₀)]),tokens[1:]] : [forms.concat([sym]),tokens]})

anyfix_macros_set('.', λ(forms,sym,tokens){return [forms[: -1].concat([[sym,forms₋₁||err('bad .',forms₋₁,tokens),tokens₀]]),tokens[1:]]})
anyfix_macros_set([';',','], λ(forms,sym,tokens){return [forms,tokens]})
anyfix_macros_set(unicode.subscripts.concat(unicode.subscripts.map(λ{'₋'+v})),
	λ(forms,sym,tokens){return [forms[: -1].concat([[S('__sub__'),forms₋₁,sym.with_v(unicode.midscript(sym.v))]]),tokens]})
anyfix_macros_set('λ', λ(forms,sym,tokens){
	// don't require () ?
	if (tokens₀ isa Array && tokens₀₀.v = '(') {
		p ← tokens₀[1:].filter(λ{¬se(v,',')}); tokens ← tokens[1:]
		// may disrespect precedence
		t ← anyfix_macro_eval_p1([],tokens); b ← t₀₀; tokens ← t₁; if (t₀.length ≠ 1) err('bad λ')
		return [forms.concat([[sym,p,b]]),tokens] }
	else if (tokens₀ isa Array && tokens₀₀.v = '{') {
		p ← [S('v'),S('b'),S('c')]
		// may disrespect precedence
		tokens₀₀.v ←! '(' //! gah
		t ← anyfix_macro_eval_p1([],tokens); b ← t₀₀; tokens ← t₁; if (t₀.length ≠ 1) err('bad λ')
		return [forms.concat([[sym,p, [S('return')].concat([b])]]),tokens] }
	else return [forms.concat([sym]),tokens] })

--- phase macro ---
group			[] () {} ‹›
special			λ .
--- phase evaluated ---
← tight			[ ( { ‹ ….… …−[ …−( …₀ᵢ // …++ …--
← new			new…
→ prefix		¬−… ↔-−… // ↔+−…
← mul			…*… …/… …%… // % is temporary
← add			…+… …-…
← bitwise
← cmp 			…isa… …in… …¬in…
s cmp-chained	…=… …≠… …<… …>… …≤… …≥…
← logical		…&… …|… // maybe && || and or ?
→ if-infix		…?…:…
→ assignment	…←… …←!… …+=… // temporary hacks, bah -= *= /= &= |=
? separator		…;… …,…
s ?				λ… if…[:]…[else…] while…[:]… return[…] try…[catch…][finally…] // maybe throw ?

groups ← {'(':')','[':']','{':'}','‹':'›'}
group ← λ(g){
	group ← λ(g,l){
		check ← λ(){if (l.no) err('group is not closed @'+g.line)}
		check()
		r ← [g]; while(true){
			if (se(l₀,groups[g.v])) return [r,l[1:]]
			if (l₀ isa Symbol && own(groups,l₀.v)) {t ← group(l₀,l[1:]); r.push(t₀); l ←! t₁; check(); continue}
			r.push(l₀); l ←! l[1:]; check()}}
	r ← group(S('{'),g.concat([S('}')])); if (¬r₁.no) err(); return r₀}

open_macro_eval ← λ{anyfix_macro_eval(group(v))}


anyfix_macros ← {}; anyfix_macros_set ← λ(ss,f){(ss isa Array? ss : [ss]).map(λ(s){symbol_set_decode(s).map(λ(s){
	v ← s.v; s ← s.space
	if (¬is(f)) {if (own(anyfix_macros,v)) {delete(anyfix_macros[v][s]); if (Object.keys(anyfix_macros[v]).no) delete(anyfix_macros[v])}}
	else {if (¬own(anyfix_macros,v)) {anyfix_macros[v] ←! {}} anyfix_macros[v][s] ←! f}
	}) }) }

anyfix_macro_eval ← λ(token){t ← anyfix_macro_eval_form([], [token]); if (¬(t₁.no && t₂.no)) err(); return t₀}
anyfix_macro_eval_l ← λ(tokens){r ← []; while (¬tokens.no) {t ← anyfix_macro_eval_1(r,tokens); r ←! t₀; tokens ←! t₁} return r}
anyfix_macro_eval_form ← λ(buf,tokens,dont){while (¬(buf.length>1 || tokens.no || (¬buf.no && dont && dont(tokens)))) {t ← anyfix_macro_eval_1(buf,tokens); buf ←! t₀; tokens ←! t₁} return [buf₀,buf[1:],tokens]}
anyfix_macro_eval_1 ← λ(forms,tokens){
	v ← tokens₀; tokens ←! tokens[1:]
	if (v isa Array) {t ← ((anyfix_macros[v₀.v]||err(v₀))[v₀.space]||err(v₀,v₀.space))(forms,v₀, [v[1:]].concat(tokens)); forms ←! t₀; tokens ←! t₁}
	else if (v isa Symbol && own(anyfix_macros,v.v) && anyfix_macros[v.v][v.space]) {t ← anyfix_macros[v.v][v.space](forms,v,tokens); forms ←! t₀; tokens ←! t₁}
	else forms.push(v)
	return [forms,tokens]}

anyfix_macro_eval_p1 ← λ(forms,tokens){l ← forms.length; while (¬tokens.no && forms.length < l+1) {t ← anyfix_macro_eval_1(forms,tokens); forms ←! t₀; tokens ←! t₁} return [forms,tokens]}

; (λ(){
	vector ← λ(forms,sym,tokens){tokens₀ ←! anyfix_macro_eval_l(tokens₀); return [forms.concat([(has_sym(tokens₀,':')? [S('__sliceλ__')].concat(split_slice(tokens₀)) :
		[sym.with_v('__array__')].concat(tokens₀))]),tokens[1:]]}
	block ← λ(forms,sym,tokens){return [forms.concat([[S('__do__')].concat(tokens₀)]),tokens[1:]]}
anyfix_macros_set('[', vector)
anyfix_macros_set('−[', λ(forms,sym,tokens){return forms.no? vector([],sym,tokens) : [
	forms[: -1].concat(
		has_sym((tokens₀ ←! anyfix_macro_eval_l(tokens₀)),':')?
			[[S('__slice__'),forms₋₁].concat(split_slice(tokens₀))] :
			[[S('__sub__'),forms₋₁].concat(tokens₀)]
			),tokens[1:]]})
anyfix_macros_set('(',block)
anyfix_macros_set('−(', λ(forms,sym,tokens){return forms.no? block([],sym,tokens) : [forms[: -1].concat([[forms₋₁].concat(anyfix_macro_eval_l(tokens₀))]),tokens[1:]]})
})()
anyfix_macros_set('{', λ(forms,sym,tokens){
	r←undefined
	starts_like_dict ← λ{(v₀ isa Symbol || typeof(v₀)='string') && se(v₁,':')}
	if (starts_like_dict(tokens₀)) {
		r ←! {}; buf ← []; tokens_ ← tokens₀
		while (¬tokens_.no) {if (¬starts_like_dict(tokens_)) {err(tokens_)} t ← anyfix_macro_eval_form(buf,tokens_[2:],starts_like_dict); r[tokens_₀.v||tokens_₀] ←! t₀; buf ←! t₁; tokens_ ← t₂}
		r ←! [r].concat(buf)
		}
	else r ←! [[S('__do__s')].concat(anyfix_macro_eval_l(tokens₀))]
	return [forms.concat(r),tokens[1:]] })
anyfix_macros_set('‹', λ(forms,sym,tokens){err('‹› not implemented')})
anyfix_macros_set('.', λ(forms,sym,tokens){return [forms[: -1].concat([[sym,forms₋₁||err('bad .',forms₋₁,tokens),tokens₀]]),tokens[1:]]})
anyfix_macros_set([';',','], λ(forms,sym,tokens){return [forms,tokens]})
anyfix_macros_set(unicode.subscripts.concat(unicode.subscripts.map(λ{'₋'+v})),
	λ(forms,sym,tokens){return [forms[: -1].concat([[S('__sub__'),forms₋₁,sym.with_v(unicode.midscript(sym.v))]]),tokens]})
anyfix_macros_set('λ', λ(forms,sym,tokens){
	// don't require () ?
	if (tokens₀ isa Array && tokens₀₀.v = '(') {
		p ← tokens₀[1:].filter(λ{¬se(v,',')}); tokens ← tokens[1:]
		// may disrespect precedence
		t ← anyfix_macro_eval_p1([],tokens); b ← t₀₀; tokens ← t₁; if (t₀.length ≠ 1) err('bad λ')
		return [forms.concat([[sym,p,b]]),tokens] }
	else if (tokens₀ isa Array && tokens₀₀.v = '{') {
		p ← [S('v'),S('b'),S('c')]
		// may disrespect precedence
		tokens₀₀.v ←! '(' //! gah
		t ← anyfix_macro_eval_p1([],tokens); b ← t₀₀; tokens ← t₁; if (t₀.length ≠ 1) err('bad λ')
		return [forms.concat([[sym,p, [S('return')].concat([b])]]),tokens] }
	else return [forms.concat([sym]),tokens] })
anyfix_macros_gen ← λ(v,to){
	// this is horrifying and needs a good refactoring
	parse ← λ{v.match(~/(\[.*?\])|[^[\]]+/g).map(λ{v₀='['? [parse(v[1: -1])] : v.trim().split(' ')}).m_concat().filter(λ{v ≠ ''})}
	t ← parse(v); first ← t₀='…'; t ← first?t[1:]:t; n ← t₀; vs ← t[1:]
	anyfix_macros_set(n,λ(forms,sym,tokens){
		buf ← []
		r ← [to? sym.with_v(to) : sym]; if (first) r.push(is(forms₋₁)?forms₋₁:err())
		vs.map(λ(v,i){
			if (v='…') {
				dont ← vs[i+1] isa Array && vs[i+1]₀ ≠ '…'? vs[i+1]₀ : undefined
				t ← anyfix_macro_eval_form(buf,tokens,λ{se(v₀,dont)}); r.push(t₀); buf ←! t₁; tokens ←! t₂}
			else if (v isa Array) {
				tokens_ ← tokens
				buf_ ← buf
				r_ ← []
				vs_ ← v
				if (vs_.every(λ(v){
						if (v='…') {
							dont ← vs_[i+1] isa Array && vs_[i+1]₀ ≠ '…'? vs_[i+1]₀ : undefined
							t ← anyfix_macro_eval_form(buf_,tokens_,λ{se(v₀,dont)}); r_.push(t₀); buf_ ←! t₁; tokens_ ←! t₂}
						else {
							if (buf_.no && se(tokens_₀,v))
								tokens_ ←! tokens_[1:]
							else return false
						}
						return true
					})) {
					tokens ←! tokens_
					r ←! r.concat(r_)
					buf ←! buf_
				}
			}
			else err('|'+v+'|')
		})
		return [(first?forms[: -1]:forms).concat([r],buf),tokens]
	}) }
anyfix_macros_gen('if … [:] … [else …]','if_s')
anyfix_macros_gen('… ? … [:] …','if')
anyfix_macros_gen('while … [:] …')
anyfix_macros_gen('return […]') // !!
anyfix_macros_gen('throw …')
anyfix_macros_gen('try … [catch …] [finally …]') // !!
anyfix_macros_gen('new …')
anyfix_macros_gen('¬− …')
anyfix_macros_gen('… isa …')
anyfix_macros_gen('… in …')
anyfix_macros_gen('… ¬in …')
anyfix_macros_gen('… * …')
anyfix_macros_gen('… / …')
anyfix_macros_gen('… % …') //-
anyfix_macros_gen('… + …')
anyfix_macros_gen('… - …')
anyfix_macros_gen('↔-− …') // !!
anyfix_macros_gen('… = …')
anyfix_macros_gen('… ≠ …')
anyfix_macros_gen('… < …')
anyfix_macros_gen('… > …')
anyfix_macros_gen('… ≤ …')
anyfix_macros_gen('… ≥ …')
anyfix_macros_gen('… & …'); anyfix_macros_gen('… && …') //-
anyfix_macros_gen('… | …'); anyfix_macros_gen('… || …') //-
anyfix_macros_gen('… ← …')
anyfix_macros_gen('… ←! …')
anyfix_macros_gen('… += …')
*/