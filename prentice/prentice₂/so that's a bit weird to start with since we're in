so that's a bit weird to start with since we're in a position where we can't hold the idea in our head https://medium.com/ai-control/safe-automated-assistants-aa69edd46a57
what if we tried

[I command] Which direction is home?
[Z commands] Explain how you would ''
	[I command] Display a map that includes my current location and my home.
	[Z does] ''
	[I would 1st] Display an arrow pointing Northwest.
	[I would 2nd] Say “Northwest”.
[I command] Which direction is home?
[Z predicts I would] Display an arrow pointing Northwest. Say “Northwest”.
[Z does] Display an arrow pointing Northwest.
[Z does] Say “Northwest”.

<explain>: “lyrics”
	“lyrics of current song”
<explain>: “lyrics of current song”
	is spotify playing a song?
	-> true. then, “lyrics of it (the song spotify is playing)”
<explain>: “is spotify playing a song?”
	“run applescript “tell app "spotify" to player state as string” = “playing”?”
<explain>: “run applescript “tell app "spotify" to player state as string” = “playing”?”
	“eval osaᵥ("tell app \"spotify\" to player state as string") === "playing"”
<explain>: “lyrics of it (the song spotify is playing)”
	“get artist, name of it (the song spotify is playing)”.
	“with those, google those plus “lyrics””.
<explain>: “get artist, name of it (the song spotify is playing)”
	“run applescript “tell app "spotify" to get {artist,name} of current track””
<explain>: “run applescript “tell app "spotify" to get {artist,name} of current track””
	“eval osaᵥ("tell app \"spotify\" to get {artist,name} of current track")”
<explain>: “with those, google those plus “lyrics””
	“eval those.join(' ')+" lyrics"”.
	“with that, eval "http://google.com/search?q=" + encodeURIComponent(that)”
	“with that, open that in a browser”
<explain>: “with that, open that in a browser”
	“run applescript “tell app "chrome" to open location $that””
<explain>: “run applescript “tell app "chrome" to open location $that””
	“eval osa("tell app \"chrome\" to open location "+osa_encode(postredirect_url(that)))”

predictor ← λ(cmd){
	past_cmds[cmd] || “eval print('...')”
}

Rather than teaching a machine the map Command → Implementation, we could try to teach it the map Context → Response. We could then generate complex behaviors by iterating this map.

Here is a simple implementation of this idea.
	A context consists of the command which is currently being executed, as well as everything the user has input or observed while implementing the command.
	A response consists of a command to execute in a given context, or a command to supply as the next element of the output sequence.
	Instead of training P to directly execute a command, we train it to guess our response to each context. We gather training data exactly as in the original proposal, but rather than collecting a single data point of (Command→Implementation) we get a series of data points of (Context→Response), one for each command you execute while implementing Q*.

Imitate. Provide pairs (Context, Response), and train P to predict the response given the context. This is the proposal described above.

but P is weak, so misprediction could be scary
