/*#######################*/ global['try #1'] = _.once(=>{ ######################
parse_bash(œÜ`~/.bashrc`.text).then(Œπ=> global.train = Œπ)

schema2 = Œπ=>{ êÖ™êÖûêÖÇêÖÇêÖú‚Üê;
	# sc_merge ‚Üê Œª(a,b){ak ‚Üê _.keys(a); bk ‚Üê _.keys(b)
	# 	bk.-(ak).forEach(k=> a[k] = b[k])
	# 	ak.‚à©(bk).forEach(k=> a[k] = !Tprim(a[k])? sc_merge(a[k],b[k]) : !Tprim(b[k])? 'error' : a[k])
	# 	‚Ü© a }

	schemas ‚Üê (=>{ # uniq by ‚âà.schema , index by .Œπ
		as_schema ‚Üê Œπ=> _(Œπ).mapObject(Œπ‚áí
			: T.boolean(Œπ)? ‚úì
			: Tstr(Œπ)? ''
			: Tnum(Œπ)? 0
			: schemas.get_Œπ(Œπ)? schemas.get_Œπ(Œπ).id : ‚ÄΩ(Œπ) )
		sch_to_data ‚Üê new Map()
		Œπ_to_sch ‚Üê new Map()
		‚Ü© {
			,get_Œπ: Œπ=> sch_to_data.get(Œπ_to_sch.get(Œπ))
			,add_Œπ: Œπ=>{
				schema ‚Üê as_schema(Œπ)
				sch_k ‚Üê simple_hash_str(schema)
				Œπ_to_sch.set(Œπ,sch_k)
				sch_to_data.has(sch_k) || sch_to_data.set(sch_k,{ Œπ:schema, id:'#'+b36(fromUInt32BE([#Q (êÖ™êÖûêÖÇêÖÇêÖú||(êÖ™êÖûêÖÇêÖÇêÖú= [0] )).0 #Q].Œπ++)), })
				}
			,map: f=> [‚Ä¶sch_to_data.values()].map(f)
			# ,simplify: =>{
			# 	...
			# 	}
			,show(){
				d_t_s ‚Üê sch_to_data.‚Åª¬πdeclare_uniq
				s_t_Œπ ‚Üê Œπ_to_sch.‚Åª¬π
				‚Ü© @.map(Œπ=> JSON_pretty(Œπ.Œπ)+' '+s_t_Œπ.get(d_t_s.get(Œπ)).‚Äñ+' '+Œπ.id ) }
			} })()

	walk(Œπ,Œπ=> Tprim(Œπ) || schemas.add_Œπ(Œπ) )

	‚Ü© schemas.show() }

if( global.train ) sb.tab.push(schema2(train))

# summarizes ~1200 objects with ~500 types
# could try to simplify
/*################################*/ }); /* ####################################
# make pseudocode instead

node ‚Üê js.object
	using: node -> schema ‚Üê _(Œπ).mapObject(Œπ‚áí
		: T.boolean(Œπ)? ‚úì
		: Tstr(Œπ)? ''
		: Tnum(Œπ)? 0
		: @.as.name(Œπ) )
schema
	using ‚â° ‚Üê simple_hash_str
	using [node -> schema]‚Åª¬π
schema <-> name : name = `#${[schema age index] as base 36}`

show(){‚Ü© schemas(Œª(){‚Ü© for @.schema: (JSON_pretty(Œπ) @.as.node(Œπ).‚Äñ @.as.name(Œπ)).join(' ') }) },

# simplify
node -> schema ‚Üê for range: if Œπ.as.(node).‚Äñ = 1 and Œπ.[* - T.prim]/and*.as.(node).‚Äñ = 1: Œπ.[* - T.prim] ‚Üê *.as.schema

;(async =>{
	train ‚Üê await parse_bash(œÜ`~/.bashrc`.text)
	sb.tab.push( schemas(Œª(){‚Ü© @(train).as.schema }) )
	})()

###################### */ global['try #2'] = _.once(=>{ ######################
global['support #1']()
# compile pseudocode to js_lang

Type('node',{
	,'‚àà':Object
	})
Type('schema',{
	,'‚â°':simple_hash_str
	# ,representative(){ _(@).max(Œπ=> Œπ.precedence) }
	,show(){‚Ü© [ JSON_pretty(@), @.as('(node)').‚Äñ, @.as.name, ].join(' ') }
	})
node.->.schema = Œª(Œπ){‚Ü© _(Œπ).mapObject(Œπ‚áí
	: T.boolean(Œπ)? ‚úì
	: Tstr(Œπ)? ''
	: Tnum(Œπ)? 0
	: @(Œπ).as.name ) },
schema.<->.name = Œª(Œπ){‚Ü© `#${age(Œπ).index‚àà(age(@)).as.base(36)}` }

# simplify
# the way that all these concepts interlock is. fucky.
# im too sleep to know how to fix this.
# u do it

schema.‚â°.close_over!(Œπ=>{


	q_is‚Åª¬π ‚Üê Œπ=> Œπ.as('(node)').‚Äñ===1
	names ‚Üê¬†Œπ.filter(Œπ=> Œπ.is.name)

	# should be:
	# if your children names are contained by only one schema:
	# 	fold them into you
	# good skill!

	‚Ü© q_is‚Åª¬π(Œπ) && names.map(Œπ=> q_is‚Åª¬π)./(and)
		? _({}) <- ( Œπ, names.map(Œπ=> Œπ.as.schema) )
		: Œπ } )

;(async =>{
	sb.tab.push( node(await parse_bash(œÜ`~/.bashrc`.text)).as.schema )
	})()

/*################*/ }); global['support #1'] = _.once(=>{ ###################
and ‚Üê (a,b)=> a && b

# missing:
./
.map
.filter

.is.typename
.as.typename
.as('(typename)')
Type
	Type(typename,{
		'‚àà':
		[typename.->.typename]:Œª(Œπ){‚Ü© ...}
			@(Œπ).as.typename
		'‚â°':
			.close_over!
		[Any]:
		show:Œª(){‚Ü© ""}
		})
		.->
			.‚Åª¬π
		.<->
Any
	[Any]:
.‚Äñ
	(Array|Set|Map|etc).prototype.‚Äñ
age
	age(Œπ ‚àà typename)
		.index‚àà
	age(typename)
		.as
			.base(int)

/*##############################*/ }) /* note ##################################
# ‚Ä° alice, expand schema to handle parse_bash output

# sc_merge ‚Üê Œª(a,b){ak ‚Üê _.keys(a); bk ‚Üê _.keys(b)
# 	bk.-(ak).forEach(k=> a[k] = b[k])
# 	ak.‚à©(bk).forEach(k=> a[k] = !Tprim(a[k])? sc_merge(a[k],b[k]) : !Tprim(b[k])? 'error' : a[k])
# 	‚Ü© a }

it looks like you're trying to write a clustering algorithm on the semantic structure of arbitrary json documents
why are you doing this.
i mean it sounds cool but isnt this a major addition at this stage?
what does it do?

in other words, you're trying to write a program that makes guesses at how to parse arbitrary json you found on the internet
why
this is.

parser inference = type inference

but you dont know much about inference really



so if i am?

this is a, um
this is part of the obbbbject inspector html thing?
huh
maybe
i also like schemas and i think this sort of work transfers

