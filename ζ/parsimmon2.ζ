// this would be so fun to optimize
// ok, i grok this now, & i see how i'd need to do various things b4 it's optimizeable. let's do this! later. yay grokking parser combinators :)

// ---------------------------------- core ---------------------------------- //

// issue: makes parser not reentrant, as perf optimization
G_opt ← {fast:null}

_lazy ← f=> p_wrap(λ(stream,i){↩ (@._ = f()._)(stream,i) })
_string ← ι=> p_wrap((stream,i)=>{ head ← stream.slice(i,i+ι.length); ↩ head===ι? make_win(i+ι.length,head) : make_lose(i,ι) })
_regex ← (re,group=0)=>{ T.RegExp(re) || ‽; Tnum(group) || ‽
  re = RegExp(re.source,re.flags.replace(/[^imu]/g,'')+'y'); re_s ← re+''
  ↩ p_wrap((stream,i)=>{ t ← re.exec_at(stream,i); ↩ t && !(t[group]===null || t[group]===undefined)? make_win(i+t[0].length, t[group]) : make_lose(i,re_s) }) }

P ← (ι,…a)=> Tfun(ι)? _lazy(ι) : Tstr(ι)? _string(ι) : T.RegExp(ι)? _regex(ι,…a) : ‽('cant make parser from',ι)

p_wrap ← ι=> new Parser(ι)
Parser ← λ(f){ @._ = f }
P.proto = Parser.prototype

P.proto.parse = λ(stream){ Tstr(stream) || ‽
  G_opt.fast = true; r ← @.skip(eof)._(stream,0)
  if (!r.status){ G_opt.fast = false; r ← @.skip(eof)._(stream,0); !!r.status && ‽; ‽({ index:make_line_col_index(stream, r.furthest), expected:r.expected, }) }
  ↩ r.value }

make_win ← (index,value)=>0?0: { status:true, index, value, }
make_lose ← (index,expected)=>0?0: { status:false, index:-1, value:null, furthest:index, expected:[expected], }

seq ← P.seq = (…ps)=>{ ps.map(ι=> ι instanceof Parser || ‽)
  r ← p_wrap((stream,i)=>{r←;
    accum ← []
    for (j←0;j<ps.length;j++){p←ps[j];  r = merge_replies(p._(stream,i), r); if (!r.status) ↩ r; accum.push(r.value); i = r.index  }
    ↩ merge_replies(make_win(i,accum), r) })
  ↩ r}

alt ← P.alt = (…ps)=>{ ps.map(ι=> ι instanceof Parser || ‽)
  if (!ps.length) ↩ fail('zero alternates')
  ↩ p_wrap((stream,i)=>{r←;
    for (j←0;j<ps.length;j++){p←ps[j];  r = merge_replies(p._(stream,i), r); if (r.status) ↩ r  }
    ↩ r }) }

P.proto.many = λ(){↩ @.times(0,Infinity) }
P.proto.times = λ(min,max){
  if (arguments.length < 2) max = min
  Tnum(min) || ‽; Tnum(max) || ‽

  ↩ p_wrap((stream,i)=>{
    accum ← []
    r←;
    prev_r←;

    for (times ← 0; times < min; times += 1){
      r = @._(stream,i)
      prev_r = merge_replies(r,prev_r)
      if (r.status){ i = r.index; accum.push(r.value) }
      else ↩ prev_r
      }
    for (; times < max; times += 1){
      r = @._(stream,i)
      prev_r = merge_replies(r,prev_r)
      if (r.status){ i = r.index; accum.push(r.value) }
      else break
      }
    ↩ merge_replies(make_win(i,accum), prev_r)
  })
}

P.proto.map = λ(f){ Tfun(f) || ‽; ↩ p_wrap((stream,i)=>{ r ← @._(stream,i); if (r.status) r.value = f(r.value); ↩ r }) }
P.proto.skip = λ(next){↩ seq(@,next).map(ι=> ι[0]) }

eof ← P.eof = p_wrap((stream,i)=> i < stream.length? make_lose(i,'EOF') : make_win(i,null) )

// -------------------------- extra (mostly unused) ------------------------- //

merge_replies ← (r,last)=>{
  if (G_opt.fast) ↩ r
  if (!last) ↩ r
  if (r.furthest > last.furthest) ↩ r
  expected ← r.furthest===last.furthest? unsafe_union(r.expected, last.expected) : last.expected
  ↩ { status:r.status, index:r.index, value:r.value, furthest:last.furthest, expected, } }

// Returns the sorted set union of two arrays of strings. Note that if both arrays are empty, it simply returns the first array, and if exactly one array is empty, it returns the other one unsorted. This is safe because expectation arrays always start as [] or [x], so as long as we merge with this function, we know they stay in sorted order.
unsafe_union ← (xs,ys)=>{
  xL ← xs.length
  yL ← ys.length
  if (xL===0) ↩ ys; else if (yL===0) ↩ xs
  r ← {}
  for (i ← 0; i < xL; i++) r[xs[i]] = true
  for (i ← 0; i < yL; i++) r[ys[i]] = true
  ↩ _.keys(r).sort() }

P.format_error = (stream,error)=>{
  t ← error.expected; ex ← t.length===1? t[0] : 'one of '+t.join(', ')

  index ← error.index
  i ← index.offset

  if (i===stream.length) ↩ ', got the end of the stream'

  prefix ← (i > 0 ? "'..." : "'")
  suffix ← (stream.length - i > 12 ? "...'" : "'")

  got ← ' at line ' + index.line + ' column ' + index.column +  ', got ' + prefix + stream.slice(i,i+12) + suffix

  ↩ 'expected '+ex+got }

seq_map ← P.seq_map = (…a)=>{ f ← a[-1]; a = a.slice(0,-1); Tfun(f) || ‽; ↩ seq(…a).map(ι=> f(…ι)) }

// Allows to add custom primitive parsers
P.custom = f=> p_wrap(f(make_win,make_lose))

P.sep_by = (p,sep)=> P.sep_by1(p,sep).or(P.of([]))
P.sep_by1 = (p,sep)=>{ p instanceof Parser || ‽; sep instanceof Parser || ‽
  pairs ← sep.then(p).many()
  ↩ p.chain(r=> pairs.map(rs=> [r].concat(rs) ) ) }

P.proto.or = λ(ι){↩ alt(@,ι) }
P.proto.then = λ(next){ next instanceof Parser || ‽; ↩ seq(@,next).map(ι=> ι[1]) }

P.proto.result = λ(ι){↩ @.map(()=> ι) }
P.proto.at_most = λ(n){↩ @.times(0,n) }
P.proto.at_least = λ(n){↩ seq_map(@.times(n), @.many(), (init,r)=> init.concat(r) ) }
P.proto.mark = λ(){↩ seq_map(index,@,index,(start,value,end)=>0?0: { start, value, end } ) }
P.proto.desc = λ(expected){↩ p_wrap((stream,i)=>{ r ← @._(stream,i); if (!r.status) r.expected = [expected]; ↩ r }) }

P.of = (value)=> p_wrap((stream,i)=> make_win(i,value) )
fail ← P.fail = expected=> p_wrap((stream,i)=> make_lose(i,expected) )
P.any = p_wrap((stream,i)=> i >= stream.length? make_lose(i,'any character') : make_win(i+1, stream[i]) )
P.all = p_wrap((stream,i)=> make_win(stream.length, stream.slice(i)) )

test ← P.test = test=>( Tfun(test) || ‽,
  p_wrap((stream,i)=> i < stream.length && test(stream[i])? make_win(i+1,stream[i]) : make_lose(i,'a character matching '+test) )
  )
P.one_of = s=> test(ch=> s.indexOf(ch) >= 0 )
P.none_of = s=> test(ch=> s.indexOf(ch) < 0 )
P.take_while = test=>( Tfun(test) || ‽,
  p_wrap((stream,i)=>{ j ← i; while (j < stream.length && test(stream[j])) j++; ↩ make_win(j,stream.slice(i,j)) })
  )

make_line_col_index ← (stream,i)=>{ lines ← stream.slice(0,i).split('\n'); ↩ { offset:i, line:lines.length, column:lines[-1].length+1, } }

index ← P.index = p_wrap((stream,i)=> make_win(i,make_line_col_index(stream,i)) )

P.proto.chain = λ(f){↩ p_wrap((stream,i)=>{ r ← @._(stream,i); ↩ !r.status? r : merge_replies(f(r.value)._(stream,r.index), r) }) }

// ---------------------------------- final --------------------------------- //

Pretty_Typed ← λ(T,ι){ @.T = T; @.ι = ι }; Pretty_Typed.prototype.inspect = λ(d,opt){↩ (@.T==='ident'?'i':@.T)+util.inspect(@.ι,opt) }
P.proto.type = λ(T){↩ @.map(ι=> new Pretty_Typed(T,ι) ) }

typeof module !== 'undefined' && ( module.exports = P )

// test ← ()=>{
//   ident ← P(/(?![0-9])[A-Za-z0-9_$ʰ-ʸˡ-ˣΑ-ΡΣ-ωᴬ-ᵛᵢ-ᵥᶜᶠᶻ⁰ⁱⁿₐ-ₓₕ-ₜℂℕℚℝℤⱼⱽ]+|@/)
//   comment ← /(\/\/.*|\/\*[^]*?(\*\/|$))+/
//   simple_js ← P(()=> P.alt(
//     P.seq( P.alt( ident, P(')'), P(']'), P(/[0-9]/) ), P(RegExp('[ \t]*(?!'+comment.source+')/')) ),
//     P.seq( P('`').type('template'), tmpl_ι.many(), P('`').type('template') ),
//     P(/(['"])(\1|((.*?[^\\])?(\\\\)*)\1)/).type('string'),
//     P(comment).type('comment'),
//     P(/\/((?:[^\/\\\[]|(?:\\.)|\[(?:[^\\\]]|(?:\\.))*\])*)\/([a-z]*)/).type('regex'),
//     P.seq( P('{'), simple_js, P('}') ),
//     ident,
//     P(/[^{}/'"`)@\]A-Za-z0-9_$ʰ-ʸˡ-ˣΑ-ΡΣ-ωᴬ-ᵛᵢ-ᵥᶜᶠᶻ⁰ⁱⁿₐ-ₓₕ-ₜℂℕℚℝℤⱼⱽ]+|[^}]/)
//     ).many() )
//   tmpl_ι ← P.alt( P.seq( P('${').type('template'), simple_js, P('}').type('template') ), P(/\\[^]|(?!`|\$\{)[^]/).type('template') )
//   js_file ← P.seq( P(/(#!.*\n)?/).type('shebang'), simple_js )
//   cn.log('test parsimmon')
//   test ← ()=> js_file.parse(in_); in_ ← φ`~/code/scratch/ζ/index.ζ`.text
//   pass ← JSON.stringify(test())===φ`/tmp/aaaa`.text
//   cn.log(pass?'pass ✓':'fail X')
//   cn.log('perf',bench(test,{TH:3}))
//   }
// typeof @_ !== 'undefined' && test()
