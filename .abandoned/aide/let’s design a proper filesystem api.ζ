// #mission let’s design a proper fucking filesystem api
// #mission let’s do it so that it’s done and we’re done

a filesystem
is made of paths, which are URLs with some extra functionality. they represent directories and files and symlinks, and also FIFO, and occasionally hard links and isBlockDevice/isCharacterDevice/isSocket and maybe something weirder
a path may correspond to a thing that exists but you don’t have permission for
	Error: EACCES: permission denied, scandir '/.Trashes'
paths can be normalized and absolutized and de-symlinked
	∃ a standard pronoun “working directory”; relative paths are interpreted as relative to it. in processes, it’s a directory; in html pages, it’s an http origin
paths can have extensions, which are often meaningful. (basename/filename, ext/suffix)
paths which exist have metadata, such as .birthtime
directories are always just a list of paths relative to themselves and are sometimes but usually not formatted
files are always just a list of bytes and are usually but not always formatted
paths have {{URL,unixpath}{,symlinkified},bashpath} representation
formats include
	binary / bytes   
	utf8             
	lines            
	json             .json
	image            
	png              .png
	jpg              .jpg
	xml              .xml /^<\?xml /
	plist            
	base64           .64
	lines of base64  
	csv              .csv
	pixels (grey)    
	stdin            fd:0
	FIFO             fd:0…
	:executable      ,/^#!/ | try{fs.accessSync(ι,fs.X_OK); ↩ true} catch(e){↩ false}
files at paths can be GET POST PUT DELETE, but POST PUT DELETE can be folded into SET, but we want to make some distinctions to make sure we don’t fuck things up accidentally (although trash could help). GET POST PUT have really tangly apis for all sorts of efficiency concerns. symlinks pretend to be their targets sometimes and show themselves as symlinks some other times.
	? transform-move $bashpath (includes mv)
	? synchronize datasource 1 with datasource 2 (includes cp -r)
		when datasource 1 is an in-memory datastructure and datasource 2 is a filesystem piece and a destination, this is ... shit, it’s a hand-rolled mongo, isn’t it

// ----- uncategorized ---- //

there exists a giant stream of all filesystem events that we can get mostly-reliable slices of
we need to be careful with non-atomic transactions
we need to think about how this interacts with concurrency
we need to think about how this interacts with distributed machines (e.g. mixing file and http URLs)
	“like, it should be caching urls all the time.”

// ------ impl notes ------ //















? synchronize datasource 1 with datasource 2

? transform-move $bashpath

[change basename before extension.]
[change basename. replace non-basename.]
[replace .js extension & parse. replace non-basename.]
[replace extension. exec to filename utility which copies, so unlink.]
[replace non-basename.]
[strip extension & parse. change basename. replace non-basename.]
[strip extension & parse. replace non-basename.]
[unlink.]

append / @($bashpath) += $utf8

basename w/o extension of $bashpath

basename_encode

change working directory // change a pronoun (typical pronouns: global, working directory, jQuery $, ι)

copy $bashpath to $bashpath

find: $bashpath find .64 children (basenames / names relative to bashpath)        //  cwd bashpath; './*.64' ?basename?
find: $bashpath find children (basenames)                                         //  bashpath+'/*' ?basename?
find: $bashpath find children (full names)                                        //  bashpath+'/*'
find: $bashpath find children (full names) | sort | [-1] | read it as json.       //  bashpath+'/*'
find: $bashpath find descendants which are files (name relative to bashpath)      //  cwd bashpath; φ`./**`._.filter('file')
find: $bashpaths | map find .js children (full names)                             //  φ`${bashpath}/**/*.js'
find: ($bashpath find descendants with name = $utf8)[0] // with good performance  //  φ`${bashpath}/**/${utf8}`
find: for children in $bashpath, read it as json // with good performance         //  './**'
find: for children in $bashpath: read it as json                                  //  './**'
find: in $bashpath: find descendants of working-dir that are files                //  './**' filter file
find: in $bashpath: path in $bashpath | filter | delete                           //  bashpath+'/**'
find: working directory find children (basenames)                                 //  './*' ?basename?
find: working directory find descendants (full names) (with their contents)       //  './**'
sets: fs('.').parents().children('{run,index,main}{,.sh,.ζ,.js,.py}')[0]          //  ./..*/{run,index,main}{,.{sh,ζ,js,py}}
// Mage - 0{47..63}.png

if extension is .json, do something with the basename w/o extension, else do something else
if modifying the first two bytes of a file, check if they’re now #! and chmod +x it if so.

metadata: $bashpath exists?
metadata: $bashpath-set | sort stat.birthtime | [-1]
metadata: is dir?

mktemp

move $bashpath to $bashpath

read $bashpath (as utf8)
read $bashpath as base64
read $bashpath as bytes
read $bashpath as lines
read $bashpath as lines * as base64
read $bashpath whose contents are obviously xml | do stuff with the parsed xml
read $bashpath.json
read $bashpath.json (lazily)
read and write symlinks
read stdin to Buffer (to utf8)
read-and-unlink $bashpathfile
read: $bashpath is json (parsing empty file as null). read $bashpath.

resolve $bashpath in $bashpath
resolve-dirname / resolve-(absolute path of “compilation unit”)
resolve-symlinks $bashpath
resolve: (resolve $PWD) absolute path of $bashpath

sets: globs probably aren’t bashpaths, but they’re fun!

unlink $bashpathfile
unlink recursive / rm -r

watch files ∈ path
write $bashpath from $csv (async okay)
write $bashpath from $utf8
write '' to $bashpath
write to $bashpath from $utf8
write to $bashpath from lines
write to $bashpath.json from $json
write to $bashpath.json from ($json from $bashpath as plist) // and be pretty
write to $bashpath.png from $image
write to ($bashpath as binary) from (read-and-unlink $bashpath as base64)
write: $bashpath is json. write to $bashpath from $json
write: atomic write to $bashpath from lines
write: send Buffer to Duplex to file
















// ----- here’s a list of everything we know about that works with files ---- //
// hey future alice: you’re gonna be pretty immersed in the things you’ve done already. only go ahead if you can get over that.
read $unixpath (as utf8)
	q ← fs('corpus/test.js').$
	jsdom.env(fs(ι).$,...)
	// represented as a Path, it has properties path_ and $/val/value/deref
write to $unixpath from $utf8
	fs('../'+date.replace(/-/g,'/')+'/'+slug+'.html').$ = text
	print(i,ι); fs(out).$ = GET_L(ι);
write to $bashpath.png from $image
	(merge weather images @ hour 0, index 9 10 11 12) (″ @ hour 48) → @test.png
$unixpath|bashpath is json (parsing empty file as null). read $unixpath|bashpath.
	t ← fs(DATA_FILE).$; t && Δ._.assign(JSON.parse(t)._.pick(Δ._.keys()))
	ι = JSON.parse(fs(ι).$)
	JSON.parse(fs('~/.auth/spotify').$)
	ι ← JSON.parse(fs("'"${1:-~/Library/Application Support/Google/Chrome/Default/Bookmarks}"'").$).roots.bookmark_bar.children
	// maybe we can also pass it a type/format/view/mixin! eesh, maybe we need to fit it into the prototype system instead of just using a mixin…
$unixpath is json. write to $unixpath from $json
	process.on('exit',λ(){fs(DATA_FILE).$ = JSON.stringify(Δ,null,'  ')})
	fs(out).$ = JSON.stringify(...)
write to $(unix|bash)path.json from $json
	fs('comments.json').$ = JSON.stringify(r,null,'  '),0
	fs('~/ali/history/auto/spotify/'+moment().toString()+'.json').$ = JSON.stringify(tracks,null,'\t')
	fs(cache+'/package.json').$ = JSON.stringify({description:"-",repository:1,license:"ISC"})
read $bashpath whose contents are obviously xml | do stuff with the parsed xml
	read lackey.keylayout; $('keyMapSet').@ = ['foo']
read $unixpath as lines
	story_meta.cache = (t=fs(sm_out).$.split('\n'), t[-1]==='' && t.pop(), t)
	fs('posts.txt').$.trim().split('\n')
	var [title,date,…text] = fs(fl).$.split('\n'); text = text.join('\n')
write to $unixpath from lines
	fs('./posts/'+basename_encode(ι)).$ = posts.join('\n')+'\n' // perhaps this should encode the lines?
	φ`posts/${ι}`.lines = posts  ?
atomic write to $unixpath from lines
	fs('/tmp/fimscrape').$ = C.join('\n'); fs.renameSync('/tmp/fimscrape',sm_out)
read $unixpath as base64
	f10 ← base64.read(fs('data/10.txt').$)
read $unixpath as bytes
	tea ← Buffer(fs('data/tea.txt').$)
read $unixpath as lines * as base64
	data ← fs('data/20.txt').$.trim().split('\n').map(base64.read).map(λ(v){↩ endecrypt_aes_128_ctr(v,key,Buffer(8).fill(0))})
write $bashpath from $utf8
	fs('~/Library/Application Support/Karabiner/private.xml').$ = make_xml(parse_keyrc(fs('~/.keyrc').$))
write $unixpath from $csv (async okay)
	csv.stringify(r,λ(e,ι){fs('comments.csv').$ = ι})
read $bashpath.json
	TAGTIME_V=$(jq .version package.json -r)
read $bashpath.json (lazily)
	let auth = read ./arc/fb_auth.json   or error
	read auth from ./arc/fb_auth.json   or error        (note: should be lazy) <...> auth.id+'|'+auth.secret
write to $bashpath.json from ($json from $bashpath as plist) // and be pretty
	break; case 'from': fs(arg.in+'.json').$ = json_pretty_stringify(plist.parse(fs(arg.in).$),null,'\t')
append / @($bashpath) += $utf8
	Path.prototype.append = function(v){fs.appendFileSync(this._path,v)}
unlink $bashpathfile
	fs(cache+'/package.json').$ = fs(cache+'/README').$ = null
	rmds(){ rm -f ~/{,Desktop,Downloads}/.DS_STORE ~/ali/**/.DS_STORE; }
read-and-unlink $bashpathfile
	t ← fs('/tmp/fs_ipc_'+port).$; fs('/tmp/fs_ipc_'+port).$ = null
	alias ·='eval "$(cat /tmp/__·)"; rm /tmp/__·;'
// del(){ for v in "$@"; do v="$(realpath "$v")"; -q osascript -e 'tell app "finder" to delete POSIX file "'"$v"'"'; rm -f "$(dirname "$v")/.DS_STORE"; done; }
// unlinking is dangerous
// writing is too but typically you unlink more files at a time than you write
// really we should use an algorithm more like Trash
// maybe - use this for anything that's *not* in /tmp ?
write to ($bashpath as binary) from (read-and-unlink $bashpath as base64)
	fs.writeFileSync(out+"/"+fix(ι).replace(/\.64$/,""), Buffer(fs.readFileSync(from+"/"+ι)+"","base64")); fs.unlinkSync(from+"/"+ι)})
read and write symlinks
	for v in /-* ~/-* ~/Library/LaunchAgents/-*; do [ -h "$v" ] && printf "$v"$'\t'; readlink "$v"; done
	ln -sf ~/books/#misc/page_cache ~/pg
rw impls
	Path.prototype._$ = λ(){t ← @.path; ↩ !@.exists()? '' : @.dir()? (console.trace('[ζ] DEPRECATED dir_$'), fs.readdirSync(t).map(λ(ι){↩ t+'/'+ι})) : fs.readFileSync(t)+''}
	Path.prototype['='] = λ(ι){
		// string: text file, Array: directory, etc
		// async should use like fs.createReadStream(ι.path).pipe(fs.createWriteStream(@.path))
		if (@.exists() && @.dir()) throw Error('writing to directories not implemented')
		if (ι == null) {@.exists() && fs.unlinkSync(@.path); ↩}
		mkdir_p ← λ ρ(ι){try {fs.statSync(ι).isDirectory() || fs.mkdirSync(ι)} catch (e) {if (e.code !== 'ENOENT') throw e; ρ(path.dirname(ι)); fs.mkdirSync(ι)}}
		mkdir_p(path.resolve(path.dirname(@.path)))
		fs.writeFileSync(@.path,ι) }
	// Path.prototype.slice = λ(i){↩ ζ_def({},'$',λ(){},λ(ι){path_open(@,λ(){t ← Buffer(ι); fs.writeSync(@.fd,t,0,t.length,i); fs.ftruncateSync(@.fd,i + Buffer.byteLength(ι))})})}
	Path.prototype.splice = λ(idx,rm,ι){path_open(@,λ(fd){t←;
		ι = Buffer(ι)
		rm === ι.length || (t = Buffer(fs.statSync(@.path).size - (idx+rm)), fs.readSync(fd,t,0,t.length,idx+rm))
		fs.writeSync(fd,ι,0,ι.length,idx)
		rm === ι.length || fs.writeSync(fd,t,0,t.length,idx+ι.length)
		rm > ι.length && fs.ftruncateSync(fd,idx+ι.length+t.length)
		})}
copy $bashpath to $bashpath
	(event = "unlink"? touch : copy file to) "./.history/$now $(event = "unlink"? "-" : "+") $(file as filename)"
write '' to $bashpath
	(event = "unlink"? touch : copy file to) "./.history/$now $(event = "unlink"? "-" : "+") $(file as filename)"

? synchronize datasource 1 with datasource 2
	while (meta.length) {t ← meta.pop(); fs(st_out+'/'+t.id).$ = JSON.stringify(story_text(t),null,'  ')}
	fs.readdirSync(from).filter(/\.64$/.λ).map(λ(ι){fs.writeFileSync(out+"/"+fix(ι).replace(/\.64$/,""), Buffer(fs.readFileSync(from+"/"+ι)+"","base64")); fs.unlinkSync(from+"/"+ι)})
	fs("~/Pictures/Photo Booth Library/Pictures").find(">").forEach(λ(ι){t ← fs(ι).name().match(/on ([\d\-]+) at (\d\d)\.(\d\d)(?: #)?(\d+)?(.+)$/); fs.renameSync(ι,fs("~/Downloads").path+"/"+moment(t[1]+"T"+t[2]+":"+t[3]).utc().format("YYYY-MM-DD[T]HH:mm[Z]")+(t[4]?" "+t[4]:"")+t[5])})
	working directory find file descendants | [replace non-basename & exec to filename utility which copies] for v in *; do cp -r "$v" '#rotated'; done; cd '#rotated'; find . -type f -print0 | while IFS= read -r -d $'\0' t; do convert -rotate 270 "$t" "$t"; done;
	build() { install || ↩ 1; rm bin/app; cp package.json resources node_modules *.html -> bin/app; ζ₂ -c *.ζ₂ bin/app; }
	cp -r bin/app TagTime.app/Contents/Resources/
	make ~/Library/Keyboard\ Layouts/lackey.icns equal ./lackey.icns
	make ~/Library/Keyboard\ Layouts/lackey.keylayout equal make_keylayout() \n if any write happened: print 'foo'
? transform-move $bashpath
	[strip extension & parse. change basename. replace non-basename.] fs.writeFileSync(out+"/"+fix(ι).replace(/\.64$/,""), Buffer(fs.readFileSync(from+"/"+ι)+"","base64")); fs.unlinkSync(from+"/"+ι)})
	[change basename. replace non-basename.] t ← fs(ι).name().match(/on ([\d\-]+) at (\d\d)\.(\d\d)(?: #)?(\d+)?(.+)$/); fs.renameSync(ι,fs("~/Downloads").path+"/"+moment(t[1]+"T"+t[2]+":"+t[3]).utc().format("YYYY-MM-DD[T]HH:mm[Z]")+(t[4]?" "+t[4]:"")+t[5])
	[strip extension & parse. replace non-basename.] (fs(arg.out+'/'+R(t[1])).$ = transform_json(fs(arg.in+'/'+ι).$))
	[strip extension & parse. replace non-basename.] replace $in with $out in all writes/deletions. <...> ≈/\.json$/ -> write @file as plist to file without extension
	[replace non-basename.] : (fs(arg.out+'/'+R(ι)).$ = fs(arg.in+'/'+ι).$) // cp(φ`{${arg.in},${arg.out}}${ι}`) ?
	[replace non-basename.] replace $in with $out in all writes/deletions. <...> else -> write @file to file
	[unlink.] .map(λ(ι){ fs(ι).$ = null })
	[replace extension. exec to filename utility which copies, so unlink.] convert "$v" "${v%.*}.png" && rm "$v"
	[replace .js extension & parse. replace non-basename.] else fs(out+'/'+fs(ι).name('.ζ')+'.js').$ = ζ_compile_file(fs(ι).$)
	[change basename before extension.] t=$(identify -verbose "$v" | grep exif:DateTimeOriginal | sed -E 's/^ +[a-zA-Z:]+ //'); $echo mv "$v" "$(echo $t | awk '{ print $1 }' | tr : -)T$(echo $t | awk '{ print $2 }')Z.jpg"

if modifying the first two bytes of a file, check if they’re now #! and chmod +x it if so.
	fs('~/Documents/keyrc_power_key.sh').$ = '#!/usr/bin/env bash -i\nack'; fs.chmod(fs('~/Documents/keyrc_power_key.sh').path,0o777)
for children in $bashpath: read it as json
	fs('comments').find('>').map(λ(ι){↩ JSON.parse(fs(ι).$)})
($unixpath find descendants with name = $utf8)[0] // with good performance
	guess ← fs(process.env.HOME+'/ali').findˢ('#'+place).next().value
$unixpath exists?
	if (context.length === 2 && context[1].type === 'ur_answer' && fs(context[1].v+'/'+context[0].v[1]).exists())
	if (fs(out).exists()) ↩;
	[ -d node_modules ] || npm install
	t="atom-shell-v$ATOMSH_V-darwin-x64.zip"; [ -f "$t" ] || { curl -LO "$ATOMSH_ROOT/$t"; rm Atom.app; }
unixpaths are actually bashpaths - s/^~(?:\/|$)/${process.env.HOME}/
	sublime_open(fs('~/ali/scratch/planspad').path)
	Path ← λ Path(path_){@.path_ = (path_+'').replace(/^~(?=\/|$)/,process.env.HOME); @.path = path.normalize(@.path_+'/.')}
	Path.prototype.toString = λ(){↩ path.resolve(@.path).replace(RegExp('^'+regex_encode(process.env.HOME)+'(?=/|$)'),'~')} // that really shouldn't be “resolve”
globs probably aren’t unixpaths, but they’re fun!
	~/{,Desktop,Downloads}/.DS_STORE* ~/ali/**/.DS_STORE
	{run,index,main}{,.sh,.ζ,.js,.py}
	ln -sf ~/ali/github/scratch/{spotiman,bandcamp-dl,dotfiles/{.bashrc,.keyrc}} ~/ali/books ~
they can even do the same thing as …
	mv ./etc/sudoers{,.bak}
change working directory // change a pronoun (typical pronouns: global, working directory, jQuery $, ι)
	process.chdir(fs('~/ali/scratch').path)
basename_encode
	fs('.history/'+moment(time).toISOString()+' '+(type==='unlink'?'X':'=')+' '+basename_encode(fl)).$ = type==='unlink'? '' : fs(fl).$
watch files ∈ path
	fsʷ.on('.', λ(fl,{type,dir,time}){if (dir) ↩; ... })
	watch files ∈ (. - ./.history/):
working directory find children (basenames)
	ιs ← /* if is filename context */ fs('.').find('>').map(λ(ι){↩ ι.slice(2)})
$unixpath find children (full names)
	corpus ← fs('corpus/all').find('>').map(λ(v){↩ 'corpus/all/'+v})
$bashpath find .64 children (basenames / names relative to bashpath)
	fs.readdirSync(from).filter(/\.64$/.λ)
$unixpaths | map find .js children (full names)
	schelling_places.map(ι => fs(ι).find('> .js'))._.flatten(false)
$unixpath find children (basenames)
	t = t._.indexBy('id'); fs.readdirSync(st_out).map(λ(ι){delete t[ι]})
	t ← fs.readdirSync('post_cache')._.difference(fs.readdirSync('comments'))[0]
for children in $unixpath, read it as json // with good performance
	for (ι of fs('.').findˢ('>')) {ι = JSON.parse(fs(ι).$); t ← ι.parts._.map('content').filter(/<\/a>/.λ).join(' '); t !== '' && r.push(t)}
working directory find descendants (full names) (with their contents)
	fs('.').find('*').map(λ(ι){↩ [ι,fs(ι).$]})._.groupBy(1)._.values().map(λ(ι){↩ ι._.map(0)}).filter(λ(ι){↩ ι.length > 1})
$unixpath find children (full names) | sort | [-1] | read it as json.
	JSON.parse(fs(fs('~/ali/history/auto/spotify').find('>').sort()[-1]).$)
basename w/o extension of $unixpath
	path.basename(ι,'.mp3') // path.basename(ι).replace(/\.[^.]*$/,'')
	.replace('NAME',name=path.basename(ι,'.js'))
send Buffer to Duplex to file
	t ← getDuplex(); t.end(data); t.pipe(fs.createWriteStream(fs(out).path)).on('finish',λ(){ mp3_id3(out).$ = metadata; cb&&cb.in() })
in $bashpath: find descendants of working-dir that are files
	fs(arg.in).find('*').filter(λ(ι){↩ !fs(ι).dir()}).map(λ(ι){↩ ι.slice(arg.in.length).replace(/^\//,'')})
	for files ∈ in *:
resolve-dirname / resolve-(absolute path of “compilation unit”)
	var t = ι => eval(ζ_compile(require('fs').readFileSync(__dirname+'/'+ι+'.ζ')+''))
	break; case '-v': case '--version': print(JSON.parse(fs(__dirname+'/package.json').$).version)
	__dirname=$(dirname $(/usr/local/bin/realpath "${BASH_SOURCE[0]}")); ack(){ (afplay "$__dirname/ack.wav" &); }
(resolve $PWD) absolute path of $bashpath
	Module._load(path.resolve(argv[0]), null, true)
	path.resolve(process.argv[3] || 'Packages')
	path.resolve(fs('~/Library/Application Support/Sublime Text 3/Packages').path)
	.replace('FILE','file://'+fs(ι).resolve())
resolve-symlinks $bashpath
	Path.prototype.realpath = function(){return fs.realpathSync(this._path)}
	beep ← λ(){/*if (shown) */new Audio((@rc).ping_sound as file .realpath()).play()}
resolve $bashpath in $bashpath
	(fs(arg.out+'/'+R(t[1])).$ = transform_json(fs(arg.in+'/'+ι).$))
	: (fs(arg.out+'/'+R(ι)).$ = fs(arg.in+'/'+ι).$)
	roots ← fs('.').find('>').map(λ(ι){↩ arg.out+'/'+ι})
if extension is .json, do something with the basename w/o extension, else do something else
	(t=ι.match(/^(.*)\.json$/))?
$bashpath find descendants which are files (name relative to bashpath)
	out ← fs(arg.out).find('*').filter(λ(ι){↩ roots.some(λ(r){↩ ι.indexOf(r) === 0})}).filter(λ(ι){↩ !fs(ι).dir()})
in $bashpath: path in $bashpath | filter | delete
	_.difference(out,written)
		.filter(λ(ι){ ↩ !/Package Control\./.test(ι.replace(arg.out,'')) })
		.map(λ(ι){ fs(ι).$ = null })
	for paths ∈ (in > *): delete unless (we wrote to it earlier  ||  within in and ≈/Package Control\./)
mktemp
	user_js ← '/tmp/userscript_'+10..map(ι => rand(/[0-9a-z]/.genex_0())).join('')+'.user.js'
		fs(user_js).$ = t
		osa_encode('file://'+user_js)
read stdin to Buffer (to utf8)
	fs.fstatSync(0).mode & 0x1000? read_stdin(t) : t()
is dir?
	fs(ι).dir()
	Path.prototype.dir = λ(){try{↩ fs.statSync(@.path).isDirectory()} catch(e){if (!(e.code==='ENOENT')) throw e; ↩ false}}
rename $bashpath to $bashpath
	fs.renameSync(ι,fs("~/Downloads").path+"/"+moment(t[1]+"T"+t[2]+":"+t[3]).utc().format("YYYY-MM-DD[T]HH:mm[Z]")+(t[4]?" "+t[4]:"")+t[5])
fs('.').parents().children('{run,index,main}{,.sh,.ζ,.js,.py}')[0]
	local t=$(while :; do t=($(shopt -s nullglob; echo {ru[n],inde[x],mai[n]}{,.sh,.ζ,.js,.py})); [[ $t != "" ]] && echo "$PWD/$t" || [[ $PWD != '/' ]] && { cd ..; continue; }; break; done)
$unixpath-set | sort stat.birthtime | [-1]
	ls|sbᵥ|… looks hard. a start: fs('/tmp').find('>').filter(λ(ι){↩ /\/subl stdin /.λ(ι)})._.sortBy(λ(ι){↩ fs.statSync(ι).birthtime})[-1]
	/tmp/subl\ stdin\ * | .sortBy(λ(ι){↩ fs.statSync(ι).birthtime})[-1]
rm -r
	rm node_modules; build || ↩ 1

past difficulty: it’s really weird how this returns a thing that you can’t actually pass to fs(). maybe we’ll fix this by returning a more magical, jquery-like thing?
past difficulty: doesn’t normalize everything properly or reliably

notes on filesystem selectors
	//	*                          *
	//	⟨x⟩ > ⟨children⟩           foo/*
	//	⟨x⟩ ⟨descendants⟩          foo/**
	//	.⟨ext⟩                     .bar
	//	⟨selector1⟩, ⟨selector2⟩   {foo,bar}
	//	⟨filename⟩                 foobar
	//	:file                      
	//	:dir                       
	//  :has(⟨selector⟩)           foo/**.bar/..
	unresolved interesting things:
	set-normalization to [those which exist. uniq.]
	normalization (remove excess . ..)
	(canonical form *does* use ~/) ⋈ no false
	links, symbolic and hard (and consistent sane behavior in the presence of them)

more on file formats
but file formats are really actually Buffer formats
	export ping_file ← file dirty.getDataPath()+'/pings.log'
		ping_file is an array of {time :: unix time, period :: float, tags :: str}, parsed out of its lines:
			// 2014-03-26/19:51:56-07:00(p22.5)? a b c \(a: comment\)
			read:
				≈/^(\d+)([^\[]+)/ -> {time:it[1], period:(@rc).period, tags:it[2].trim()}
				≈/^(?=....-)([^\sp]+)⟨p(\S+)⟩? (.*)$/ -> {time:it[1], period:it[2] || 45, tags:it[3].trim() unless ='<unanswered>'}
			show: (.time as 'YYYY-MM-DD/HH:mm:ssZ')+('p'+.period unless .period=45)+' '+(.tags || '<unanswered>')
		ping_file ~= [next]
		let pings = @ping_file
			somehow we must watch ping_file for changes, as hard as this problem is
			including changes from main.js of this program
			but not including our own changes
		i want to display a view of a slice of @ping_file
		i want the slice to start at the first ping with .tags==null and go until the end or max length
		recent_tags ping ← pings[:(index of ping in pings)][::-1].dropWhile(.tags == null)[0]?.tags
		↩ generate_actions(name, @ping_file -! tagdsl_read.P(tagdsl)(.tags), datapoints_read(it))

	.lackey files are formatted like <read function>; read default.lackey → boxes, chords

	read plist: npm::plist.parse(it)
	show plist: npm::plist.build(it)



// -------------------------- implementation todos -------------------------- //

φ.mktemp.randomstring = λ(fmt){t ← /[0-9a-z]/.genex_0(); ↩ fmt.replace(/(X+)([^X]*)$/,λ(ˣ,ι,r){↩ ι.replace(/./g,()=>rand(t)) + r})} // except as a proper file or w/e https://github.com/sasaplus1/mktemp/blob/master/lib/mktemp.js

// ----- if existence_matching or globbing ---- //

//! bad - should use directed Dijkstra's from all roots with edge length equal to the number of files in a dir
// sample impl:
	// all ← λ(ι){try {↩ fs.readdirSync(ι).map(t => ι+'/'+t) } catch (e) {↩ []}}
	// root ← '.'
	// dist ← {}; dist[root] = 0
	// next ← [root] // should be pqueue
	// out ← []
	// while (next.length) {t ← next._.min(λ(ι){↩ dist[ι]}); next = next._.without(t); out.push(t); at←; (at=all(t)).map(λ(ι){dist[ι] = dist[t] + at.length; next.push(ι)}) }
// or just:
	// all ← λ(ι){try {↩ fs.readdirSync(ι).map(λ(t){↩ ι+'/'+t}) } catch (e) {↩ []}}; root ← '.'; out ← []
	// (λ λ(ι,dist){out.push([dist,ι]); at←;(at=all(ι)).forEach(λ(t){λ(t,dist + at.length)})})(root,0)
	// q ← out._.sortBy(0)._.map(1)

// ι = ι.mapcat(ι => !ts(ι)? [{raw:ENC(ι.raw+'')}] : ι===''?[]: ι.split(''))
// r ← head? [head] : [(!ts(ι[0])? ι[0].raw[0] : ι[0])==='/'? '/' : './']
// parse ← λ(l){
// 	// ^ value+ $ = '{' value* ',' (value | ',')* '}' | `\*+` | `/` | .
// 	push_ ← λ(r,ι){r[-1]&&r[-1].type==='raw' && ι.type==='raw'? (r[-1].ι += ι.ι) : r.push(ι)}
// 	_1 ← λ(i){if (l[i]==='{'}){i++; r ← [{type:'',ι:[]}]; for(;;){ if (l[i]===','){i++; r.push({type:'',ι:[]})} else if (l[i]==={'}'){i++; ↩ r.length>1? {i,ι:{type:'|',ι:r}} : null} else if (i===l.length){↩} else {t ← value(i); i = t.i; push_(r[-1].ι,t.ι)} }}} // '{' value* ',' (value | ',')* '}'
// 	_2 ← λ(i){if (l[i]==='*'){i++; type←'*'; if (l[i]==='*'){i++; type+='*'}; ↩ {i,ι:{type}}}} // `\*+`
// 	_3 ← λ(i){if (l[i]==='/'){i++; type←'/'; ↩ {i,ι:{type}}}} // `/`
// 	_4 ← λ(i){↩ {i:i+1, ι:{type:'raw',ι:(!ts(l[i])? l[i].raw : l[i])}}} // .
// 	value ← λ(i){↩ _1(i) || _2(i) || _3(i) || _4(i)}
// 	all ← λ(){r ← []; i ← 0; while (i !== l.length) {t ← value(i); if (t.i === i) throw Error(); i = t.i; push_(r,t.ι)}; ↩ {type:'',ι:r}} // ^ value+ $
// 	↩ all()}
// eval_ ← λ(r,{type,ι,dir}){switch(type){default: ‽
// 	break; case '': ι.forEach(λ(ι){
// 		r = eval_(r,ι)
// 		}); ↩ r
// 	break; case 'raw': ↩ r.map(r => r+ι)
// 	break; case '/': ↩ r.map(r => r+'/')
// 	break; case '|': ↩ r.mapcat(r => ι.mapcat(ι => eval_([r],ι)))
// 	// break; case '*': ↩ r.mapcat(r => fs.readdirSync(r).filter(re`^…${ι.replace(/\*|[^*]+/g, ι => (ι==='*'? /[^]*/ : re`${ι}`).source)}$`.λ).map(ι => r+'/'+ι))
// 	break; case '*': ↩ r.mapcat(r => fs.readdirSync(r).map(ι => r+'/'+ι))
// 	break; case '**': ↩ r.mapcat(r => […walk(r,!dir)]); dir && (r = r.map(r => r+'/'))
// 	}}
// ι = eval_(r,parse(ι))
// ι = ι.map(path.normalize.X)
// ι = ι.filter(existsSync)
// ↩ ι

// if (ι==='..*') r = r.mapcat(ι => […(λ*(){if (!path.isAbsolute(ι)) {for(;;){yield ι; if (ι==='.') break; ι = path.dirname(ι)}; ι = path.resolve(ι); if (ι==='/') ↩}; for(;;){yield ι; if (ι==='/') break; ι = path.dirname(ι)}})()])

//! handle symlink-cycle and symlink-following cycle
//! needs to handle things like   ${child}*
//! add mktemp.   φ.mktemp.randomstring = λ(fmt){t ← /[0-9a-z]/.genex_0(); ↩ fmt.replace(/(X+)([^X]*)$/,λ(ˣ,ι,r){↩ ι.replace(/./g,()=>rand(t)) + r})} // except as a proper file or w/e https://github.com/sasaplus1/mktemp/blob/master/lib/mktemp.js

//! dedup all globs, existence_matching or no (including parent-ness)

//! make it more jquery-like, so that when it returns an array the elements of the array are literally just strings
// we *can* return Strings or Arrays with a φ property ... but it's probably best not to

// anything that gets properties of things that *aren’t* jQuerys does a .first() first, although it’s perfectly willing to *set* properties on sets
// it is meaningful to end in a slash but only if existence_matching. you’ll only find directories.

// ------- if doing other exotic things ------- //

//! unresolved: fs.fstatSync(0).isFIFO() ; replace with φ.fd(0) ?

// ------------------------ //

// treat symlinks like their targets
// * treat broken symlink like permission error
// except,
// * rm -r doesn’t follow symlinks
// * cp -r doesn’t follow symlinks (to mirror mv)
// * include symlink-specific functions that treat symlinks like files whose contents are their destination and are able to make symlinks and are able to symlink-normalize (which then dedups) - which doesn’t have to normalize to “no symlinks”; it should be possible to normalize to a chosen set of symlinks ... i think
// * * readlink, realpath

// weird things are treated like permission errors
// is_not_weird ← λ(ι){t ← fs.statSync(ι).mode & 0xf000; ↩ t===0x4000 || t===0x8000} // also 0xa000 is symbolic link and 0x1000 is fifo

// permission errors are sometimes ignored and sometimes thrown - think about what’s the right thing to do for various functions
// if they can be fixed via chmoding - again, sometimes you want to fix them and sometimes you don’t (like, you don’t if walking /, but you do if accessing specifically X. maybe other situations?)

// all paths are relative to http:// or file:/ or . or some other path; these are all different kinds of paths and do not mix, but sometimes you want to ‘change the perspective’

// // -------- weird ------- //
// there exists a giant stream of all filesystem events that we can get mostly-reliable slices of

// // ----- uncategorized ---- //
// ? transform-move $bashpath (includes mv)
// ? synchronize datasource 1 with datasource 2 (includes cp -r)
// 	when datasource 1 is an in-memory datastructure and datasource 2 is a filesystem piece and a destination, this is ... shit, it’s a hand-rolled mongo, isn’t it

// we need to be careful with non-atomic transactions
// we need to think about how this interacts with concurrency
// we need to think about how this interacts with distributed machines (e.g. mixing file and http URLs)
// 	“like, it should be caching urls all the time.”

/*
E.pixels = {
	read: λ(ι,type='rgb',cb){npm('get-pixels@3.2.3')(φ(ι)+'',λ(e,{data:D,shape:[X,Y,depth],stride}){X|=0;Y|=0
		// maybe just use Symbol.iterator ?
		;(depth === 4 && stride._.isEqual([4,X*4,1])) || (λ(){throw Error()})()
		if      (type==='rgba') ι ← D
		else if (type==='rgb' ) {ι ← Buffer(X*Y*3); pˡ←0; pᵈ←0; for(i←0;i<X*Y;i++) {ι[pˡ++]=D[pᵈ++]; ι[pˡ++]=D[pᵈ++]; ι[pˡ++]=D[pᵈ++]; pᵈ++}}
		else if (type==='grey') {ι ← Buffer(X*Y); for(i←0;i<X*Y;i++) ι[i] = D[i*4]}
		else throw Error()
		cb(e,{X,Y,ι}) }) },
	show: λ({ι,X,Y},type='rgb',to){
		t ← new (npm('pngjs@2.2.0').PNG)({width:X, height:Y}); D ← t.data; p←0
		if      (type==='rgba') (Buffer.isBuffer(ι)? ι : Buffer(ι)).copy(t.data)
		else if (type==='rgb' ) for(i←0;i<ι.length;) {D[p++] = ι[i++]; D[p++] = ι[i++]; D[p++] = ι[i++]; D[p++] = 0xff}
		else if (type==='grey') for(i←0;i<ι.length;) {D[p++] =         D[p++] =         D[p++] = ι[i++]; D[p++] = 0xff}
		else throw Error()
		t.pack().pipe(fs.createWriteStream(φ(to)+'')) },
	}
*/
