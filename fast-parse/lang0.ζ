#!/usr/bin/env ζ
# *wow* this is a sad way to do versions

############## app prelude #############
Ps ← require(φ`~/code/scratch/fast-parse/parser`+'')
𐅬Tag ← (…ι)⇒{ ,tag:ι[0] ,inspect:=>Tag(…ι) }

################# entry ################
# ⧫. parse_lang ==> ι=> [words,tree.*,𐅪𐅨s_s].fold((ι,f,i)=>{ f===𐅪𐅨s_s &&( γ.𐅬𐅜𐅝𐅃𐅋 = ✓ ) ;r← ;log('⧗',i,⧗(=> r = ι && f.parse(ι) )) ;↩ r },ι)
⧫. parse_lang ==> ι=>
	[words,tree.*,𐅪𐅨s_s]
	.fold((ι,f)=> ι && f.parse(ι) ,ι)

################# word #################
P ← Ps.string
P.err_if_partial = (a,b)⇒
	: b? P([ P.if(P(a)) ,P(b).? ]) ≫(([ˣ,ι])=> ι===∅? ‽(𐅮𐅦𐅨𐅝𐅃) : ι)
	: a===𐅮𐅦𐅨𐅝𐅃 || ‽(a)
	𐅮𐅦𐅨𐅝𐅃 ← Error()

words ← P(Set(
	,sharp= P(Set(
		,P.err_if_partial( /['"]/,P(/(['"])(((?!\1)[^\\]|\\.)*?)\1/) ≫(..2) ).Tag`string`
		,P(Set(
			,P(/[ \t\n,]+/) ≫(ι=> ι.includes(',')? 3 : ι.includes('\n')? 2 : 1 )
			,P(/#[\s#].*/) ≫(=>2) )
			).+ ≫(.fold((a,b)=> max(a,b))).Tag`space`
		,re(alt_ws`( ) [ ] { } . ‘ + - × / ^ * ∪ ∩ …← = ≠ <= >= < > ∈ ∋ & | !> |> ? : ← ←! ↩ ⇒ => ≫`)
		))
	,re(alt_ws`! …`)
	,P([ P.not(sharp),P.unicode_category(/[LNPMS]./) ]) ≫(..1) .+ ≫(.join(''))
	)).*.catch(P.err_if_partial) ;sharp←;

################# tree #################
P ← Ps.list
tree ← P(Set(
	,… ['()','[]','{}'].map(ι=> P([ ,ι[0],=>tree.*,ι[1] ]) ≫(..1).Tag(ι) )
	,P.filter(ι=> ! […'()[]{}'].includes(ι) )
	))

############## ops: tools ##############
is0_ ← .p[0]===𐅭
𐅭 ← P(=>‽('𐅭')) …←(𐅬Tag('𐅭'))
[ᛟ1,ᛟ2,ᛟ3] ← [1,2,3].map(ordid=> P.filter(ι=> ι.tag==='space' && ι.ι<=ordid).? …←(𐅬Tag('ᛟ'+ordid)) )
𐅮𐅦𐅭𐅜𐅬 ← =>{
	γ.𐅃𐅃𐅃𐅋𐅜 = 𐅜𐅩𐅬𐅮𐅩.map(ι=> T.Set(ι)? ι : Set(ι) )
	γ.ops = Set(…𐅃𐅃𐅃𐅋𐅜.…)
	ops.map( .inspect= λ(){↩ Tag('op',@.id) } )
	γ.as_op = ι=> Tstr(ι)? 𐅫𐅫𐅂𐅰𐅩(ι) : ι ;𐅫𐅫𐅂𐅰𐅩 ← ops.group_uniq(.id) ‘.get .f
	}

############## ops: define #############
Ptree ← memoize_proc(tag=> P.filter(.tag===tag) …←(𐅬Tag('filter',tag)) )
# op: {,id,p,map}
𐅂𐅬 ← f=> λ(ι){↩ Tag( @.id ,f(ι) ) }
𐅯R ← (id,…p)⇒{ ,id ,p ,map:𐅂𐅬(ι=>{ [a,t] ← ι.‖===1? [∅,ι[0]] : ι ;t = Tarr(t)? t[-1] : t ;↩[ a,…𐅪𐅨s_s.parse(t.ι) ] }) }
𐅯n ← (id,p)=>{ ;t ← is0_({p})? ..0 : .-1 ;f ← p.filter(ι=>ι===𐅭).‖===1? t : .chunk(2).map(t) ;↩{ ,id ,p ,map:𐅂𐅬(f) } }
𐅯2 ← (id,ι)=> 𐅯n(id,[𐅭,…ι,𐅭])
R_ ← ι=> alt_ws(ι).map_(ι=> 𐅯n(ι,[ι,ᛟ1,𐅭]))
_R ← ι=> alt_ws(ι).map_(ι=> 𐅯n(ι,[𐅭,ᛟ1,ι]))
_2 ← ι=> alt_ws(ι).map_(ι=> 𐅯2(ι,[ᛟ2,ι,ᛟ2]) )
𐅜𐅩𐅬𐅮𐅩 ← [
,'.'|>(ι=> 𐅯2(ι,[ᛟ2,ι,ᛟ1])) !>(ι=> ι.map = ι.map ≫ (ι=>{ Tstr(ι.ι[1]) &&( ι.ι[1] = Tag('string',ι.ι[1]) ) ;↩ι }) ) # weird, man
,𐅯2('‘.',[ᛟ2,'‘','.',ᛟ1])
,𐅯R('()',𐅭,ᛟ1,Ptree('()'))
,𐅯R('[]',𐅭,ᛟ1,Ptree('[]'))
,𐅯R('{}',Ptree('{}'))
,𐅯R('‘[]',𐅭,ᛟ1,'‘',Ptree('[]'))
,_2`^`
,R_`!`
,_2`× /`
,Set( ,…_2`+` ,'-'|>(ι=> 𐅯2(ι,[ᛟ1,ι,ᛟ2])) )
,_2`∪ ∩`
,_2`…←`
,_2`= ≠ <= >= < > ∈ ∋`
,_2`& |`
,_2`!> |> ≫`
,𐅯n('if?',[𐅭,'?',𐅭,':',𐅭].join_(ᛟ2))
,𐅯n('if_',['if',𐅭,P(':').?,𐅭,P(/:|else/u).?,𐅭].join_(ᛟ2))
,alt_ws`⇒ =>`.map_(ι=> 𐅯2(ι,[ᛟ1,ι,ᛟ2]))
,_2`←`
,Set( ,…R_`↩` ,𐅯n('…_',['…',ᛟ1,𐅭]) )
,𐅯n('_…',[𐅭,ᛟ1,'…',P.not([ᛟ1,=> ops.filter(ι=> alt_ws`() [] {} if ↩ 𐅬word`.has(ι.id)).map_(𐅪Pz.X)])])
,_2`:`
,{ ,id:'𐅬word' ,p:[P.not(=> ops.filter(.id!=='𐅬word').map_(𐅪Pz.X)).then(P.filter(.tag!=='space'))] ,map:..0..0 }
]
𐅮𐅦𐅭𐅜𐅬()

𐅃op< ← (it,itᵢ)=> ops.filter(sub=> 0
	|| 𐅨.get…(it,sub)
	|| !is0_(sub)
	|| ( it===sub? alt_ws`^ ← ⇒ => if?`.has(it.id)
		: 𐅰(it) > 𐅰(sub) ) )
	𐅰 ← ι=> 𐅃𐅃𐅃𐅋𐅜.findIndex(.has(ι))
	𐅨 ← new Map()
	b ← as_op('←')                 ;𐅃op<(b).filter(.id!=='.') .map(a=> 𐅨.set…(a,b,✓) )
	a ← as_op('-') ;c ← as_op('!') ;𐅃op<(a).-(𐅃op<(c))        .map(b=> 𐅨.set…(a,b,✗) )

############## ops: parse ##############
𐅭2 ← 𐅃op< ≫ (ops=> P(=> 𐅨𐅃_(ops)(∅).? ) …←(𐅬Tag('𐅭')) )
𐅪P ← memoize_proc(op=> op.p.edge_comple(ι=>ι===𐅭) .map((ι,i)=> ι.‖===1&&ι[0]===𐅭? 𐅭2(op,i) : ι) )
𐅪Pz ← op=> 𐅪P(op) |>(ι=> is0_(op)? ι.slice(1) : ι)
𐅪Pa ← (op,a)=> 𐅪Pz(op) |>(P) ≫(ι=> op.map(!is0_(op)? ι : [a,…ι]) )
𐅮𐅜𐅯𐅜𐅫 ← memoize_proc(.filter(is0_))
𐅨𐅃_ ← memoize_proc( ops=>a=> P(ops.map_(op=> 𐅪Pa(op,a) )).chain(a=>Set( ,𐅨𐅃_(𐅮𐅜𐅯𐅜𐅫(ops))(a) ,P.of(a) )) )
𐅪𐅨s_s ← 𐅨𐅃_(ops)(∅).join2?(ᛟ3)

################################################################################
module.exports = { ,parse:parse_lang }
