##################################### note #####################################
conceptual: word s refer to the procedure-local database of words we know about

ex-parser items: ‚úì ‚úó null ‚àÖ ‚Äñ

note; dont forget: frequently we want to [error if start and not finish] in a form, such as string

P ‚Üê require_new(œÜ`~/code/scratch/fast-parse/parser`)

is_word_unit ‚Üê memoize_persist(Œπ=> memoize_persist(=>
	_u(npm`unicode@10.0.0/category`)
	.filter((À£,type)=> type.re`^[LNPMS].$`)
	.map‚Ä¶(Œπ=> _.keys(Œπ).map(Œπ=> Œπ|0) )
	._.sortBy()
	)().includes(ord(Œπ)) )

# words create a tree structure
# words are considered in a particular order
# it is almost as if words are parsed first via a lexer, but it is not quite

parenless function calls? mb figure those out after you get this working. this is haard.

#################################### grammar ###################################
that_inter_thing ‚Üê (·õü,Œπ)=> [·õü,P([Œπ,·õü]).*]
infix ‚Üê Œπ=> [_,Œπ,_].join2(·õü‚ÇÇ)
prefix ‚Üê Œπ=> [Œπ,·õü‚ÇÅ,_]
·õü‚ÇÅ ‚Üê /[ \t]*/
·õü‚ÇÇ ‚Üê /[ \t\n]*/
·õü‚ÇÉ ‚Üê /[ \t\n,]*/
_ ‚Üê [
	,/(['"])(((?!\1)[^\\]|\\.)*?\1)/
	,[_,·õü‚ÇÇ,'.',·õü‚ÇÅ,P.|([word,string])]
	,[_,·õü‚ÇÇ,'‚Äò.',·õü‚ÇÅ,P.|([word,string])]
 	,[_,·õü‚ÇÅ,'(',that_inter_thing(·õü‚ÇÉ,_),')']
	,[_,'[',_,']'].join2(·õü‚ÇÅ)
	,[_,'‚Äò[',_,']'].join2(·õü‚ÇÅ)
	,['^'].map(Œπ=> infix(Œπ) ‚Ä¶‚Üê ({ right:‚úì }) )
	,['!','-'].map(prefix)
	,['√ó','/'].map(infix)
	,['+','-'].map(infix)
	,['‚à™','‚à©'].map(infix)
	,['‚Ä¶‚Üê'].map(infix)
	,['=','‚â†','<','>','<=','>=','‚àà','‚àã'].map(infix)
	,['&','|'].map(infix)
	,['!>','|>'].map(infix)
	,[_,'?',_,':',_].join2(·õü‚ÇÇ)
	,['if',_,P(':').?,_,P.|([':','else']).?,_].join2(·õü‚ÇÇ)
	,['‚Üê','‚Üê!'].map(Œπ=> infix(Œπ) ‚Ä¶‚Üê ({ right:‚úì }) )
	,['‚Ä¶','‚Ü©‚Üê'].map(prefix)
	,['‚Ü©',·õü‚ÇÅ,_.?]
	,[_,·õü‚ÇÅ,'‚áí',·õü‚ÇÇ,_]
	,[':'].map(infix)
	,['()','[]','{}'].map(([a,b])=> [a,that_inter_thing(·õü‚ÇÉ,_),b])
	,[ ['[',that_inter_thing(·õü‚ÇÉ,_),']']
	,is_word_unit.+
	]

####################### btw i made a simple infix parser #######################
# for:
# E.Property = ‚à™( ,¬ß`obj √ó id -> place`
# 	,‚àã( ¬ß`-> üîí √ó hide` ,=> [‚úó,‚úì] )
# 	,‚àã( ¬ß`-> host` ,(obj,id,place,üîí,hide)=> Set( Object.getOwnPropertyDescriptors(obj)[id], Object.getOwnPropertyDescriptor(obj,id), { ,configurable:!üîí ,enumerable:!hide } ‚Ä¶‚Üê (place) ).Just )

P.build_op = (unit,op)=>{
	# binary left: 1-2-3 = (1-2)-3  ;binary right: 1^2^3 = 1^(2^3)
	# ,'2 center':p=> P([ p, P.seq(op,p).*.map(Œπ=> _(Œπ).flatten(‚úì)) ]).map(([a,op_bs])=> !op_bs.length? a : R('op',{A:'2 center', Œπ:[a, ‚Ä¶op_bs]}) )
	_1L ‚Üê p=>{ r ‚Üê P(=> P.|([ P([ op,r ]).map(([op,Œπ])=> [op,‚àÖ,Œπ]) ,p ])) ;‚Ü© r }
	_1R ‚Üê p=> P([ p, op.* ]).map(([x,r])=> r.fold((Œπ,op)=> [op,Œπ,‚àÖ], x) )
	_2L ‚Üê p=> P([ p, P([ op,p ]).* ]).map(([x,r])=> r.fold((a,[op,b])=>[op,a,b], x) )
	_2R ‚Üê p=>{ r ‚Üê P(=> p.chain(a=> P.|([ P([ op, r ]).map(([op,b])=>[op,a,b]) ,P.of(a) ])) ) ;‚Ü© r }
	‚Ü© unit |>(_2L) |>(_1L) |>(_1R) }

fn_wrap_lits ‚Üê f=> code=> code.eval_in_lexical_env('('+Œ∂_parse(code+'').map(Œπ=> Œπ.T==='shebang'? '' : Œπ.T==='string'||Œπ.T==='regex'? f(Œπ.Œπ) : Œπ ).join('')+')')

¬ß ‚Üê (=>{
	P ‚Üê require_new(œÜ`~/code/scratch/fast-parse/parsimmon.Œ∂`)
	Any ‚Üê =>Any; Any = ‚Äòlexical_env=>{
		unit ‚Üê P.alt([ ,/[A-Za-züîíŒπ]+/ ,P([ '[',Any,']' ]).map(Œπ=> Œπ[1]) ])
		‚Ü© [ '.','√ó','+','->' ].fold(P.build_op,unit) }
		|> ( fn_wrap_lits(Œπ=> String.raw`P(${Œπ}).skip(/\s*/)`) )()
	‚Ü© Œπ=>{Œπ+=''
		Œπ = Any.parse(Œπ)
		Tarr(Œπ)
		} })()
