P ← require_new(φ`~/code/scratch/fast-parse/parser`)
##################################### note #####################################
# conceptual: word s refer to the procedure-local database of words we know about

# modules: ✓ ✗ null ∅ ‖

# words create a tree structure
# words are considered in a particular order
# it is almost as if words are parsed first via a lexer, but it is not quite

# parenless function calls? mb figure those out after you get this working. this is haard.

################################ grammar 1 flesh ###############################
leaf_prefixd ← P.|([
	,P.err_if_partial( /['"]/,P(/(['"])(((?!\1)[^\\]|\\.)*?)\1/).map(([ˣ,ʸ,ι])=> ι) )
	])
_ ← P.|([
	,leaf_prefixd
	,P([ P.not(leaf_prefixd),P.unicode_category(/[LNPMS]./) ]).map(..1).+ .map(.join('')).Tag`id`
	]).catch(P.err_if_partial)

############################### grammar -1 flesh ###############################
# a simple infix parser
P.build_op = (unit,op)=>{
	# binary left: 1-2-3 = (1-2)-3  ;binary right: 1^2^3 = 1^(2^3)
	# ,'2 center':p=> P([ p, P.seq(op,p).*.map(ι=> _(ι).flatten(✓)) ]).map(([a,op_bs])=> !op_bs.length? a : R('op',{A:'2 center', ι:[a, …op_bs]}) )
	∅R_ ← p=>{ r ← P(=> P.|([ P([ op,r ]).map(([op,ι])=> [op,∅,ι]) ,p ])) ;↩ r }
	_R∅ ← p=> P([ p, op.* ]).map(([x,r])=> r.fold((ι,op)=> [op,ι,∅], x) )
	_R_l ← p=> P([ p, P([ op,p ]).* ]).map(([x,r])=> r.fold((a,[op,b])=>[op,a,b], x) )
	_R_r ← p=>{ r ← p.chain(a=> P.|([ P([ op, r ]).map(([op,b])=>[op,a,b]) ,P.of(a) ])) ;↩ r }
	↩ unit |>(_R_l) |>(∅R_) |>(_R∅) }

# [ '.','×','+','->' ].fold(P.build_op,/[A-Za-z🔒ι]+/)
# §`obj × id -> place`
# §`-> 🔒 × hide`
# §`-> host`

################################### grammar 3 ##################################
# ok this is cute but lets just hardcode a lexer and get on with it
# hardcoded lexer + word prioritization (read time) (the way clojure does macros should be good enough)

⧫. parse_lang ==>{

γ.words = P(Set(
	,sharp= P(Set(
		,P(/(['"])(((?!\1)[^\\]|\\.)*?)\1/).map(..2).Tag`string`
		,P(/[ \t\n,]+/).map(ι=> ι.includes(',')? 3 : ι.includes('\n')? 2 : 1 ).Tag`space`
		,re(alt_ws`( ) [ ] { } . ‘ + - × / ^ * ∪ ∩ …← = ≠ <= >= < > ∈ ∋ & | !> |> ? : ← ←! ↩ ⇒`)
		))
	,re(alt_ws`! …`)
	,P([ P.not(sharp),P.unicode_category(/[LNPMS]./) ]).map(..1).+ .map(.join(''))
	)).* ;sharp←;

id ← ι=> P.any1.filter(t=> t===ι)
γ.trees = P(=>trees) ;trees = P(Set(
	,… ['()round','[]square','{}curly'].map(ι=> P([ ,id(ι[0]),trees,id(ι[1]) ]).map(..1).Tag(ι.slice(2)))
	,P.any1.filter(ι=> ! […'()[]{}'].includes(ι) )
	)).*

_2 ← ι=> (ι+'').split(' ').map(ι=> P([ _,ι,_ ]).map(ι=> [ι[0],ι[1]]).Tag(ι).join(ᛟ2) )
# prefix ← (ι,f=ι=>ι)=> P([ι,ᛟ1,f(_)]).map(..2).Tag(ι)
ᛟ1 ← P.any1.filter(ι=> ι.tag==='space' && ι.ι<=1 ).?
ᛟ2 ← P.any1.filter(ι=> ι.tag==='space' && ι.ι<=2 ).?
ᛟ3 ← P.any1.filter(ι=> ι.tag==='space' && ι.ι<=3 ).?
# γ.ops = P(=>ops) ;ops =
	# ,[_,ᛟ2,'.',ᛟ1,_]
	# ,[_,ᛟ2,'‘.',ᛟ1,_]
	# ,[_,ᛟ1,'(',top,')']
	# ,[_,'[',_,']'].join2(ᛟ1)
	# ,[_,'‘[',_,']'].join2(ᛟ1)
	# ,['^'].map(ι=> infix(ι) …← ({ right:✓ }) )
	# ,['!','-'].map(prefix)
	# ,_2`× /`
	# ,[ ,…_2`+` ,[ P.|([ free,_ ]),ᛟ1,'-',ᛟ2,_ ] ]
	# ,_2`∪ ∩`
	# ,_2`…←`
	# ,_2`= ≠ <= >= < > ∈ ∋`
	# ,_2`& |`
	# ,_2`!> |>`
	# ,[_,'?',_,':',_].join2(ᛟ2)
	# ,[ 'if',_,P(':').?,_,P(/:|else/).?,_ ].join2(ᛟ2)
	# ,['←','←!'].map(ι=> infix(ι) …← ({ right:✓ }) )
	# ,['…'].map(prefix)
	# ,['↩',ᛟ1,_.?]
	# ,[_,ᛟ1,'⇒',ᛟ2,_]
	# ,_2`:`

↩ ι=> [words,trees].fold((ι,p)=> p.parse(ι) ,ι) }

;[
	,"if 'handle' 5 : 6 7"
	,"if 'handle' 5 : 6? 7:8"
	,"yield'saddlepoint'"
	,"↩ ['saddlepoint' [bogan]()]"
	,"… ! ↩← 5"
	,"…! ↩←"
	]
	.map(parse_lang.X)
