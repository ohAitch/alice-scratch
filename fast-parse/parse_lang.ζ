# conceptual: word s refer to the procedure-local database of words we know about

# modules: ✓ ✗ null ∅ ‖

# words create a tree structure
# words are considered in a particular order
# it is almost as if words are parsed first via a lexer, but it is not quite

# parenless function calls? mb figure those out after you get this working. this is haard.

# you want to find the shortest substring that parses? you do this by iterating thru the file running op_tree on unparsed chars & getting back parsed spans on success
# i think this is a cheat but a good one

################################################################################
# ok this is cute but lets just hardcode a lexer and get on with it
# hardcoded lexer + word prioritization (read time) (the way clojure does macros should be good enough)

⧫. parse_lang ==> ι=> [words,tree.*,op_trees].fold((ι,p)=> ι && p.parse(ι) ,ι)

Ps ← require_new(φ`~/code/scratch/fast-parse/parser`)
##############################
P ← Ps.string

P.err_if_partial = (a,b)⇒
	: b? P([ P.if(P(a)) ,P(b).? ]).map(([ˣ,ι])=> ι===∅? ‽(𐅮𐅦𐅨𐅝𐅃) : ι)
	: a===𐅮𐅦𐅨𐅝𐅃 || ‽(a)
	𐅮𐅦𐅨𐅝𐅃 ← Error()

words ← P(Set(
	,sharp= P(Set(
		,P.err_if_partial( /['"]/,P(/(['"])(((?!\1)[^\\]|\\.)*?)\1/).map(..2) ).Tag`string`
		,P(/[ \t\n,]+/).map(ι=> ι.includes(',')? 3 : ι.includes('\n')? 2 : 1 ).Tag`space`
		,re(alt_ws`( ) [ ] { } . ‘ + - × / ^ * ∪ ∩ …← = ≠ <= >= < > ∈ ∋ & | !> |> ? : ← ←! ↩ ⇒ =>`)
		))
	,re(alt_ws`! …`)
	,P([ P.not(sharp),P.unicode_category(/[LNPMS]./) ]).map(..1).+ .map(.join(''))
	)).*.catch(P.err_if_partial) ;sharp←;

##############################
P ← Ps.list
tree ← P(=>tree) ;tree ← P(Set(
	,… ['()','[]','{}'].map(ι=> P([ ,ι[0],tree.*,ι[1] ]).map(..1).Tag(ι) )
	,P.filter(ι=> ! […'()[]{}'].includes(ι) )
	))

##############################
_ ← P(=>‽('_'))
[ᛟ1,ᛟ2,ᛟ3] ← [1,2,3].map(ordid=> P.filter(ι=> ι.tag==='space' && ι.ι<=ordid).? )
𐅯_Rι ← (id,…ι)⇒{ ,id ,p:[_,…ι] ,map(ι,a){↩[ a,…op_trees.parse(ι[-1].ι) ]} }
R_ ← ι=> alt_ws(ι).map_(ι⇒{ ,id:ι ,p:[ι,ᛟ1,_] })
𐅯2 ← (id,…ι)⇒{ ,id ,p:[_,…ι,_] }
_2 ← ι=> alt_ws(ι).map_(ι=> 𐅯2(ι,ᛟ2,ι,ᛟ2) )
𐅜𐅩𐅬𐅮𐅩 ← [
	,'.'|>(ι=> 𐅯2(ι,ᛟ2,ι,ᛟ1))
	,𐅯2('‘.',ᛟ2,'‘','.',ᛟ1)
	,𐅯_Rι('_(_)' ,ᛟ1,    P.filter(.tag==='()'))
	,𐅯_Rι('_[_]' ,ᛟ1,    P.filter(.tag==='[]'))
	,𐅯_Rι('‘_[_]',ᛟ1,'‘',P.filter(.tag==='[]'))
	,_2`^`
	,R_`!`
	,_2`× /`
	,Set( ,…_2`+` ,'-'|>(ι=> 𐅯2(ι,ᛟ1,ι,ᛟ2)) )
	,_2`∪ ∩`
	,_2`…←`
	,_2`= ≠ <= >= < > ∈ ∋`
	,_2`& |`
	,_2`!> |>`
	# ,{ ,id:'if?' ,p:[_,'?',_,':',_].join2(ᛟ2) ,map(){} }
	# ,[ 'if',_,P(':').?,_,P(/:|else/).?,_ ].join2(ᛟ2)
	,alt_ws`⇒ =>`.map_(ι=> 𐅯2(ι,ᛟ1,ι,ᛟ2))
	,_2`←`
	,R_`…`
	,R_`↩`
	,_2`:`
	# nonprefixed () [] {}
	]

op_ord ← 𐅜𐅩𐅬𐅮𐅩.map(ι=> T.Set(ι)? ι : Set(ι) )
ops ← Set(…op_ord.…)
ops.map( ‘.P .thunk= λ(){↩ P(@.p.trim(_)).map(ι⇒{op:@,ι}) } )
ops.map( .inspect= λ(){↩ Tag('op',@.id) } )
ops.map(ι=> ι.map||(ι.map= (ι,…a)=> a ))
𐅪 ← ι=> op_ord.findIndex(t=> […t].some(t=> t.id===ι.id))
cmp ← new Map()
ops.map(a=> ops.map(b=> cmp.set…(a,b, 𐅪(b) - 𐅪(a) ) ))
as_op ← ι=> Tstr(ι)? 𐅫𐅫𐅂𐅰𐅩(ι) : ι ;𐅫𐅫𐅂𐅰𐅩 ← ops.index(.id) ‘.get .f
𐅃op< ← a=> ops.filter(b=> !(b.p[0]===_ && cmp.get…(as_op(a),b)>0 ))
cmp_is ← (a,b,ι)=> cmp.set…(as_op(a),as_op(b),ι)

ops.map(ι=> cmp_is(ι,ι,1) )
;['^','←'].map(ι=> cmp_is(ι,ι,-1) )
b ← '←' ;𐅃op<(b).filter(.id!=='.') .map(a=> cmp_is(a,b,-1) )
a ← '-' ;c ← '!' ;𐅃op<(a).-(𐅃op<(c)) .map(b=> cmp_is(a,b,1) )

𐅃op< = memoize_proc(𐅃op<)
𐅬𐅋word ← P.not(Set( ops ,P.filter(.tag==='space') )).then(P.any1)
𐅞𐅰_op ← ops=>a=>Set(
	,P(ops).chain(({op,ι})⇒
		: op.p[-1]===_? op_tree(𐅃op<(op)).map(b=>[ op.id ,…op.map(ι,a,b) ])
		: P.of([ op.id ,…op.map(ι,a) ])
		).chain(𐅞𐅰_op(ops.filter(.p[0]===_)))
	,P.of(a) )
op_tree ← ops=> 𐅬𐅋word.?.chain(𐅞𐅰_op(ops))
op_trees ← op_tree(ops).join2?(ᛟ3)

parse_lang(`
cmp_is ← (a,b,ι)=> cmp.set…(as_op(a),as_op(b),ι)
=> e ← a‘.b
if 'handle' 5 : 6? 7:8 9
… ! ↩
! x + 5
- 7
space ^ azo ^ now
a × b← c + d
↩ ( ['saddlepoint' [bogan]()] ) x y
`)
