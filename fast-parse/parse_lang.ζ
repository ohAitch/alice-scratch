P â† require_new(Ï†`~/code/scratch/fast-parse/parser`)

##################################### note #####################################
# conceptual: word s refer to the procedure-local database of words we know about

# modules: âœ“ âœ— null âˆ… â€–

# words create a tree structure
# words are considered in a particular order
# it is almost as if words are parsed first via a lexer, but it is not quite

# parenless function calls? mb figure those out after you get this working. this is haard.

################################ grammar 1 flesh ###############################
# P.err_if_partial = (a,b)â‡’
# 	: b? P([ P.if(P(a)) ,P(b).? ]).map(([Ë£,Î¹])=> Î¹===âˆ…? â€½(ğ…®ğ…¦ğ…¨ğ…ğ…ƒ) : Î¹)
# 	: a===ğ…®ğ…¦ğ…¨ğ…ğ…ƒ || â€½(a)
# 	ğ…®ğ…¦ğ…¨ğ…ğ…ƒ â† Error()

# leaf_prefixd â† P(Set(
# 	,P.err_if_partial( /['"]/,P(/(['"])(((?!\1)[^\\]|\\.)*?)\1/).map(([Ë£,Ê¸,Î¹])=> Î¹) )
# 	))
# _ â† P(Set(
# 	,leaf_prefixd
# 	,P([ P.not(leaf_prefixd),P.unicode_category(/[LNPMS]./) ]).map(..1).+ .map(.join('')).Tag`id`
# 	)).catch(P.err_if_partial)

################################### grammar 3 ##################################
# ok this is cute but lets just hardcode a lexer and get on with it
# hardcoded lexer + word prioritization (read time) (the way clojure does macros should be good enough)

# â§«. parse_lang ==>{

word â† P(Set(
	,sharp= P(Set(
		,P(/(['"])(((?!\1)[^\\]|\\.)*?)\1/).map(..2).Tag`string`
		,P(/[ \t\n,]+/).map(Î¹=> Î¹.includes(',')? 3 : Î¹.includes('\n')? 2 : 1 ).Tag`space`
		,re(alt_ws`( ) [ ] { } . â€˜ + - Ã— / ^ * âˆª âˆ© â€¦â† = â‰  <= >= < > âˆˆ âˆ‹ & | !> |> ? : â† â†! â†© â‡’`)
		))
	,re(alt_ws`! â€¦`)
	,P([ P.not(sharp),P.unicode_category(/[LNPMS]./) ]).map(..1).+ .map(.join(''))
	)) ;sharpâ†;

# is â† Î¹=> P.filter(t=> Tstr(Î¹)? t===Î¹ : re`^${Î¹}$`.test(t) )
is â† Î¹=> P.filter(t=> t===Î¹)
tree â† P(=>tree) ;tree â† P(Set(
	,â€¦ ['()round','[]square','{}curly'].map(Î¹=> P([ ,is(Î¹[0]),tree.*,is(Î¹[1]) ]).map(..1).Tag(Î¹.slice(2)))
	,P.filter(Î¹=> ! [â€¦'()[]{}'].includes(Î¹) )
	))

##############################
# _2 â† Î¹=> (Î¹+'').split(' ').map(Î¹=> P([ _,Î¹,_ ]).map(Î¹=> [Î¹[0],Î¹[1]]).Tag(Î¹).join(á›Ÿ2) )
á›Ÿ1 â† P.filter(Î¹=> Î¹.tag==='space' && Î¹.Î¹<=1 ).?
á›Ÿ2 â† P.filter(Î¹=> Î¹.tag==='space' && Î¹.Î¹<=2 ).?
á›Ÿ3 â† P.filter(Î¹=> Î¹.tag==='space' && Î¹.Î¹<=3 ).?

_2            â† Î¹=> alt_ws(Î¹).map_(Î¹â‡’{ ,id:Î¹ ,P:P([á›Ÿ2,is(Î¹),á›Ÿ2]).map(..1) })
_2_norm_tight â† Î¹=> alt_ws(Î¹).map_(Î¹â‡’{ ,id:Î¹ ,P:P([á›Ÿ2,is(Î¹),á›Ÿ1]).map(..1) })
_2_tight_norm â† Î¹=> alt_ws(Î¹).map_(Î¹â‡’{ ,id:Î¹ ,P:P([á›Ÿ1,is(Î¹),á›Ÿ2]).map(..1) })
ops â† [
	,_2_norm_tight`. â€˜.`
	# ,[_,á›Ÿ1,'(',top,')']
	,Set( { ,id:'round' ,P:P([á›Ÿ1,P.filter(.tag==='round')]).map(..1).map(Î¹=>( Î¹.Î¹= top.parse(Î¹.Î¹) ,Î¹ )) } )
	# ,[_,'[',_,']'].join2(á›Ÿ1)
	# ,[_,'â€˜[',_,']'].join2(á›Ÿ1)
	,_2`^`
	# ,['!','-'].map(prefix)
	,_2`Ã— /`
	# ,[,[ P(Set( free,_ )),á›Ÿ1,'-',á›Ÿ2,_ ] ]
	,_2`+ -`
	,_2`âˆª âˆ©`
	,_2`â€¦â†`
	,_2`= â‰  <= >= < > âˆˆ âˆ‹`
	,_2`& |`
	,_2`!> |>`
	# ,[_,'?',_,':',_].join2(á›Ÿ2)
	# ,[ 'if',_,P(':').?,_,P(/:|else/).?,_ ].join2(á›Ÿ2)
	,_2`â†`
	# ,['â€¦'].map(prefix)
	# ,['â†©',á›Ÿ1,_.?]
	,_2_tight_norm`â‡’`
	,_2`:`
	]
ğ…ª â† Î¹=> ops.findIndex(t=> [â€¦t].some(t=> t.id===Î¹.id))
ğ…ƒo â† Î¹=> ğ…ğ…¦ğ…¦ğ…¬ğ…¨.get(Î¹) ;ğ…ğ…¦ğ…¦ğ…¬ğ…¨ â† ops.â€¦.index(.id)
cmp â† new Map() .| ((a,b)=> ğ…ª(b) - ğ…ª(a))
ops_lt â† Î¹=> memoize_proc(Î¹=> Set(â€¦ops.â€¦.filter(t=> cmp(ğ…ƒo(Î¹),t)<0 )) )(o_name(Î¹))
o_name â† Î¹=> Tstr(Î¹)? Î¹ : Î¹.tag # it is possible i want to replace all .id with .tag ,via Tag(...)
oP â† ops=> P(Set(â€¦ops.map(.P)))
ğ…¯ğ…®word â† P.not(oP(ops.â€¦)).then(P.any1).?
ğ…‹ğ…¬op â† (p,ops)=> p.chain(a=> P(Set(
	,ğ…‹ğ…¬op( oP(ops).chain(o=> ğ…‹ğ…¬op(ğ…¯ğ…®word,ops_lt(o)).map(b=>[ o,a,b ]) ) ,ops )
	,P.of(a) )) )
top â† ğ…‹ğ…¬op(ğ…¯ğ…®word,ops.â€¦).*?

ops.â€¦.map(Î¹=> cmp.setâ€¦(Î¹,Î¹,1) )
;['^','â†'].map(ğ…ƒo).map(Î¹=> cmp.setâ€¦(Î¹,Î¹,-1) )
cmp.setâ€¦(ğ…ƒo('+'),ğ…ƒo('â†'),-1)

# if 'handle' 5 : 6 7
# if 'handle' 5 : 6? 7:8
# yield'saddlepoint'
# â†© ['saddlepoint' [bogan]()]
# â€¦ ! â†©â† 5
# â€¦! â†©â†
lines`
'space'
an.i.mal + so.und + cloud.grey('space')
azo
space ^ quon ^ now
a + a + c + .d2^d3 Ã— e
a + aâ† b + b
.+.
`.map(Î¹=> [word.*,tree.*,top].fold((Î¹,p)=> p.parse(Î¹) ,Î¹) )
