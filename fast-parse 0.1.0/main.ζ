#!/usr/bin/env ζ
// [parsimmon] would be so fun to optimize

// ----------------------------- todo eventually ---------------------------- //
// issue: makes parser not reentrant, as perf optimization
// G_opt ← {fast:null}
// G_opt.fast = true; r ← p.skip(/$/)._(in_,0); if (!r.status){ G_opt.fast = false; r ← p.skip(/$/)._(in_,i); /*!!r.status && ‽*/; r.status || ‽({ i:make_line_col_index(in_, r.furthest), expected:r.expected, in_:in_.slice(i,i+1e3), })
// merge_replies ← (r,last)=>{ if (G_opt.fast) ↩ r
// Don't use backtracking, instead explore all variants concurrently. Backtracking requires to keep the entire input in memory (also known as a memory leak).
// Support left recursion.

// ---------------------------------- util ---------------------------------- //
log ← { levels:{ info:0, warn:1, } }
log.set = ι=> log.level = ι
_(log.levels).keys().forEach(t=>{
	log[t] = (…a)=> log.levels[log.level] <= log.levels[t] && cn.log(…a)
	})
log.set('warn')

// ------------------ eve-style records with tags, sort of ------------------ //
Tagged ← λ(){ @.tag = new Set() }
Tagged.prototype.inspect = λ(d,opt){
	ks ← (…a)=> _(@).keys().sort()._.isEqual(a.sort())
	↩ @.tag.map(ι=> opt.stylize('#'+ι,'regexp')).join('')+( ks('tag')? '' : ' '+util.inspect( ks('tag','ι')? @.ι : _(_(@).pairs()._.object()).omit('tag') ,opt) ) }
Tagged.prototype.≈  = λ(ss,…ιs){ ss.length===1 || ‽; ι ← ss[0]; ι.re`^#` || ‽; ↩ @.tag.has(ι.replace(/^#/,'')) }
Tagged.prototype.+= = λ(ss,…ιs){ ss.length===1 || ‽; ι ← ss[0]; ι.re`^#` || ‽; @.tag.add(ι.replace(/^#/,'')); ↩ @ }
Tagged.prototype.-= = λ(ss,…ιs){ ss.length===1 || ‽; ι ← ss[0]; ι.re`^#` || ‽; @.tag.delete(ι.replace(/^#/,'')); ↩ @ }
// Tagged.prototype.<- = 
R ← (…a)=>{t←;
	if (is_template(a)){ r ← new Tagged(); easy_template(ι=>ι)(…a).mapcat(ι=> Tstr(ι)? ι.trim().split(' ') : [{ι:ι[0]}]).forEach(ι=> Tstr(ι)? r.+=([ι]) : _(r).assign(ι) ); ↩ r }
	a.length===1 || ‽; ι ← a[0]
	if (ι instanceof Tagged) ↩ ι
	if (Tprim(ι)) ↩ R`${ι}`
	if ((t=Object.getPrototypeOf(ι))===null || t===Object.prototype) ↩ _(new Tagged()).assign(ι)
	‽ }
// ι = {ι:6}
// R`#foo #bar ${ι}`
// R`#foo #bar …${ι}`
// R`#foo #bar f:${ι}`
// R`#foo #bar …${{f:ι}}`
// R(ι).+=`#repeat` vs R`#repeat …${ι}`

map_tag_tree ← (ι,f)=>{ if(ι&&( Tarr(ι) || ι.tag )) _(ι).forEach((v,k)=> ι[k] = map_tag_tree(v,f) ); ↩ f(ι) }

// ------------------------------- regex_parse ------------------------------ //
// P ← require_new(φ`~/file/code/scratch/fast-parse/main.ζ`+'')
anon_eefm3←null;
regex_parse ← ι=> (anon_eefm3 || ( anon_eefm3 = _.memoize(flags=>{
	ENC ← ι=> parse_external(OR_or_SEQ,ι.source || ι)
	dehex ← ι=> String.fromCodePoint(parseInt(ι,16))
	simplify ← ι=>{ if (ι && ι.tag){
		if (ι.ι){ if (Tarr(ι.ι)) ι.ι = ι.ι.map(simplify); else ι.ι = simplify(ι.ι) }
		if (ι.≈`#seq`){
			ι.ι = ι.ι.mapcat(ι=> ι.tag && ι.≈`#seq`? ι.ι : [ι] )
			if (ι.ι.length===1) ↩ simplify(ι.ι[0])
			}
		if (ι.≈`#not` && ι.ι.≈`#set` && !ι.ι.ι.length) ↩ ENC(/(?:)/)
		}; ↩ ι }

	ESCAPE ← P(['\\',P.or([
		P(/x([0-9a-fA-F]{2})/).map(ι=> dehex(ι[1])),
		P(/u\{([0-9a-fA-F]+)\}/).map(ι=> dehex(ι[1])),
		P(/u([0-9a-fA-F]{4})/).map(ι=> dehex(ι[1])),
		P(/c[A-Z]|[trnvf0]|[dDwWsSbB]|[1-9][0-9]*/).map(ι⇒
			{t:'\t',r:'\r',n:'\n',v:'\v',f:'\f',0:'\0'}[ι] ||( 0?0
			: ι[0]==='c'? String.fromCodePoint(ι[1].codePointAt() - 'A'.codePointAt() + 1)
			: ι==='d'? ENC(/[0-9]/u)
			: ι==='D'? ENC(/[^0-9]/u)
			: ι==='w'? ENC(/[A-Za-z0-9_]/u)
			: ι==='W'? ENC(/[^A-Za-z0-9_]/u)
			: ι==='s'? ENC(/[ \f\n\r\t\v\u00a0\u1680\u180e\u2000-\u200a\u2028\u2029\u202f\u205f\u3000\ufeff]/u)
			: ι==='S'? ENC(/[^ \f\n\r\t\v\u00a0\u1680\u180e\u2000-\u200a\u2028\u2029\u202f\u205f\u3000\ufeff]/u)
			: ι==='b'? ENC(String.raw`(?<=\w)(?!\w)|(?<!\w)(?=\w)`)
			: ι==='B'? ENC(String.raw`(?<=\w)(?=\w)|(?<!\w)(?!\w)`)
			: ( ι===(ι = ι|0)+'' || ‽, R`#backref ${ι}` ) ) ),
		/[^]/
		])]).map(ι=>ι[1])
	SET_ESCAPE ← P.or([ P('\\b').map(()=>'\b'), ESCAPE ])
	s1 ← P.or([
		/[^.()[\]^$|\\]/,
		ESCAPE,
		P`.`.map(()=> ENC(/[^\n\r\u2028\u2029]/)),
		P`(?:${()=>OR_or_SEQ})`,
		P`(?!${()=>OR_or_SEQ})`.R`#not`,
		P`(?=${()=>OR_or_SEQ})`.R`#not`.R`#not`,
		P`(?<=${()=>OR_or_SEQ})`.R`#behind`,
		P`(?<!${()=>OR_or_SEQ})`.R`#behind`.R`#not`,
		P`(${()=>OR_or_SEQ})`.R`#capture`,
		P`[${[ /\^?/, (λ(){ t ← P.or([ SET_ESCAPE,/[^\]]/ ]); ↩ P.or([ P([ P([t,'-']).map(ι=>ι[0]), t ]), t, ]).* })() ]}]`
			.map(ι=>{ r ← R`#set ${ι[1]}`; if (ι[0]) r = R`#seq ${[ R`#not ${r}`, R`#any` ]}`; ↩ r }),
		])
	TIMES ← P([ s1, P([ P.or([ '*','+','?',/\{([0-9]+)(?:(,)([0-9]*))?\}/ ]), P('?').?, ]).? ]).map(([ι,rep])=>{
		if (!rep) ↩ ι
		for_ ← ι=> ι==='*'? [0,∞] : ι==='+'? [1,∞] : ι==='?'? [0,1] : (λ(){ [ˣ,a,two,b] ← ι; ↩ [a|0,b? b|0 : two? ∞ : a|0] })()
		↩ R({ ι, for:for_(rep[0]), greedy:!rep[1], }).+=`#repeat` })
	q ← dir=> ENC((!flags.re`m`? { '^':'(?<![^])', '$':'(?![^])' } : { '^':'(?<![^\n\r])', '$':'(?![^\n\r])' })[dir])
	s2 ← P.or([ P('^').map(q), P('$').map(q), TIMES ])
	OR_or_SEQ ← P.sep_by(s2.*.R`#seq`, '|').map(ι=> ι.length > 1? R`#or ${ι}` : ι[0] )
	↩ ι=>{
		r ← parse_external(OR_or_SEQ,ι)
		if (flags.re`y`) r = R`#seq ${[R`#sticky`,r]}`
		if (flags.re`u`) r = R`#unicode ${r}`; else ‽('can only parse unicode regex')
		if (flags.re`i`) r = R`#ignore_case ${r}`
		if (flags.re`g`) ‽
		// g should be part of the call, not the regex (split no care, search no care, replace care simple, match care simple, exec care weird)
		↩ R(simplify(r)).+=`#RegExp`
		} }) ))(ι.flags || '')(ι.source || ι)

// ------------------------------- fast_parse ------------------------------- //
P ← (ι,…ιs)⇒
	: ι.tag? ι
	: is_template([ι,…ιs])? (()=>{
		ι = easy_template(ι=>ι)(ι,…ιs)
		i ← ι.map((ι,i)=>[ι,i]).filter(([ι,i])=>Tarr(ι)).map(([ι,i])=>i)
		↩ P(ι.map(ι=> Tarr(ι)?ι[0]:ι)).map(ι=> i.length===1? ι[i[0]] : i.map(i=> ι[i]) )
		})()
	: Tfun(ι)? R`#graph_thunk ${()=> P(ι())}`
	: Tstr(ι)? P(re`${ι}`)
	: T.RegExp(ι)? R`#regex ${ι}`
	// ---- regex-overlap --- //
	: Tarr(ι)? R`#seq ${ι.map(P.X)}`
	// ---------------------- //
	: ‽('cant make parser from',ι)
// ----- regex-overlap ---- //
P.any = ()=> R`#any`
// P.behind = ι=> R`#behind ${P(ι)}`
P.not = ι=> R`#not ${P(ι)}`
P.or = ι=> R`#or ${ι.map(P.X)}`
P.repeat = o=>{ o.ι = P(o.ι); ↩ R(o).+=`#repeat` }
// P.set = ι=> R`#set ${ι}`
// ------------------------ //
P.return = o=> R(o).+=`#return`
P.__chain = ({ι,f})=> R({ ι:P(ι), f }).+=`#chain`
// ------------------------ //
P.__map = ({ι,f})=> P(ι).chain((ι,etc)=> P.return({ ι:f(ι,etc) }))
P.? = (ι,greedy=true)=> P.repeat({ ι, for:[0,1], greedy }).map(ι=> ι[0])
P.* = (ι,greedy=true)=> P.repeat({ ι, for:[0,∞], greedy })
P.+ = (ι,greedy=true)=> P.repeat({ ι, for:[1,∞], greedy })
P.?? = ι=> P.?(ι,false)
P.*? = ι=> P.*(ι,false)
P.+? = ι=> P.+(ι,false)
// ------------------------ //
Tagged.prototype.chain = λ(f){↩ P.__chain({ ι:@, f }) }
Tagged.prototype.map = λ(f){↩ P.__map({ ι:@, f }) }
Tagged.prototype.R = λ(ss,…ιs){ ιs = […ιs,null]; ss = _([…ss,'']).assign({raw:[…ss.raw,'']}); ↩ @.map(ι=>{ ιs[-1] = ι; ↩ R(ss,…ιs) }) }
def(Tagged.prototype,'?',{get(){↩ P.?(@) }})
def(Tagged.prototype,'*',{get(){↩ P.*(@) }})
def(Tagged.prototype,'+',{get(){↩ P.+(@) }})
def(Tagged.prototype,'??',{get(){↩ P.??(@) }})
def(Tagged.prototype,'*?',{get(){↩ P.*?(@) }})
def(Tagged.prototype,'+?',{get(){↩ P.+?(@) }})
// ------------------------ //
P.sep_by = (p,sep)=> P.or([ P.sep_by1(p,sep), P.return({ι:[]}) ])
P.sep_by1 = (p,sep)=> P(p).chain(ι=> P([sep,p]).map(ι=>ι[1]).*.map(ιs=> [ι].concat(ιs)))

parse ← (p,in_,i)=>(λ(){ L ← in_.length - i; if(0);
	// ---- regex-overlap --- //
	else if( @.≈`#any` ) ↩ L > 0? make_win(i+1,in_[i]) : make_lose(i,{inspect(d,opt){↩ opt.stylize('anything','special') }})
	else if( @.≈`#seq` ){ r ← []; t←; for(var p of @.ι){ t = merge_replies(parse(p,in_,i),t); if (!t.status) ↩ t; r.push(t.ι); i = t.i }; ↩ merge_replies(make_win(i,r),t) }	
	else if( @.≈`#or` ){ r←; for(var p of @.ι){ r = merge_replies(parse(p,in_,i),r); if (r.status) ↩ r }; ↩ r }
	else if( @.≈`#repeat` ){ @.greedy || ‽
		r ← []; prev_t←; j←0
		for(;j<@.for[0];j++){ t ← parse(@.ι,in_,i); prev_t = merge_replies(t,prev_t); if( t.status ){ i = t.i; r.push(t.ι) }else ↩ prev_t }
		for(;j<@.for[1];j++){ t ← parse(@.ι,in_,i); prev_t = merge_replies(t,prev_t); if( t.status ){ i = t.i; r.push(t.ι) }else break }
		↩ merge_replies(make_win(i,r), prev_t) }
	else if( @.≈`#not` ){ if( @.ι.tag && @.ι.≈`#not` ){ t ← parse(@.ι.ι,in_,i); ↩ t.status? make_win(i,undefined) : t }else{ t ← parse(@.ι,in_,i); self ← @; ↩ t.status? make_lose(i,{inspect(d,opt){↩ opt.stylize('not','special')+' '+util.inspect(self.ι,opt) }}) : make_win(i,undefined) } }
	// else if( @.≈`#behind` ){ }
	// else if( @.≈`#set` ){ }
	// ---------------------- //
	else if( @.≈`#return` ) ↩ @.e? make_lose(i,@.e) : make_win(i,@.ι)
	else if( @.≈`#chain` ){ r ← parse(@.ι,in_,i); ↩ !r.status? r : merge_replies(parse(@.f(r.ι,{ start:i, i:r.i, in_ }),in_,r.i),r) }
	else if( @.≈`#regex` ){ !@.ι.flags.replace(/[muy]/g,'') || ‽; t ← @.ι.u.y.exec_at(in_,i); ↩ t? make_win( i+t[0].length, t.length===1? t[0] : t.slice() ) : make_lose(i,@.ι) }
	// ---------------------- //
	else if( @.≈`#graph_thunk` ) ↩ parse(( Tfun(@.ι) &&( @.ι = @.ι() ), @.ι ),in_,i)
	else ‽ }).call(p)
p2 ← parse
parse = (p,in_,i)=>{ r ← p2(p,in_,i); log.info('parse',{p,in:in_.slice(i),r}); ↩ r }
parse_external ← (p,in_,i=0)=>(λ(){
	r ← parse(P([@,/$/]).map(ι=> ι[0]),in_,i)
	r.status || ‽({ i:make_line_col_index(in_, r.furthest), expected:r.expected, in_:in_.slice(i).slice(0,1e3), })
	↩ r.ι }).call(p)

make_line_col_index ← (in_,i)=>{ lines ← in_.slice(0,i).split('\n'); ↩ { offset:i, line:lines.length, column:lines[-1].length+1, } }

// make_win ← (i,ι)⇒ { status:true, i, ι, }
make_win ← (i,ι)⇒ { status:true, i, ι, furthest:-1, expected:[], }
make_lose ← (i,expected)⇒ { status:false, i:-1, ι:null, furthest:i, expected:[expected], }

interpret_regex_exec_at ← (ι,str,i)=>{
// 	regex_parse produces these tags:
// 	any
// 	not
// 	or
// 	repeat
// 	seq

// 	behind
// 	set

// 	backref
// 	capture
// 	ignore_case
// 	RegExp
// 	sticky
// 	unicode
	ι = regex_parse(ι)
	ι.≈`#unicode` || ‽
	ι = ι.ι
	ι.≈`#seq` && ι.ι[0].≈`#sticky` || ‽
	ι.ι.shift()
	ι = map_tag_tree(ι,ι⇒
		: Tstr(ι)? P(ι)
		: ι.tag &&( ι.≈`#seq` || ι.≈`#repeat`)? ι.map(ι=> ι.join(''))
		: ι )
	cn.log('running',ι)
	log.set('info')
	t ← parse(ι,str,i)
	log.set('warn')
	↩ !t.status? null : t.ι }

// resolve ← p=>{
// 	t ← search_graph(p,ι=> ι instanceof Parser)
// 	↩ t.map(ι=> _(ι).omit('_','ps','p'))
// 	}

// Parser.prototype.resolve = λ(seen){ seen ||( seen = new Map() )
// 	if (seen.has(@)) ↩ seen.get(@); seen.set(@,@)
// 	switch( @.type ){
// 		default: ;
// 		break; case 'lazy': Tfun(@.ι) &&( @.ι = @.ι(), @.ι.resolve(seen) )
// 		break; case 'seq': case 'alt': @.ps.map(ι=> ι.resolve(seen))
// 		break; case 'times': case 'map': case 'map_js': case 'chain': @.p.resolve(seen)
// 		}
// 	↩ seen.get(@) }
// Parser.prototype.optimize = λ(seen){ seen ||( seen = new Map() )
// 	if (seen.has(@)) ↩ seen.get(@); seen.set(@,@)
// 	switch( @.type ){
// 		default:;
// 		break; case 'lazy': seen.set(@,@.ι); @.ι = @.ι.optimize(seen); seen.set(@,@.ι)
// 		break; case 'seq': case 'alt': @.ps = @.ps.map(ι=> ι.optimize(seen))
// 		break; case 'times': case 'map': case 'map_js': case 'chain': @.p = @.p.optimize(seen)
// 		}
// 	↩ seen.get(@) }

// -------------------------- extra (mostly unused) ------------------------- //

merge_replies ← (r,last)=>{
	// Returns the sorted set union of two arrays of strings. Note that if both arrays are empty, it simply returns the first array, and if exactly one array is empty, it returns the other one unsorted. This is safe because expectation arrays always start as [] or [x], so as long as we merge with this function, we know they stay in sorted order.
	unsafe_union ← (xs,ys)=>{
		xL ← xs.length
		yL ← ys.length
		if (xL===0) ↩ ys; else if (yL===0) ↩ xs
		r ← {}
		for (i ← 0; i < xL; i++) r[xs[i]] = true
		for (i ← 0; i < yL; i++) r[ys[i]] = true
		↩ _.keys(r).sort() }
	if (!last) ↩ r
	if (r.furthest > last.furthest) ↩ r
	expected ← r.furthest===last.furthest? unsafe_union(r.expected, last.expected) : last.expected
	↩ { status:r.status, i:r.i, ι:r.ι, furthest:last.furthest, expected, } }

// ---------------------------------- final --------------------------------- //

typeof module !== 'undefined' && ( module.exports = {P,parse_external} )

if (!module.parent){

word_extra ← re`♈-♓🔅🔆`; word_extra_gu ← re`[${word_extra}]`.g
word ← re`A-Za-z0-9_$ʰ-ʸˡ-ˣΑ-ΡΣ-ωᴬ-ᵛᵢ-ᵥᶜᶠᶻ⁰ⁱⁿₐ-ₓₕ-ₜℂℕℚℝℤⱼⱽ${word_extra}`
ident ← P(re`(?![0-9])[${word}]+|@`)
comment ← re`(?://.*|/\*[^]*?(?:\*/|$))+`
simple_js ← P(()=> P.or([
	P(comment).R`#comment`,
	P([ P('{'), simple_js, P('}') ]),
	P([ P.or([
		P(/(['"])((\\.|(?!\1|\\)[^])*?\1)/).map(ι=> ι[0]).R`#string`,
		ident,
		P([ P('`').R`#template`, tmpl_ι.*, P('`').R`#template` ]),
		/[)\]0-9]/,
		]), P(re`[ \t]*(?!${comment})/`).?.map(ι=> ι||'') ]),
	P(re`/(?:(?:[^/\\\[]|(?:\\.)|\[(?:[^\\\]]|(?:\\.))*\])*)/(?:[a-z]*)`).R`#regex`,
	P(re`[^{}/'"…${'`'})@\]${word}]+|[^}]`)
	]).* )
tmpl_ι ← P.or([ [ P('${').R`#template`, simple_js, P('}').R`#template` ], P(/(?:\\[^]|(?!`|\$\{)[^])+/).R`#template` ])
js_file ← P([ P(/(?:#!.*\n)?/).R`#shebang`, simple_js ])

ζ_parse ← code=>{ r ← []; for(var t of parse_external(js_file,code)._.flatten()) Tstr(t) && Tstr(r[-1])?( r[-1]+=t ): r.push(t); ↩ r }
test ← ()=> ζ_parse(in_); in_ ← φ`/tmp/foo`.text // φ`~/code/scratch/ζ/index.ζ`.text
// pass ← JSON.stringify(test())===φ`/tmp/aaaa`.text
// cn.log(pass?'pass ✓':'fail X')
// cn.log('perf',bench(test,{TH:3}))
// cn.log('output',test())
// cn.log(regex_parse(/\{([0-9]+)(?:(,)([0-9]*))?\}/u))
// cn.log(regex_parse(/[^imu]/u))
// cn.log(regex_parse(/(['"])((\\.|(?!\1|\\)[^])*?\1)/u))
// cn.log(regex_parse(/(?:\\[^]|(?!`|\$\{)[^])+/u))
// cn.log(regex_parse(/(#!.*\n)?/u))

// cn.log(js_file)
// cn.log('perf',pretty_time_num(bench1(test) * (φ`~/code/scratch/ζ/index.ζ`.text.length / φ`/tmp/foo`.text.length)))
// cn.log(regex_parse(/^(foo)?(?:b(b.)){2,7}\baz[^]??[^\n](?:\\b.ar|\b[\ba-c-e()}][^\s]|b*?|baz(gremlin\u2424$)?(?!groblem)|)*\3/iuy))
// cn.log(/(?:b|a|r| |f|o|m)*foo+/uy.exec_at('bar fooooooo m fooo fo',0))
// cn.log([interpret_regex_exec_at(/(?:b|a|r| |f|o|m)*foo+/uy,'bar fooooooo m fooo fo',0)])

}




/*fix
regex_parse(/[^\s]/u)
regex_parse(/[💩-💫]/u)
regex_parse(/[\D]/)

#unicode#RegExp #seq [ #not #set [ #set [ ' ',
      '\f',
      '\n',
      '\r',
      '\t',
      '\u000b',
      ' ',
      ' ',
      '᠎',
      [ ' ', ' ' ],
      ' ',
      ' ',
      ' ',
      ' ',
      '　',
      '﻿' ] ],
  #any ]

#unicode#RegExp #set [ '�', [ '�', '�' ], '�' ]

#set#RegExp [ #seq [ #not #set [ [ '0', '9' ] ], #any ] ]
*/

// -------- trash? -------- //
// seq_map ← P.seq_map = (…a)=>{ f ← a[-1]; a = a.slice(0,-1); Tfun(f) || ‽; ↩ P(a).map(ι=> f(…ι)) }
// Parser.prototype.mark = λ(){↩ seq_map(P_index,@,P_index,(start,ι,end)⇒ { start, ι, end } ) }
// Parser.prototype.desc = λ(e){↩ P.or([ @,P.return({e}) ]) }
// __index ← ()=> P2({ type:'index', _(in_,i){↩ make_win(i,make_line_col_index(in_,i)) }, })
